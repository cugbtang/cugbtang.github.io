<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage data-theme=light><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>从预训练到蒸馏：深入解析大语言模型训练全流程2 - ✌yesplease's blog</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=yes"><meta name=MobileOptimized content="width"><meta name=HandheldFriendly content="true"><meta name=applicable-device content="pc,mobile"><meta name=color-scheme content="light dark"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=mobile-web-app-capable content="yes"><meta name=generator content="Hugo 0.152.2"><link rel=canonical href=https://cugbtang.github.io/post/llm/llm-4.1/><meta name=author content="yesplease"><meta name=description content="全面解析大语言模型从预训练到部署的全流程关键技术，包括Pretrain、SFT、LoRA、RLHF/DPO、RLAIF和模型蒸馏等核心概念与实践应用"><meta name=keywords content="LLM,预训练,微调,RLHF,模型蒸馏"><meta property="og:url" content="https://cugbtang.github.io/post/llm/llm-4.1/"><meta property="og:site_name" content="✌yesplease's blog"><meta property="og:title" content="从预训练到蒸馏：深入解析大语言模型训练全流程2"><meta property="og:description" content="全面解析大语言模型从预训练到部署的全流程关键技术，包括Pretrain、SFT、LoRA、RLHF/DPO、RLAIF和模型蒸馏等核心概念与实践应用"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="post"><meta property="article:published_time" content="2025-12-23T00:00:00+00:00"><meta property="article:modified_time" content="2025-12-23T00:00:00+00:00"><meta property="article:tag" content="LLM"><meta property="article:tag" content="预训练"><meta property="article:tag" content="微调"><meta property="article:tag" content="RLHF"><meta property="article:tag" content="模型蒸馏"><meta itemprop=name content="从预训练到蒸馏：深入解析大语言模型训练全流程2"><meta itemprop=description content="全面解析大语言模型从预训练到部署的全流程关键技术，包括Pretrain、SFT、LoRA、RLHF/DPO、RLAIF和模型蒸馏等核心概念与实践应用"><meta itemprop=datePublished content="2025-12-23T00:00:00+00:00"><meta itemprop=dateModified content="2025-12-23T00:00:00+00:00"><meta itemprop=wordCount content="1636"><meta itemprop=keywords content="LLM,预训练,微调,RLHF,模型蒸馏"><meta name=twitter:card content="summary"><meta name=twitter:title content="从预训练到蒸馏：深入解析大语言模型训练全流程2"><meta name=twitter:description content="全面解析大语言模型从预训练到部署的全流程关键技术，包括Pretrain、SFT、LoRA、RLHF/DPO、RLAIF和模型蒸馏等核心概念与实践应用"><link rel=icon href=/favicon.ico><link rel=stylesheet href=/css/style.min.e7c52960f769ac11bea62d460dc48cd995591740192e6c6f8c0f5585fb135c9d.css integrity="sha256-58UpYPdprBG+pi1GDcSM2ZVZF0AZLmxvjA9VhfsTXJ0=" media=screen crossorigin=anonymous><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script><script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--><script>(function(){var e=localStorage.getItem("theme")||"light";document.documentElement.setAttribute("data-theme",e)})()</script></head><body><div id=back-to-top></div><header class=site-header><div class=desktop-header><div class=desktop-header-logo><a href=/ class=logo>✌yesplease</a></div><nav class=desktop-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=https://cugbtang.github.io/>This is Home</a></li><li class=menu-item><a class=menu-item-link href=https://cugbtang.github.io/post/>Archives</a></li><li class=menu-item><a class=menu-item-link href=https://cugbtang.github.io/tags/>Tags</a></li><li class=menu-item><a class=menu-item-link href=https://cugbtang.github.io/about/>About</a></li><li class=menu-item><a class="theme-toggle menu-item-link" href=javascript:void(0);><svg aria-hidden="true" class="lucide lucide-sun hi-svg-inline theme-icon-light" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><circle cx="12" cy="12" r="4"/><path d="M12 2v2"/><path d="M12 20v2"/><path d="m4.93 4.93 1.41 1.41"/><path d="m17.66 17.66 1.41 1.41"/><path d="M2 12h2"/><path d="M20 12h2"/><path d="m6.34 17.66-1.41 1.41"/><path d="m19.07 4.93-1.41 1.41"/></svg>
<svg aria-hidden="true" class="lucide lucide-moon hi-svg-inline theme-icon-dark" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M12 3a6 6 0 009 9 9 9 0 11-9-9z"/></svg></a></li><li class=menu-item><a class=menu-item-link href=https://cugbtang.github.io/index.xml rel="noopener alternate" type=application/rss+xml title=rss target=_blank><svg aria-hidden="true" class="lucide lucide-rss hi-svg-inline icon--rss" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></li></ul></nav></div><div class=mobile-header><div id=mobile-navbar class=mobile-navbar><div id=mobile-navbar-icon class=mobile-navbar-icon><svg aria-hidden="true" class="lucide lucide-menu hi-svg-inline icon--menu" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><line x1="4" x2="20" y1="12" y2="12"/><line x1="4" x2="20" y1="6" y2="6"/><line x1="4" x2="20" y1="18" y2="18"/></svg></div><div class=mobile-navbar-logo><a href=/ class=logo>✌yesplease</a></div></div><div id=mobile-menu-close-modal class=mobile-menu-close-modal></div><nav id=mobile-menu class=mobile-menu><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=https://cugbtang.github.io/>This is Home</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://cugbtang.github.io/post/>Archives</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://cugbtang.github.io/tags/>Tags</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://cugbtang.github.io/about/>About</a></li><li class=mobile-menu-item><a class="theme-toggle menu-item-link" href=javascript:void(0);><svg aria-hidden="true" class="lucide lucide-sun hi-svg-inline theme-icon-light" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><circle cx="12" cy="12" r="4"/><path d="M12 2v2"/><path d="M12 20v2"/><path d="m4.93 4.93 1.41 1.41"/><path d="m17.66 17.66 1.41 1.41"/><path d="M2 12h2"/><path d="M20 12h2"/><path d="m6.34 17.66-1.41 1.41"/><path d="m19.07 4.93-1.41 1.41"/></svg>
<svg aria-hidden="true" class="lucide lucide-moon hi-svg-inline theme-icon-dark" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M12 3a6 6 0 009 9 9 9 0 11-9-9z"/></svg></a></li><li class=mobile-menu-item><a class=menu-item-link href=https://cugbtang.github.io/index.xml rel="noopener alternate" type=application/rss+xml title=rss target=_blank><svg aria-hidden="true" class="lucide lucide-rss hi-svg-inline icon--rss" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></li></ul></nav></div></header><main id=main class="main pico container"><div class=content-wrapper><aside class=left-sidebar><nav class=toc id=toc><div class=toc-title>Table of Contents</div><div class="toc-content custom-scrollbar"><nav id=TableOfContents><ul><li><ul><li><a href=#-1-pretrain预训练>🌱 1. <strong>Pretrain（预训练）</strong></a></li><li><a href=#-2-sftsupervised-fine-tuning监督微调>👩‍🏫 2. <strong>SFT（Supervised Fine-Tuning，监督微调）</strong></a></li><li><a href=#-3-loralow-rank-adaptation低秩适配>🔧 3. <strong>LoRA（Low-Rank Adaptation，低秩适配）</strong></a></li><li><a href=#-4-rlhf-dporeinforcement-learning-from-human-feedback--direct-preference-optimization>🤖 4. <strong>RLHF-DPO（Reinforcement Learning from Human Feedback + Direct Preference Optimization）</strong></a></li><li><a href=#-5-rlaifreinforcement-learning-from-ai-feedback--ppo--grpo--spo>🤯 5. <strong>RLAIF（Reinforcement Learning from AI Feedback） + (PPO / GRPO / SPO)</strong></a></li><li><a href=#-6-模型蒸馏model-distillation>🫖 6. <strong>模型蒸馏（Model Distillation）</strong></a></li><li><a href=#-全流程比喻总结故事版>✅ 全流程比喻总结（故事版）：</a></li></ul></li></ul></nav></div></nav></aside><div id=content class=content><article class=post><header class=post-header><h1 class=post-title>从预训练到蒸馏：深入解析大语言模型训练全流程2</h1><div class=post-meta-list><div class="post-meta-item post-meta-author"><svg aria-hidden="true" class="lucide lucide-user-round-pen hi-svg-inline" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M2 21a8 8 0 0110.821-7.487"/><path d="M21.378 16.626a1 1 0 00-3.004-3.004l-4.01 4.012a2 2 0 00-.506.854l-.837 2.87a.5.5.0 00.62.62l2.87-.837a2 2 0 00.854-.506z"/><circle cx="10" cy="8" r="5"/></svg>
<a href=/about><span class=post-meta-author-name>yesplease</span></a></div><div class="post-meta-item post-meta-time"><svg aria-hidden="true" class="lucide lucide-calendar-days hi-svg-inline" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M8 2v4"/><path d="M16 2v4"/><rect width="18" height="18" x="3" y="4" rx="2"/><path d="M3 10h18"/><path d="M8 14h.01"/><path d="M12 14h.01"/><path d="M16 14h.01"/><path d="M8 18h.01"/><path d="M12 18h.01"/><path d="M16 18h.01"/></svg>
<time datetime=2025-12-23>2025-12-23</time></div><div class=post-meta__right><div class="post-meta-item post-meta-category"><a href=https://cugbtang.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/>人工智能</a>
<a href=https://cugbtang.github.io/categories/%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/>大语言模型</a>
<a href=https://cugbtang.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/>机器学习</a></div></div></div></header><div class=post-content><p>一整套大模型（如大语言模型）从零开始到最终部署优化的完整训练流程，包含了多个关键阶段和方法。下面我将逐一解释每个专业缩写，并用<strong>简单、形象的比喻</strong>帮助理解。</p><hr><h3 id=-1-pretrain预训练>🌱 1. <strong>Pretrain（预训练）</strong></h3><ul><li><p><strong>专业解释</strong>：<br>模型在大量无标注文本上进行自监督学习（比如预测下一个词），掌握语言的基本结构、常识和知识。</p></li><li><p><strong>比喻</strong>：<br>就像一个孩子从小大量阅读百科全书、小说、新闻……虽然没人教他“这是对是错”，但他慢慢学会了“语言怎么用”“世界大概什么样”。这是打基础的阶段。</p></li></ul><hr><h3 id=-2-sftsupervised-fine-tuning监督微调>👩‍🏫 2. <strong>SFT（Supervised Fine-Tuning，监督微调）</strong></h3><ul><li><p><strong>专业解释</strong>：<br>在预训练模型基础上，用少量高质量的人工标注数据（如问答对、指令-回答对）进行微调，让模型学会“按人类要求做事”。</p></li><li><p><strong>比喻</strong>：<br>孩子上了小学，老师给他示范：“别人问‘你好吗？’，你应该答‘我很好，谢谢！’而不是背唐诗。”——这是教他“听话”和“有礼貌”。</p></li></ul><hr><h3 id=-3-loralow-rank-adaptation低秩适配>🔧 3. <strong>LoRA（Low-Rank Adaptation，低秩适配）</strong></h3><ul><li><p><strong>专业解释</strong>：<br>一种高效微调技术：不修改原模型的大参数，而是在旁边加一个小的“插件”（低秩矩阵），只训练这个小插件，节省计算资源。</p></li><li><p><strong>比喻</strong>：<br>就像给一台老式收音机加一个外接蓝牙模块，不用拆开整个机器重做，就能让它支持新功能。便宜、快、不伤本体！</p></li></ul><hr><h3 id=-4-rlhf-dporeinforcement-learning-from-human-feedback--direct-preference-optimization>🤖 4. <strong>RLHF-DPO（Reinforcement Learning from Human Feedback + Direct Preference Optimization）</strong></h3><blockquote><p>注：严格来说，<strong>RLHF</strong> 和 <strong>DPO</strong> 是两种不同路线，但常被一起讨论。这里按常见理解拆解：</p></blockquote><h4 id=a-rlhf基于人类反馈的强化学习>a) <strong>RLHF（基于人类反馈的强化学习）</strong></h4><ul><li>用人类对模型输出的偏好（A 比 B 好）训练一个“奖励模型”，再用 PPO 等算法优化主模型。</li></ul><h4 id=b-dpodirect-preference-optimization直接偏好优化>b) <strong>DPO（Direct Preference Optimization，直接偏好优化）</strong></h4><ul><li><p>跳过奖励模型，直接用偏好数据优化策略，数学上更简洁高效。</p></li><li><p><strong>比喻（合起来）</strong>：<br>想象你在练习演讲：</p><ul><li><strong>RLHF</strong>：先请一群观众打分，训练一个“AI评委”；然后你根据 AI 评委的打分不断改进演讲（用 PPO）。</li><li><strong>DPO</strong>：观众直接说“版本 A 比 B 好”，你立刻调整自己，不再依赖中间评委，学得更快更直接。</li></ul></li></ul><hr><h3 id=-5-rlaifreinforcement-learning-from-ai-feedback--ppo--grpo--spo>🤯 5. <strong>RLAIF（Reinforcement Learning from AI Feedback） + (PPO / GRPO / SPO)</strong></h3><ul><li><p><strong>专业解释</strong>：<br>当人类反馈成本太高时，用另一个强大的 AI 模型（如 GPT-4）代替人类来提供偏好信号，再用 PPO、GRPO 或 SPO 等算法优化目标模型。</p><ul><li><strong>PPO</strong>：经典稳重型强化学习更新。</li><li><strong>GRPO</strong>：在一组多个回答中比较优劣，适合多选偏好。</li><li><strong>SPO（SimPO）</strong>：简化版偏好优化，直接拉大“好回答”和“差回答”的概率差距。</li></ul></li><li><p><strong>比喻</strong>：<br>你请不起真人导师，但你可以用“AI学霸”当助教。它帮你批改作业、指出哪篇作文更好。你根据它的意见反复修改——这就是 RLAIF。<br>而 PPO/GRPO/SPO 就是你采用的不同“学习策略”：</p><ul><li>PPO：每次只改一点点，怕改过头；</li><li>GRPO：一次交三篇作文，让 AI 排名，你重点学第一名；</li><li>SPO：AI 只说“这篇比那篇好”，你就拼命模仿好的那篇。</li></ul></li></ul><hr><h3 id=-6-模型蒸馏model-distillation>🫖 6. <strong>模型蒸馏（Model Distillation）</strong></h3><ul><li><p><strong>专业解释</strong>：<br>用一个大而强的“教师模型”生成高质量输出，让一个小而快的“学生模型”去模仿它，从而压缩模型体积、提升推理速度。</p></li><li><p><strong>比喻</strong>：<br>就像一位大师傅熬了一锅高汤，味道极其复杂。他让学生尝这锅汤，然后让学生试着用更少的材料、更快的时间，调出几乎一样的味道。最后学生做出的“简化版高汤”虽然没那么浓，但又快又便宜，还能上大众餐桌！</p></li></ul><hr><h3 id=-全流程比喻总结故事版>✅ 全流程比喻总结（故事版）：</h3><blockquote><p>一个 AI 模型的成长之路：</p><ol><li><strong>Pretrain</strong>：它小时候博览群书，成了“知识通”；</li><li><strong>SFT</strong>：上培训班，学会听指令、讲人话；</li><li><strong>LoRA</strong>：为了适应不同客户，它戴上可插拔的“技能耳环”，灵活切换角色；</li><li><strong>RLHF/DPO</strong>：找人类老师点评作业，越改越懂人心；</li><li><strong>RLAIF（PPO/GRPO/SPO）</strong>：人类太忙，就请 AI 助教代评，继续精进；</li><li><strong>模型蒸馏</strong>：最后，它把自己的毕生所学浓缩成一本“速成手册”，教出一个轻量级小徒弟，去服务千家万户。</li></ol></blockquote><hr><p>这套流程代表了当前大模型（如 Llama、Qwen、ChatGLM 等）从训练到落地的主流范式，兼顾效果、效率与可扩展性。</p></div><div class=post-copyright><p class=copyright-item><span class=item-title>Author</span>
<span class=item-content>yesplease</span></p><p class=copyright-item><span class=item-title>LastMod</span>
<span class=item-content>2025-12-23</span></p><p class=copyright-item><span class=item-title>License</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank>CC BY-NC-ND 4.0</a></span></p></div><footer class=post-footer><div class=post-tags><a href=https://cugbtang.github.io/tags/llm/>LLM</a>
<a href=https://cugbtang.github.io/tags/%E9%A2%84%E8%AE%AD%E7%BB%83/>预训练</a>
<a href=https://cugbtang.github.io/tags/%E5%BE%AE%E8%B0%83/>微调</a>
<a href=https://cugbtang.github.io/tags/rlhf/>RLHF</a>
<a href=https://cugbtang.github.io/tags/%E6%A8%A1%E5%9E%8B%E8%92%B8%E9%A6%8F/>模型蒸馏</a></div><nav class=post-nav><a class=prev href=/post/llm/llm-4/><i class=iconfont><svg aria-hidden="true" class="lucide lucide-chevron-left hi-svg-inline" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="m15 18-6-6 6-6"/></svg>
</i><span class="prev-text nav-default">从预训练到蒸馏：深入解析大语言模型训练全流程</span>
<span class="prev-text nav-mobile">Prev</span>
</a><a class=next href=/post/llm/llm-1/><span class="next-text nav-default">LLM发展关键术语：从"单词卡片"到"思维网络"</span>
<span class="prev-text nav-mobile">Next</span>
<i class=iconfont><svg aria-hidden="true" class="lucide lucide-chevron-right hi-svg-inline" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="m9 18 6-6-6-6"/></svg></i></a></nav></footer></article></div><aside class=right-sidebar></aside></div></main><footer id=footer class=site-footer><div class=social-icon-links><a href=mailto:cugbtang@sina.com rel="me noopener" class=social-icon-link title=email><svg aria-hidden="true" class="icon hi-svg-inline" fill="currentColor" height="1em" viewBox="0 0 1451 1024" width="1em" xlink="http://www.w3.org/1999/xlink"><path d="M664.781909 681.472759.0 97.881301C0 3.997201 71.046997.0 71.046997.0H474.477909 961.649408h399.992405s71.046998 3.997201 71.046998 97.881301L771.345323 681.472759S764.482731 685.154773 753.594283 688.65053V688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858V688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759zm53.281707 130.131124C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633.0 212.052267.0 212.052267V942.809523S0 1024 83.726336 1024H682.532949 753.579947h595.368192C1432.688811 1024 1432.688811 942.809523 1432.688811 942.809523V212.052267S893.138176 701.759633 817.019477 767.734955c-39.771477 34.470494-74.671786 43.295855-98.955861 43.868928z"/></svg>
</a><a href=https://github.com/cugbtang rel="me noopener" class=social-icon-link title=github target=_blank><svg aria-hidden="true" class="icon hi-svg-inline" fill="currentColor" height="1em" viewBox="0 0 1024 1024" width="1em" xlink="http://www.w3.org/1999/xlink"><path d="M512 12.672c-282.88.0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667.0-12.16-.426667-44.373333-.64-87.04C242.005334 929.664 211.968 830.08 211.968 830.08 188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333.0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333.0.0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667.0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72.0 68.522667-.64 123.562667-.64 140.202666.0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"/></svg>
</a><a href=https://cugbtang.github.io/index.xml rel="noopener alternate" type=application/rss+xml class=social-icon-link title=rss target=_blank><svg aria-hidden="true" class="lucide lucide-rss hi-svg-inline" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a>
</span><span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a>
</span><span class=copyright-year>&copy;
2017 -
2026
<span class=heart><i class=iconfont><svg aria-hidden="true" class="lucide lucide-heart hi-svg-inline" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M19 14c1.49-1.46 3-3.21 3-5.5A5.5 5.5.0 0016.5 3c-1.76.0-3 .5-4.5 2-1.5-1.5-2.74-2-4.5-2A5.5 5.5.0 002 8.5c0 2.3 1.5 4.05 3 5.5l7 7z"/></svg>
</i></span><span class=author>yesplease</span></span></div></footer><script type=text/javascript src=/js/main.002d1a80e7bd914cb4592a8c6486c23920f3d9827531bd1c79b3b5716dcf0bd5.js integrity="sha256-AC0agOe9kUy0WSqMZIbCOSDz2YJ1Mb0cebO1cW3PC9U=" crossorigin=anonymous></script><script type=text/javascript src=/lib/photoswipe/photoswipe.min.js></script><script type=text/javascript src=/lib/photoswipe/photoswipe-ui-default.min.js></script></body></html>