<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>kubeadm startup Kubernetes more than v1.20.0 (centos7+containerd+ipvs+calico) - ✌yesplease's blog</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=yes"><meta name=MobileOptimized content="width"><meta name=HandheldFriendly content="true"><meta name=applicable-device content="pc,mobile"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=mobile-web-app-capable content="yes"><meta name=author content="yesplease"><meta name=description content="这篇文章的作者部署的是kubernetes v1.23，但其实是基于kubernetes对CRI的改动执行的较为流行的方案。 我绝的主要是针对D"><meta name=keywords content="yesplease,blog,technology"><meta name=generator content="Hugo 0.101.0"><link rel=canonical href=http://cugbtang.github.io/post/kubernetes/series-kubernetes-3/><link rel=icon href=/favicon.ico><link rel=stylesheet href=/sass/jane.min.b3a8813c06e6d785beba22bf8264e174fa2cb3a396b22f9ba24e2c00c18aaf7f.css integrity="sha256-s6iBPAbm14W+uiK/gmThdPoss6OWsi+bok4sAMGKr38=" media=screen crossorigin=anonymous><meta property="og:title" content="kubeadm startup Kubernetes more than v1.20.0 (centos7+containerd+ipvs+calico)"><meta property="og:description" content="这篇文章的作者部署的是kubernetes v1.23，但其实是基于kubernetes对CRI的改动执行的较为流行的方案。 我绝的主要是针对D"><meta property="og:type" content="article"><meta property="og:url" content="http://cugbtang.github.io/post/kubernetes/series-kubernetes-3/"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-03-01T16:01:23+08:00"><meta property="article:modified_time" content="2022-03-01T16:01:23+08:00"><meta itemprop=name content="kubeadm startup Kubernetes more than v1.20.0 (centos7+containerd+ipvs+calico)"><meta itemprop=description content="这篇文章的作者部署的是kubernetes v1.23，但其实是基于kubernetes对CRI的改动执行的较为流行的方案。 我绝的主要是针对D"><meta itemprop=datePublished content="2022-03-01T16:01:23+08:00"><meta itemprop=dateModified content="2022-03-01T16:01:23+08:00"><meta itemprop=wordCount content="7002"><meta itemprop=keywords content="kubernetes,kubeadm,deploy,"><meta name=twitter:card content="summary"><meta name=twitter:title content="kubeadm startup Kubernetes more than v1.20.0 (centos7+containerd+ipvs+calico)"><meta name=twitter:description content="这篇文章的作者部署的是kubernetes v1.23，但其实是基于kubernetes对CRI的改动执行的较为流行的方案。 我绝的主要是针对D"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script>
<script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>yesplease</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=http://cugbtang.github.io/>This is Home</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://cugbtang.github.io/post/>Archives</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://cugbtang.github.io/tags/>Tags</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://cugbtang.github.io/categories/>Categories</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://cugbtang.github.io/about/>About</a></li><li class=mobile-menu-item><a class=menu-item-link href=https://github.com/cugbtang rel=noopener target=_blank>github
<i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M623.36 272.96 473.216 423.04C467.2 429.056 467.072 438.656 472.896 444.416c0 0-6.72-6.656 1.6 1.6 21.568 21.632 54.144 54.208 54.144 54.208C534.464 506.048 544 505.856 550.016 499.904l150.08-150.144 67.328 66.432c9.024 8.96 27.456 4.544 30.4-8.96 19.968-92.608 46.656-227.52 46.656-227.52 6.848-34.496-16.192-56.704-49.92-49.92.0.0-134.656 26.816-227.328 46.784C560.32 178.048 556.352 182.272 554.752 187.136c-3.2 6.208-3.008 14.208 3.776 20.992L623.36 272.96z"/><path d="M841.152 457.152c-30.528.0-54.784 24.512-54.784 54.656V786.56H237.696V237.696h206.016c6.656.0 10.752.0 13.248.0 30.72.0 55.04-24.512 55.04-54.848C512 152.32 487.36 128 456.96 128H183.04C153.216 128 128 152.576 128 182.848c0 3.136.256 6.272.768 9.28C128.256 195.136 128 198.272 128 201.408v639.488c0 .064.0.192.0.256.0.128.0.192.0.32.0 30.528 24.512 54.784 54.784 54.784H829.76c6.592.0 9.728.0 11.712.0 28.736.0 52.928-22.976 54.464-51.968C896 843.264 896 842.304 896 841.344v-20.352V561.408v-49.28C896 481.792 871.424 457.152 841.152 457.152z"/></svg></i></a></li></ul></nav><link rel=stylesheet href=/lib/photoswipe/photoswipe.min.css><link rel=stylesheet href=/lib/photoswipe/default-skin/default-skin.min.css><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)"></button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><header id=header class="header container"><div class=logo-wrapper><a href=/ class=logo>yesplease</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=http://cugbtang.github.io/>This is Home</a></li><li class=menu-item><a class=menu-item-link href=http://cugbtang.github.io/post/>Archives</a></li><li class=menu-item><a class=menu-item-link href=http://cugbtang.github.io/tags/>Tags</a></li><li class=menu-item><a class=menu-item-link href=http://cugbtang.github.io/categories/>Categories</a></li><li class=menu-item><a class=menu-item-link href=http://cugbtang.github.io/about/>About</a></li><li class=menu-item><a class=menu-item-link href=https://github.com/cugbtang rel=noopener target=_blank>github
<i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M623.36 272.96 473.216 423.04C467.2 429.056 467.072 438.656 472.896 444.416c0 0-6.72-6.656 1.6 1.6 21.568 21.632 54.144 54.208 54.144 54.208C534.464 506.048 544 505.856 550.016 499.904l150.08-150.144 67.328 66.432c9.024 8.96 27.456 4.544 30.4-8.96 19.968-92.608 46.656-227.52 46.656-227.52 6.848-34.496-16.192-56.704-49.92-49.92.0.0-134.656 26.816-227.328 46.784C560.32 178.048 556.352 182.272 554.752 187.136c-3.2 6.208-3.008 14.208 3.776 20.992L623.36 272.96z"/><path d="M841.152 457.152c-30.528.0-54.784 24.512-54.784 54.656V786.56H237.696V237.696h206.016c6.656.0 10.752.0 13.248.0 30.72.0 55.04-24.512 55.04-54.848C512 152.32 487.36 128 456.96 128H183.04C153.216 128 128 152.576 128 182.848c0 3.136.256 6.272.768 9.28C128.256 195.136 128 198.272 128 201.408v639.488c0 .064.0.192.0.256.0.128.0.192.0.32.0 30.528 24.512 54.784 54.784 54.784H829.76c6.592.0 9.728.0 11.712.0 28.736.0 52.928-22.976 54.464-51.968C896 843.264 896 842.304 896 841.344v-20.352V561.408v-49.28C896 481.792 871.424 457.152 841.152 457.152z"/></svg></i></a></li></ul></nav></header><div id=mobile-panel><main id=main class="main bg-llight"><div class=content-wrapper><div id=content class="content container"><article class="post bg-white"><header class=post-header><h1 class=post-title>kubeadm startup Kubernetes more than v1.20.0 (centos7+containerd+ipvs+calico)</h1><div class=post-meta><time datetime=2022-03-01 class=post-time>2022-03-01</time><div class=post-category><a href=http://cugbtang.github.io/categories/kubernetes/>kubernetes</a>
<a href=http://cugbtang.github.io/categories/cloudnative/>cloudnative</a></div><span class=more-meta>7002 words</span>
<span class=more-meta>14 min read</span></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>Table of Contents</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#1准备>1.准备</a><ul><li><a href=#11-系统配置>1.1 系统配置</a></li><li><a href=#12-部署容器运行时containerd>1.2 部署容器运行时Containerd</a></li></ul></li><li><a href=#2使用kubeadm部署kubernetes>2.使用kubeadm部署Kubernetes</a><ul><li><a href=#21-安装kubeadm和kubelet>2.1 安装kubeadm和kubelet</a></li><li><a href=#22-使用kubeadm-init初始化集群>2.2 使用kubeadm init初始化集群</a></li><li><a href=#23-安装包管理器helm-3>2.3 安装包管理器helm 3</a></li><li><a href=#24-部署pod-network组件calico>2.4 部署Pod Network组件Calico</a></li><li><a href=#25-验证k8s-dns是否可用>2.5 验证k8s DNS是否可用</a></li><li><a href=#26-向kubernetes集群中添加node节点>2.6 向Kubernetes集群中添加Node节点</a></li></ul></li><li><a href=#3kubernetes常用组件部署>3.Kubernetes常用组件部署</a><ul><li><a href=#31-使用helm部署ingress-nginx>3.1 使用Helm部署ingress-nginx</a></li><li><a href=#32-使用helm部署dashboard>3.2 使用Helm部署dashboard</a></li></ul></li><li><a href=#faq>FAQ</a></li><li><a href=#参考>参考</a></li></ul></nav></div></div><div class=post-content><p>这篇文章的作者部署的是kubernetes v1.23，但其实是基于kubernetes对CRI的改动执行的较为流行的方案。</p><p>我绝的主要是针对Docker的支持问题，因为在1.24中才正式将docker-shim剔除。以下列举了较为流行的部署方案：</p><ul><li><p>kubernetes &lt; 1.20 + centos7 + docker + iptables + flannel</p></li><li><p>kubernetes &lt; 1.20 + centos7 + docker + ipvs + calico</p></li><li><p>1.20 &lt;kubernetes &lt; 1.24 + centos7 + docker + ipvs + calico</p></li><li><p>kubernetes > 1.24 + centos7 + containerd + ipvs + calico</p></li><li><p>kubernetes > 1.24 + centos7 + cri-o + ipvs + calico</p></li><li><p>kubernetes > 1.24 + centos7 + cri-dockerd + docker + ipvs + calico</p></li></ul><p><a href=https://blog.frognew.com/2021/12/kubeadm-install-kubernetes-1.23.html#1%E5%87%86%E5%A4%87>转载声明：使用kubeadm部署Kubernetes 1.23</a></p><p>kubeadm是Kubernetes官方提供的用于快速安部署Kubernetes集群的工具，伴随Kubernetes每个版本的发布都会同步更新，kubeadm会对集群配置方面的一些实践做调整，通过实验kubeadm可以学习到Kubernetes官方在集群配置上一些新的最佳实践。</p><h2 id=1准备>1.准备</h2><h3 id=11-系统配置>1.1 系统配置</h3><p>在安装之前，需要先做好如下准备。3台CentOS 7.9主机如下：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>cat /etc/hosts
</span></span><span class=line><span class=cl>192.168.96.151    node1
</span></span><span class=line><span class=cl>192.168.96.152    node2
</span></span><span class=line><span class=cl>192.168.96.153    node3
</span></span></code></pre></td></tr></table></div></div><p>在<strong>各个主机</strong>上完成下面的系统配置。</p><ul><li>yum:</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=c1>#备份本地 yum 源</span>
</span></span><span class=line><span class=cl>$ mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo_bak 
</span></span><span class=line><span class=cl><span class=c1># 获取阿里 yum 源配置文件</span>
</span></span><span class=line><span class=cl>$ wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 
</span></span><span class=line><span class=cl><span class=c1>#清理 yum</span>
</span></span><span class=line><span class=cl>$ yum clean all
</span></span><span class=line><span class=cl><span class=c1>#更新软件版本并且更新现有软件</span>
</span></span><span class=line><span class=cl>$ yum -y update
</span></span></code></pre></td></tr></table></div></div><ul><li>防火墙：</li></ul><p>如果各个主机启用了防火墙策略，需要开放Kubernetes各个组件所需要的端口，可以查看<a href=https://kubernetes.io/docs/setup/independent/install-kubeadm/>Installing kubeadm</a>中的"Check required ports"一节开放相关端口或者关闭主机的防火墙。</p><ul><li>禁用SELINUX：</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>setenforce <span class=m>0</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>vi /etc/selinux/config
</span></span><span class=line><span class=cl><span class=nv>SELINUX</span><span class=o>=</span>disabled
</span></span></code></pre></td></tr></table></div></div><ul><li>加载需要的内核模块</li></ul><p>创建/etc/modules-load.d/containerd.conf配置文件:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>cat <span class=s>&lt;&lt; EOF &gt; /etc/modules-load.d/containerd.conf
</span></span></span><span class=line><span class=cl><span class=s>overlay
</span></span></span><span class=line><span class=cl><span class=s>br_netfilter
</span></span></span><span class=line><span class=cl><span class=s>EOF</span>
</span></span></code></pre></td></tr></table></div></div><p>执行以下命令使配置生效:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>modprobe overlay
</span></span><span class=line><span class=cl>modprobe br_netfilter
</span></span></code></pre></td></tr></table></div></div><p>创建/etc/sysctl.d/99-kubernetes-cri.conf配置文件：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>cat <span class=s>&lt;&lt; EOF &gt; /etc/sysctl.d/99-kubernetes-cri.conf
</span></span></span><span class=line><span class=cl><span class=s>net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span class=line><span class=cl><span class=s>net.bridge.bridge-nf-call-iptables = 1
</span></span></span><span class=line><span class=cl><span class=s>net.ipv4.ip_forward = 1
</span></span></span><span class=line><span class=cl><span class=s>user.max_user_namespaces=28633
</span></span></span><span class=line><span class=cl><span class=s>EOF</span>
</span></span></code></pre></td></tr></table></div></div><p>执行以下命令使配置生效:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>sysctl -p /etc/sysctl.d/99-kubernetes-cri.conf
</span></span></code></pre></td></tr></table></div></div><ul><li>配置服务器支持开启ipvs的前提条件</li></ul><p>由于ipvs已经加入到了内核的主干，所以为kube-proxy开启ipvs的前提需要加载以下的内核模块：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>ip_vs
</span></span><span class=line><span class=cl>ip_vs_rr
</span></span><span class=line><span class=cl>ip_vs_wrr
</span></span><span class=line><span class=cl>ip_vs_sh
</span></span><span class=line><span class=cl>nf_conntrack_ipv4 
</span></span></code></pre></td></tr></table></div></div><p>在各个服务器节点上执行以下脚本:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span><span class=lnt>9
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>cat &gt; /etc/sysconfig/modules/ipvs.modules <span class=s>&lt;&lt;EOF
</span></span></span><span class=line><span class=cl><span class=s>#!/bin/bash
</span></span></span><span class=line><span class=cl><span class=s>modprobe -- ip_vs
</span></span></span><span class=line><span class=cl><span class=s>modprobe -- ip_vs_rr
</span></span></span><span class=line><span class=cl><span class=s>modprobe -- ip_vs_wrr
</span></span></span><span class=line><span class=cl><span class=s>modprobe -- ip_vs_sh
</span></span></span><span class=line><span class=cl><span class=s>modprobe -- nf_conntrack_ipv4
</span></span></span><span class=line><span class=cl><span class=s>EOF</span>
</span></span><span class=line><span class=cl>chmod <span class=m>755</span> /etc/sysconfig/modules/ipvs.modules <span class=o>&amp;&amp;</span> bash /etc/sysconfig/modules/ipvs.modules <span class=o>&amp;&amp;</span> lsmod <span class=p>|</span> grep -e ip_vs -e nf_conntrack_ipv4
</span></span></code></pre></td></tr></table></div></div><blockquote><p>注：内核4版本以上 nf_conntrack 替换 nf_conntrack_ipv4</p></blockquote><p>上面脚本创建了的<code>/etc/sysconfig/modules/ipvs.modules</code>文件，保证在节点重启后能自动加载所需模块。 使用<code>lsmod | grep -e ip_vs -e nf_conntrack_ipv4</code>命令查看是否已经正确加载所需的内核模块。</p><p>接下来还需要确保各个节点上已经安装了ipset软件包，为了便于查看ipvs的代理规则，最好安装一下管理工具ipvsadm。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>yum install -y ipset ipvsadm
</span></span></code></pre></td></tr></table></div></div><p>如果以上前提条件如果不满足，则即使kube-proxy的配置开启了ipvs模式，也会退回到iptables模式。</p><h3 id=12-部署容器运行时containerd>1.2 部署容器运行时Containerd</h3><p>在各个服务器节点上安装容器运行时Containerd。</p><p>下载Containerd的二进制包:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>wget https://github.com/containerd/containerd/releases/download/v1.5.8/cri-containerd-cni-1.5.8-linux-amd64.tar.gz
</span></span></code></pre></td></tr></table></div></div><p><code>cri-containerd-cni-1.5.8-linux-amd64.tar.gz</code>压缩包中已经按照官方二进制部署推荐的目录结构布局好。 里面包含了systemd配置文件，containerd以及cni的部署文件。 将解压缩到系统的根目录<code>/</code>中:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>tar -zxvf cri-containerd-cni-1.5.8-linux-amd64.tar.gz -C /
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>etc/
</span></span><span class=line><span class=cl>etc/systemd/
</span></span><span class=line><span class=cl>etc/systemd/system/
</span></span><span class=line><span class=cl>etc/systemd/system/containerd.service
</span></span><span class=line><span class=cl>etc/crictl.yaml
</span></span><span class=line><span class=cl>etc/cni/
</span></span><span class=line><span class=cl>etc/cni/net.d/
</span></span><span class=line><span class=cl>etc/cni/net.d/10-containerd-net.conflist
</span></span><span class=line><span class=cl>usr/
</span></span><span class=line><span class=cl>usr/local/
</span></span><span class=line><span class=cl>usr/local/sbin/
</span></span><span class=line><span class=cl>usr/local/sbin/runc
</span></span><span class=line><span class=cl>usr/local/bin/
</span></span><span class=line><span class=cl>usr/local/bin/critest
</span></span><span class=line><span class=cl>usr/local/bin/containerd-shim
</span></span><span class=line><span class=cl>usr/local/bin/containerd-shim-runc-v1
</span></span><span class=line><span class=cl>usr/local/bin/ctd-decoder
</span></span><span class=line><span class=cl>usr/local/bin/containerd
</span></span><span class=line><span class=cl>usr/local/bin/containerd-shim-runc-v2
</span></span><span class=line><span class=cl>usr/local/bin/containerd-stress
</span></span><span class=line><span class=cl>usr/local/bin/ctr
</span></span><span class=line><span class=cl>usr/local/bin/crictl
</span></span><span class=line><span class=cl>......
</span></span><span class=line><span class=cl>opt/cni/
</span></span><span class=line><span class=cl>opt/cni/bin/
</span></span><span class=line><span class=cl>opt/cni/bin/bridge
</span></span><span class=line><span class=cl>......
</span></span></code></pre></td></tr></table></div></div><p>注意经测试cri-containerd-cni-1.5.8-linux-amd64.tar.gz包中包含的runc在CentOS 7下的动态链接有问题，这里从runc的github上单独下载runc，并替换上面安装的containerd中的runc</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>wget https://github.com/opencontainers/runc/releases/download/v1.1.0-rc.1/runc.amd64
</span></span></code></pre></td></tr></table></div></div><p>接下来生成containerd的配置文件:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>mkdir -p /etc/containerd
</span></span><span class=line><span class=cl>containerd config default &gt; /etc/containerd/config.toml
</span></span></code></pre></td></tr></table></div></div><p>根据文档<a href=https://kubernetes.io/docs/setup/production-environment/container-runtimes/>Container runtimes </a>中的内容，对于使用systemd作为init system的Linux的发行版，使用systemd作为容器的cgroup driver可以确保服务器节点在资源紧张的情况更加稳定，因此这里配置各个节点上containerd的cgroup driver为systemd。</p><p>修改前面生成的配置文件<code>/etc/containerd/config.toml</code>：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=o>[</span>plugins.<span class=s2>&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.runc<span class=o>]</span>
</span></span><span class=line><span class=cl>  ...
</span></span><span class=line><span class=cl>  <span class=o>[</span>plugins.<span class=s2>&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.runc.options<span class=o>]</span>
</span></span><span class=line><span class=cl>    <span class=nv>SystemdCgroup</span> <span class=o>=</span> <span class=nb>true</span>
</span></span></code></pre></td></tr></table></div></div><p>再修改<code>/etc/containerd/config.toml</code>中的</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=o>[</span>plugins.<span class=s2>&#34;io.containerd.grpc.v1.cri&#34;</span><span class=o>]</span>
</span></span><span class=line><span class=cl>  ...
</span></span><span class=line><span class=cl>  <span class=c1># sandbox_image = &#34;k8s.gcr.io/pause:3.5&#34;</span>
</span></span><span class=line><span class=cl>  <span class=nv>sandbox_image</span> <span class=o>=</span> <span class=s2>&#34;registry.aliyuncs.com/google_containers/pause:3.6&#34;</span>
</span></span></code></pre></td></tr></table></div></div><p>配置containerd开机启动，并启动containerd</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>systemctl <span class=nb>enable</span> containerd --now
</span></span></code></pre></td></tr></table></div></div><p>使用crictl测试一下，确保可以打印出版本信息并且没有错误信息输出:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>crictl version
</span></span><span class=line><span class=cl>Version:  0.1.0
</span></span><span class=line><span class=cl>RuntimeName:  containerd
</span></span><span class=line><span class=cl>RuntimeVersion:  v1.5.8
</span></span><span class=line><span class=cl>RuntimeApiVersion:  v1alpha2
</span></span></code></pre></td></tr></table></div></div><h2 id=2使用kubeadm部署kubernetes>2.使用kubeadm部署Kubernetes</h2><h3 id=21-安装kubeadm和kubelet>2.1 安装kubeadm和kubelet</h3><p>下面在各节点安装kubeadm和kubelet：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>cat <span class=s>&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span class=line><span class=cl><span class=s>[kubernetes]
</span></span></span><span class=line><span class=cl><span class=s>name=Kubernetes
</span></span></span><span class=line><span class=cl><span class=s>baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
</span></span></span><span class=line><span class=cl><span class=s>enabled=1
</span></span></span><span class=line><span class=cl><span class=s>gpgcheck=1
</span></span></span><span class=line><span class=cl><span class=s>repo_gpgcheck=1
</span></span></span><span class=line><span class=cl><span class=s>gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg
</span></span></span><span class=line><span class=cl><span class=s>        http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
</span></span></span><span class=line><span class=cl><span class=s>EOF</span>
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>yum makecache fast
</span></span><span class=line><span class=cl>yum install kubelet kubeadm kubectl
</span></span></code></pre></td></tr></table></div></div><p>运行<code>kubelet --help</code>可以看到原来kubelet的绝大多数命令行flag参数都被<code>DEPRECATED</code>了，官方推荐我们使用<code>--config</code>指定配置文件，并在配置文件中指定原来这些flag所配置的内容。具体内容可以查看这里<a href=https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/>Set Kubelet parameters via a config file</a>。这也是Kubernetes为了支持动态Kubelet配置（Dynamic Kubelet Configuration）才这么做的，参考<a href=https://kubernetes.io/docs/tasks/administer-cluster/reconfigure-kubelet/>Reconfigure a Node’s Kubelet in a Live Cluster</a>。</p><p>kubelet的配置文件必须是json或yaml格式，具体可查看<a href=https://github.com/kubernetes/kubelet/blob/release-1.23/config/v1beta1/types.go>这里</a>。</p><p>Kubernetes 1.8开始要求关闭系统的Swap，如果不关闭，默认配置下kubelet将无法启动。 关闭系统的Swap方法如下:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>swapoff -a
</span></span></code></pre></td></tr></table></div></div><p>修改 /etc/fstab 文件，注释掉 SWAP 的自动挂载，使用<code>free -m</code>确认swap已经关闭。</p><p>swappiness参数调整，修改/etc/sysctl.d/99-kubernetes-cri.conf添加下面一行：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>vm.swappiness<span class=o>=</span><span class=m>0</span>
</span></span></code></pre></td></tr></table></div></div><p>执行<code>sysctl -p /etc/sysctl.d/99-kubernetes-cri.conf</code>使修改生效。</p><h3 id=22-使用kubeadm-init初始化集群>2.2 使用kubeadm init初始化集群</h3><p>在各节点开机启动kubelet服务：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>systemctl <span class=nb>enable</span> kubelet.service
</span></span></code></pre></td></tr></table></div></div><p>使用<code>kubeadm config print init-defaults --component-configs KubeletConfiguration</code>可以打印集群初始化默认的使用的配置：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span><span class=lnt>74
</span><span class=lnt>75
</span><span class=lnt>76
</span><span class=lnt>77
</span><span class=lnt>78
</span><span class=lnt>79
</span><span class=lnt>80
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>apiVersion: kubeadm.k8s.io/v1beta3
</span></span><span class=line><span class=cl>bootstrapTokens:
</span></span><span class=line><span class=cl>- groups:
</span></span><span class=line><span class=cl>  - system:bootstrappers:kubeadm:default-node-token
</span></span><span class=line><span class=cl>  token: abcdef.0123456789abcdef
</span></span><span class=line><span class=cl>  ttl: 24h0m0s
</span></span><span class=line><span class=cl>  usages:
</span></span><span class=line><span class=cl>  - signing
</span></span><span class=line><span class=cl>  - authentication
</span></span><span class=line><span class=cl>kind: InitConfiguration
</span></span><span class=line><span class=cl>localAPIEndpoint:
</span></span><span class=line><span class=cl>  advertiseAddress: 1.2.3.4
</span></span><span class=line><span class=cl>  bindPort: <span class=m>6443</span>
</span></span><span class=line><span class=cl>nodeRegistration:
</span></span><span class=line><span class=cl>  criSocket: /var/run/dockershim.sock
</span></span><span class=line><span class=cl>  imagePullPolicy: IfNotPresent
</span></span><span class=line><span class=cl>  name: node
</span></span><span class=line><span class=cl>  taints: null
</span></span><span class=line><span class=cl>---
</span></span><span class=line><span class=cl>apiServer:
</span></span><span class=line><span class=cl>  timeoutForControlPlane: 4m0s
</span></span><span class=line><span class=cl>apiVersion: kubeadm.k8s.io/v1beta3
</span></span><span class=line><span class=cl>certificatesDir: /etc/kubernetes/pki
</span></span><span class=line><span class=cl>clusterName: kubernetes
</span></span><span class=line><span class=cl>controllerManager: <span class=o>{}</span>
</span></span><span class=line><span class=cl>dns: <span class=o>{}</span>
</span></span><span class=line><span class=cl>etcd:
</span></span><span class=line><span class=cl>  local:
</span></span><span class=line><span class=cl>    dataDir: /var/lib/etcd
</span></span><span class=line><span class=cl>imageRepository: k8s.gcr.io
</span></span><span class=line><span class=cl>kind: ClusterConfiguration
</span></span><span class=line><span class=cl>kubernetesVersion: 1.23.0
</span></span><span class=line><span class=cl>networking:
</span></span><span class=line><span class=cl>  dnsDomain: cluster.local
</span></span><span class=line><span class=cl>  serviceSubnet: 10.96.0.0/12
</span></span><span class=line><span class=cl>scheduler: <span class=o>{}</span>
</span></span><span class=line><span class=cl>---
</span></span><span class=line><span class=cl>apiVersion: kubelet.config.k8s.io/v1beta1
</span></span><span class=line><span class=cl>authentication:
</span></span><span class=line><span class=cl>  anonymous:
</span></span><span class=line><span class=cl>    enabled: <span class=nb>false</span>
</span></span><span class=line><span class=cl>  webhook:
</span></span><span class=line><span class=cl>    cacheTTL: 0s
</span></span><span class=line><span class=cl>    enabled: <span class=nb>true</span>
</span></span><span class=line><span class=cl>  x509:
</span></span><span class=line><span class=cl>    clientCAFile: /etc/kubernetes/pki/ca.crt
</span></span><span class=line><span class=cl>authorization:
</span></span><span class=line><span class=cl>  mode: Webhook
</span></span><span class=line><span class=cl>  webhook:
</span></span><span class=line><span class=cl>    cacheAuthorizedTTL: 0s
</span></span><span class=line><span class=cl>    cacheUnauthorizedTTL: 0s
</span></span><span class=line><span class=cl>cgroupDriver: systemd
</span></span><span class=line><span class=cl>clusterDNS:
</span></span><span class=line><span class=cl>- 10.96.0.10
</span></span><span class=line><span class=cl>clusterDomain: cluster.local
</span></span><span class=line><span class=cl>cpuManagerReconcilePeriod: 0s
</span></span><span class=line><span class=cl>evictionPressureTransitionPeriod: 0s
</span></span><span class=line><span class=cl>fileCheckFrequency: 0s
</span></span><span class=line><span class=cl>healthzBindAddress: 127.0.0.1
</span></span><span class=line><span class=cl>healthzPort: <span class=m>10248</span>
</span></span><span class=line><span class=cl>httpCheckFrequency: 0s
</span></span><span class=line><span class=cl>imageMinimumGCAge: 0s
</span></span><span class=line><span class=cl>kind: KubeletConfiguration
</span></span><span class=line><span class=cl>logging:
</span></span><span class=line><span class=cl>  flushFrequency: <span class=m>0</span>
</span></span><span class=line><span class=cl>  options:
</span></span><span class=line><span class=cl>    json:
</span></span><span class=line><span class=cl>      infoBufferSize: <span class=s2>&#34;0&#34;</span>
</span></span><span class=line><span class=cl>  verbosity: <span class=m>0</span>
</span></span><span class=line><span class=cl>memorySwap: <span class=o>{}</span>
</span></span><span class=line><span class=cl>nodeStatusReportFrequency: 0s
</span></span><span class=line><span class=cl>nodeStatusUpdateFrequency: 0s
</span></span><span class=line><span class=cl>rotateCertificates: <span class=nb>true</span>
</span></span><span class=line><span class=cl>runtimeRequestTimeout: 0s
</span></span><span class=line><span class=cl>shutdownGracePeriod: 0s
</span></span><span class=line><span class=cl>shutdownGracePeriodCriticalPods: 0s
</span></span><span class=line><span class=cl>staticPodPath: /etc/kubernetes/manifests
</span></span><span class=line><span class=cl>streamingConnectionIdleTimeout: 0s
</span></span><span class=line><span class=cl>syncFrequency: 0s
</span></span><span class=line><span class=cl>volumeStatsAggPeriod: 0s
</span></span></code></pre></td></tr></table></div></div><p>从默认的配置中可以看到，可以使用<code>imageRepository</code>定制在集群初始化时拉取k8s所需镜像的地址。基于默认配置定制出本次使用kubeadm初始化集群所需的配置文件kubeadm.yaml：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>apiVersion: kubeadm.k8s.io/v1beta3
</span></span><span class=line><span class=cl>kind: InitConfiguration
</span></span><span class=line><span class=cl>localAPIEndpoint:
</span></span><span class=line><span class=cl>  advertiseAddress: 192.168.96.151
</span></span><span class=line><span class=cl>  bindPort: <span class=m>6443</span>
</span></span><span class=line><span class=cl>nodeRegistration:
</span></span><span class=line><span class=cl>  criSocket: /run/containerd/containerd.sock
</span></span><span class=line><span class=cl>  taints:
</span></span><span class=line><span class=cl>  - effect: PreferNoSchedule
</span></span><span class=line><span class=cl>    key: node-role.kubernetes.io/master
</span></span><span class=line><span class=cl>---
</span></span><span class=line><span class=cl>apiVersion: kubeadm.k8s.io/v1beta2
</span></span><span class=line><span class=cl>kind: ClusterConfiguration
</span></span><span class=line><span class=cl>kubernetesVersion: v1.22.0
</span></span><span class=line><span class=cl>imageRepository: registry.aliyuncs.com/google_containers
</span></span><span class=line><span class=cl>networking:
</span></span><span class=line><span class=cl>  podSubnet: 10.244.0.0/16
</span></span><span class=line><span class=cl>---
</span></span><span class=line><span class=cl>apiVersion: kubelet.config.k8s.io/v1beta1
</span></span><span class=line><span class=cl>kind: KubeletConfiguration
</span></span><span class=line><span class=cl>cgroupDriver: systemd
</span></span><span class=line><span class=cl>failSwapOn: <span class=nb>false</span>
</span></span><span class=line><span class=cl>---
</span></span><span class=line><span class=cl>apiVersion: kubeproxy.config.k8s.io/v1alpha1
</span></span><span class=line><span class=cl>kind: KubeProxyConfiguration
</span></span><span class=line><span class=cl>mode: ipvs
</span></span></code></pre></td></tr></table></div></div><p>这里定制了<code>imageRepository</code>为阿里云的registry，避免因gcr被墙，无法直接拉取镜像。<code>criSocket</code>设置了容器运行时为containerd。 同时设置kubelet的<code>cgroupDriver</code>为systemd，设置kube-proxy代理模式为ipvs。</p><p>在开始初始化集群之前可以使用<code>kubeadm config images pull --config kubeadm.yaml</code>预先在各个服务器节点上拉取所k8s需要的容器镜像。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span><span class=lnt>8
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>kubeadm config images pull --config kubeadm.yaml
</span></span><span class=line><span class=cl><span class=o>[</span>config/images<span class=o>]</span> Pulled registry.aliyuncs.com/google_containers/kube-apiserver:v1.23.1
</span></span><span class=line><span class=cl><span class=o>[</span>config/images<span class=o>]</span> Pulled registry.aliyuncs.com/google_containers/kube-controller-manager:v1.23.1
</span></span><span class=line><span class=cl><span class=o>[</span>config/images<span class=o>]</span> Pulled registry.aliyuncs.com/google_containers/kube-scheduler:v1.23.1
</span></span><span class=line><span class=cl><span class=o>[</span>config/images<span class=o>]</span> Pulled registry.aliyuncs.com/google_containers/kube-proxy:v1.23.1
</span></span><span class=line><span class=cl><span class=o>[</span>config/images<span class=o>]</span> Pulled registry.aliyuncs.com/google_containers/pause:3.6
</span></span><span class=line><span class=cl><span class=o>[</span>config/images<span class=o>]</span> Pulled registry.aliyuncs.com/google_containers/etcd:3.5.1-0
</span></span><span class=line><span class=cl><span class=o>[</span>config/images<span class=o>]</span> Pulled registry.aliyuncs.com/google_containers/coredns:v1.8.6
</span></span></code></pre></td></tr></table></div></div><p>接下来使用kubeadm初始化集群，选择node1作为Master Node，在node1上执行下面的命令：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span><span class=lnt>42
</span><span class=lnt>43
</span><span class=lnt>44
</span><span class=lnt>45
</span><span class=lnt>46
</span><span class=lnt>47
</span><span class=lnt>48
</span><span class=lnt>49
</span><span class=lnt>50
</span><span class=lnt>51
</span><span class=lnt>52
</span><span class=lnt>53
</span><span class=lnt>54
</span><span class=lnt>55
</span><span class=lnt>56
</span><span class=lnt>57
</span><span class=lnt>58
</span><span class=lnt>59
</span><span class=lnt>60
</span><span class=lnt>61
</span><span class=lnt>62
</span><span class=lnt>63
</span><span class=lnt>64
</span><span class=lnt>65
</span><span class=lnt>66
</span><span class=lnt>67
</span><span class=lnt>68
</span><span class=lnt>69
</span><span class=lnt>70
</span><span class=lnt>71
</span><span class=lnt>72
</span><span class=lnt>73
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>kubeadm init --config kubeadm.yaml
</span></span><span class=line><span class=cl><span class=o>[</span>init<span class=o>]</span> Using Kubernetes version: v1.23.1
</span></span><span class=line><span class=cl><span class=o>[</span>preflight<span class=o>]</span> Running pre-flight checks
</span></span><span class=line><span class=cl><span class=o>[</span>preflight<span class=o>]</span> Pulling images required <span class=k>for</span> setting up a Kubernetes cluster
</span></span><span class=line><span class=cl><span class=o>[</span>preflight<span class=o>]</span> This might take a minute or two, depending on the speed of your internet connection
</span></span><span class=line><span class=cl><span class=o>[</span>preflight<span class=o>]</span> You can also perform this action in beforehand using <span class=s1>&#39;kubeadm config images pull&#39;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Using certificateDir folder <span class=s2>&#34;/etc/kubernetes/pki&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;ca&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;apiserver&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> apiserver serving cert is signed <span class=k>for</span> DNS names <span class=o>[</span>kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local node1<span class=o>]</span> and IPs <span class=o>[</span>10.96.0.1 192.168.96.151<span class=o>]</span>
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;apiserver-kubelet-client&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;front-proxy-ca&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;front-proxy-client&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;etcd/ca&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;etcd/server&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> etcd/server serving cert is signed <span class=k>for</span> DNS names <span class=o>[</span>localhost node1<span class=o>]</span> and IPs <span class=o>[</span>192.168.96.151 127.0.0.1 ::1<span class=o>]</span>
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;etcd/peer&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> etcd/peer serving cert is signed <span class=k>for</span> DNS names <span class=o>[</span>localhost node1<span class=o>]</span> and IPs <span class=o>[</span>192.168.96.151 127.0.0.1 ::1<span class=o>]</span>
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;etcd/healthcheck-client&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;apiserver-etcd-client&#34;</span> certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>certs<span class=o>]</span> Generating <span class=s2>&#34;sa&#34;</span> key and public key
</span></span><span class=line><span class=cl><span class=o>[</span>kubeconfig<span class=o>]</span> Using kubeconfig folder <span class=s2>&#34;/etc/kubernetes&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>kubeconfig<span class=o>]</span> Writing <span class=s2>&#34;admin.conf&#34;</span> kubeconfig file
</span></span><span class=line><span class=cl><span class=o>[</span>kubeconfig<span class=o>]</span> Writing <span class=s2>&#34;kubelet.conf&#34;</span> kubeconfig file
</span></span><span class=line><span class=cl><span class=o>[</span>kubeconfig<span class=o>]</span> Writing <span class=s2>&#34;controller-manager.conf&#34;</span> kubeconfig file
</span></span><span class=line><span class=cl><span class=o>[</span>kubeconfig<span class=o>]</span> Writing <span class=s2>&#34;scheduler.conf&#34;</span> kubeconfig file
</span></span><span class=line><span class=cl><span class=o>[</span>kubelet-start<span class=o>]</span> Writing kubelet environment file with flags to file <span class=s2>&#34;/var/lib/kubelet/kubeadm-flags.env&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>kubelet-start<span class=o>]</span> Writing kubelet configuration to file <span class=s2>&#34;/var/lib/kubelet/config.yaml&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>kubelet-start<span class=o>]</span> Starting the kubelet
</span></span><span class=line><span class=cl><span class=o>[</span>control-plane<span class=o>]</span> Using manifest folder <span class=s2>&#34;/etc/kubernetes/manifests&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>control-plane<span class=o>]</span> Creating static Pod manifest <span class=k>for</span> <span class=s2>&#34;kube-apiserver&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>control-plane<span class=o>]</span> Creating static Pod manifest <span class=k>for</span> <span class=s2>&#34;kube-controller-manager&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>control-plane<span class=o>]</span> Creating static Pod manifest <span class=k>for</span> <span class=s2>&#34;kube-scheduler&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>etcd<span class=o>]</span> Creating static Pod manifest <span class=k>for</span> <span class=nb>local</span> etcd in <span class=s2>&#34;/etc/kubernetes/manifests&#34;</span>
</span></span><span class=line><span class=cl><span class=o>[</span>wait-control-plane<span class=o>]</span> Waiting <span class=k>for</span> the kubelet to boot up the control plane as static Pods from directory <span class=s2>&#34;/etc/kubernetes/manifests&#34;</span>. This can take up to 4m0s
</span></span><span class=line><span class=cl><span class=o>[</span>apiclient<span class=o>]</span> All control plane components are healthy after 16.003580 seconds
</span></span><span class=line><span class=cl><span class=o>[</span>upload-config<span class=o>]</span> Storing the configuration used in ConfigMap <span class=s2>&#34;kubeadm-config&#34;</span> in the <span class=s2>&#34;kube-system&#34;</span> Namespace
</span></span><span class=line><span class=cl><span class=o>[</span>kubelet<span class=o>]</span> Creating a ConfigMap <span class=s2>&#34;kubelet-config-1.23&#34;</span> in namespace kube-system with the configuration <span class=k>for</span> the kubelets in the cluster
</span></span><span class=line><span class=cl>NOTE: The <span class=s2>&#34;kubelet-config-1.23&#34;</span> naming of the kubelet ConfigMap is deprecated. Once the UnversionedKubeletConfigMap feature gate graduates to Beta the default name will become just <span class=s2>&#34;kubelet-config&#34;</span>. Kubeadm upgrade will handle this transition transparently.
</span></span><span class=line><span class=cl><span class=o>[</span>upload-certs<span class=o>]</span> Skipping phase. Please see --upload-certs
</span></span><span class=line><span class=cl><span class=o>[</span>mark-control-plane<span class=o>]</span> Marking the node node1 as control-plane by adding the labels: <span class=o>[</span>node-role.kubernetes.io/master<span class=o>(</span>deprecated<span class=o>)</span> node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers<span class=o>]</span>
</span></span><span class=line><span class=cl><span class=o>[</span>mark-control-plane<span class=o>]</span> Marking the node node1 as control-plane by adding the taints <span class=o>[</span>node-role.kubernetes.io/master:PreferNoSchedule<span class=o>]</span>
</span></span><span class=line><span class=cl><span class=o>[</span>bootstrap-token<span class=o>]</span> Using token: o7d0h6.i9taufdl7u1un4va
</span></span><span class=line><span class=cl><span class=o>[</span>bootstrap-token<span class=o>]</span> Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
</span></span><span class=line><span class=cl><span class=o>[</span>bootstrap-token<span class=o>]</span> configured RBAC rules to allow Node Bootstrap tokens to get nodes
</span></span><span class=line><span class=cl><span class=o>[</span>bootstrap-token<span class=o>]</span> configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order <span class=k>for</span> nodes to get long term certificate credentials
</span></span><span class=line><span class=cl><span class=o>[</span>bootstrap-token<span class=o>]</span> configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
</span></span><span class=line><span class=cl><span class=o>[</span>bootstrap-token<span class=o>]</span> configured RBAC rules to allow certificate rotation <span class=k>for</span> all node client certificates in the cluster
</span></span><span class=line><span class=cl><span class=o>[</span>bootstrap-token<span class=o>]</span> Creating the <span class=s2>&#34;cluster-info&#34;</span> ConfigMap in the <span class=s2>&#34;kube-public&#34;</span> namespace
</span></span><span class=line><span class=cl><span class=o>[</span>kubelet-finalize<span class=o>]</span> Updating <span class=s2>&#34;/etc/kubernetes/kubelet.conf&#34;</span> to point to a rotatable kubelet client certificate and key
</span></span><span class=line><span class=cl><span class=o>[</span>addons<span class=o>]</span> Applied essential addon: CoreDNS
</span></span><span class=line><span class=cl><span class=o>[</span>addons<span class=o>]</span> Applied essential addon: kube-proxy
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Your Kubernetes control-plane has initialized successfully!
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>To start using your cluster, you need to run the following as a regular user:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  mkdir -p <span class=nv>$HOME</span>/.kube
</span></span><span class=line><span class=cl>  sudo cp -i /etc/kubernetes/admin.conf <span class=nv>$HOME</span>/.kube/config
</span></span><span class=line><span class=cl>  sudo chown <span class=k>$(</span>id -u<span class=k>)</span>:<span class=k>$(</span>id -g<span class=k>)</span> <span class=nv>$HOME</span>/.kube/config
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Alternatively, <span class=k>if</span> you are the root user, you can run:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nb>export</span> <span class=nv>KUBECONFIG</span><span class=o>=</span>/etc/kubernetes/admin.conf
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>You should now deploy a pod network to the cluster.
</span></span><span class=line><span class=cl>Run <span class=s2>&#34;kubectl apply -f [podnetwork].yaml&#34;</span> with one of the options listed at:
</span></span><span class=line><span class=cl>  https://kubernetes.io/docs/concepts/cluster-administration/addons/
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Then you can join any number of worker nodes by running the following on each as root:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>kubeadm join 192.168.96.151:6443 --token o7d0h6.i9taufdl7u1un4va <span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span>	--discovery-token-ca-cert-hash sha256:6c55b14e9d71ef098ad0e8f249d85004c41b48063dbcd7692997930f9637f22b
</span></span></code></pre></td></tr></table></div></div><p>上面记录了完成的初始化输出的内容，根据输出的内容基本上可以看出手动初始化安装一个Kubernetes集群所需要的关键步骤。 其中有以下关键内容：</p><ul><li><code>[certs]</code>生成相关的各种证书</li><li><code>[kubeconfig]</code>生成相关的kubeconfig文件</li><li><code>[kubelet-start]</code> 生成kubelet的配置文件"/var/lib/kubelet/config.yaml"</li><li><code>[control-plane]</code>使用<code>/etc/kubernetes/manifests</code>目录中的yaml文件创建apiserver、controller-manager、scheduler的静态pod</li><li><code>[bootstraptoken]</code>生成token记录下来，后边使用<code>kubeadm join</code>往集群中添加节点时会用到</li><li>下面的命令是配置常规用户如何使用kubectl访问集群：</li></ul><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>mkdir -p <span class=nv>$HOME</span>/.kube
</span></span><span class=line><span class=cl>sudo cp -i /etc/kubernetes/admin.conf <span class=nv>$HOME</span>/.kube/config
</span></span><span class=line><span class=cl>sudo chown <span class=k>$(</span>id -u<span class=k>)</span>:<span class=k>$(</span>id -g<span class=k>)</span> <span class=nv>$HOME</span>/.kube/config
</span></span></code></pre></td></tr></table></div></div><ul><li>最后给出了将节点加入集群的命令<code>kubeadm join 192.168.96.151:6443 --token o7d0h6.i9taufdl7u1un4va \ --discovery-token-ca-cert-hash sha256:6c55b14e9d71ef098ad0e8f249d85004c41b48063dbcd7692997930f9637f22b</code></li></ul><p>查看一下集群状态，确认个组件都处于healthy状态，结果出现了错误:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>kubectl get cs
</span></span><span class=line><span class=cl>Warning: v1 ComponentStatus is deprecated in v1.19+
</span></span><span class=line><span class=cl>NAME                 STATUS      MESSAGE                                                                                       ERROR
</span></span><span class=line><span class=cl>controller-manager   Unhealthy   Get <span class=s2>&#34;http://127.0.0.1:10252/healthz&#34;</span>: dial tcp 127.0.0.1:10252: connect: connection refused
</span></span><span class=line><span class=cl>scheduler            Unhealthy   Get <span class=s2>&#34;http://127.0.0.1:10251/healthz&#34;</span>: dial tcp 127.0.0.1:10251: connect: connection refused
</span></span><span class=line><span class=cl>etcd-0               Healthy     <span class=o>{</span><span class=s2>&#34;health&#34;</span>:<span class=s2>&#34;true&#34;</span><span class=o>}</span>
</span></span></code></pre></td></tr></table></div></div><p>controller-manager和scheduler为不健康状态，修改<code>/etc/kubernetes/manifests/</code>下的静态pod配置文件<code>kube-controller-manager.yaml</code>和<code>kube-scheduler.yaml</code>，删除这两个文件中命令选项中的<code>- --port=0</code>这行，重启kubelet，再次查看一切正常。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>kubectl get cs
</span></span><span class=line><span class=cl>Warning: v1 ComponentStatus is deprecated in v1.19+
</span></span><span class=line><span class=cl>NAME                 STATUS    MESSAGE                         ERROR
</span></span><span class=line><span class=cl>scheduler            Healthy   ok
</span></span><span class=line><span class=cl>controller-manager   Healthy   ok
</span></span><span class=line><span class=cl>etcd-0               Healthy   <span class=o>{</span><span class=s2>&#34;health&#34;</span>:<span class=s2>&#34;true&#34;</span>,<span class=s2>&#34;reason&#34;</span>:<span class=s2>&#34;&#34;</span><span class=o>}</span>
</span></span></code></pre></td></tr></table></div></div><p>集群初始化如果遇到问题，可以使用<code>kubeadm reset</code>命令进行清理。</p><h3 id=23-安装包管理器helm-3>2.3 安装包管理器helm 3</h3><p>Helm是Kubernetes的包管理器，后续流程也将使用Helm安装Kubernetes的常用组件。 这里先在master节点node1上按照helm。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>wget https://get.helm.sh/helm-v3.7.2-linux-amd64.tar.gz
</span></span><span class=line><span class=cl>tar -zxvf helm-v3.7.2-linux-amd64.tar.gz
</span></span><span class=line><span class=cl>mv linux-amd64/helm  /usr/local/bin/
</span></span></code></pre></td></tr></table></div></div><p>执行<code>helm list</code>确认没有错误输出。</p><h3 id=24-部署pod-network组件calico>2.4 部署Pod Network组件Calico</h3><p>选择calico作为k8s的Pod网络组件，下面使用helm在k8s集群中按照calico。</p><p>下载<code>tigera-operator</code>的helm chart:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>wget https://github.com/projectcalico/calico/releases/download/v3.21.2/tigera-operator-v3.21.2-1.tgz
</span></span></code></pre></td></tr></table></div></div><p>查看这个chart的中可定制的配置:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>helm show values tigera-operator-v3.21.2-1.tgz
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>imagePullSecrets: <span class=o>{}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>installation:
</span></span><span class=line><span class=cl>  enabled: <span class=nb>true</span>
</span></span><span class=line><span class=cl>  kubernetesProvider: <span class=s2>&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>apiServer:
</span></span><span class=line><span class=cl>  enabled: <span class=nb>true</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>certs:
</span></span><span class=line><span class=cl>  node:
</span></span><span class=line><span class=cl>    key:
</span></span><span class=line><span class=cl>    cert:
</span></span><span class=line><span class=cl>    commonName:
</span></span><span class=line><span class=cl>  typha:
</span></span><span class=line><span class=cl>    key:
</span></span><span class=line><span class=cl>    cert:
</span></span><span class=line><span class=cl>    commonName:
</span></span><span class=line><span class=cl>    caBundle:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Configuration for the tigera operator</span>
</span></span><span class=line><span class=cl>tigeraOperator:
</span></span><span class=line><span class=cl>  image: tigera/operator
</span></span><span class=line><span class=cl>  version: v1.23.3
</span></span><span class=line><span class=cl>  registry: quay.io
</span></span><span class=line><span class=cl>calicoctl:
</span></span><span class=line><span class=cl>  image: quay.io/docker.io/calico/ctl
</span></span><span class=line><span class=cl>  tag: v3.21.2
</span></span></code></pre></td></tr></table></div></div><p>定制的<code>values.yaml</code>如下:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl><span class=c1># 可针对上面的配置进行定制,例如calico的镜像改成从私有库拉取。</span>
</span></span><span class=line><span class=cl><span class=c1># 这里只是个人本地环境测试k8s新版本，因此保留value.yaml为空即可</span>
</span></span></code></pre></td></tr></table></div></div><p>使用helm安装calico：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>helm install calico tigera-operator-v3.21.2-1.tgz -f values.yaml
</span></span></code></pre></td></tr></table></div></div><p>等待并确认所有pod处于Running状态:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>watch kubectl get pods -n calico-system
</span></span><span class=line><span class=cl>NAME                                       READY   STATUS    RESTARTS   AGE
</span></span><span class=line><span class=cl>calico-kube-controllers-7f58dbcbbd-kdnlg   1/1     Running   <span class=m>0</span>          2m34s
</span></span><span class=line><span class=cl>calico-node-nv794                          1/1     Running   <span class=m>0</span>          2m34s
</span></span><span class=line><span class=cl>calico-typha-65f579bc5d-4pbfz              1/1     Running   <span class=m>0</span>          2m34s
</span></span></code></pre></td></tr></table></div></div><p>查看一下calico向k8s中添加的api资源:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>kubectl api-resources <span class=p>|</span> grep calico
</span></span><span class=line><span class=cl>bgpconfigurations                              crd.projectcalico.org/v1               <span class=nb>false</span>        BGPConfiguration
</span></span><span class=line><span class=cl>bgppeers                                       crd.projectcalico.org/v1               <span class=nb>false</span>        BGPPeer
</span></span><span class=line><span class=cl>blockaffinities                                crd.projectcalico.org/v1               <span class=nb>false</span>        BlockAffinity
</span></span><span class=line><span class=cl>caliconodestatuses                             crd.projectcalico.org/v1               <span class=nb>false</span>        CalicoNodeStatus
</span></span><span class=line><span class=cl>clusterinformations                            crd.projectcalico.org/v1               <span class=nb>false</span>        ClusterInformation
</span></span><span class=line><span class=cl>felixconfigurations                            crd.projectcalico.org/v1               <span class=nb>false</span>        FelixConfiguration
</span></span><span class=line><span class=cl>globalnetworkpolicies                          crd.projectcalico.org/v1               <span class=nb>false</span>        GlobalNetworkPolicy
</span></span><span class=line><span class=cl>globalnetworksets                              crd.projectcalico.org/v1               <span class=nb>false</span>        GlobalNetworkSet
</span></span><span class=line><span class=cl>hostendpoints                                  crd.projectcalico.org/v1               <span class=nb>false</span>        HostEndpoint
</span></span><span class=line><span class=cl>ipamblocks                                     crd.projectcalico.org/v1               <span class=nb>false</span>        IPAMBlock
</span></span><span class=line><span class=cl>ipamconfigs                                    crd.projectcalico.org/v1               <span class=nb>false</span>        IPAMConfig
</span></span><span class=line><span class=cl>ipamhandles                                    crd.projectcalico.org/v1               <span class=nb>false</span>        IPAMHandle
</span></span><span class=line><span class=cl>ippools                                        crd.projectcalico.org/v1               <span class=nb>false</span>        IPPool
</span></span><span class=line><span class=cl>ipreservations                                 crd.projectcalico.org/v1               <span class=nb>false</span>        IPReservation
</span></span><span class=line><span class=cl>kubecontrollersconfigurations                  crd.projectcalico.org/v1               <span class=nb>false</span>        KubeControllersConfiguration
</span></span><span class=line><span class=cl>networkpolicies                                crd.projectcalico.org/v1               <span class=nb>true</span>         NetworkPolicy
</span></span><span class=line><span class=cl>networksets                                    crd.projectcalico.org/v1               <span class=nb>true</span>         NetworkSet
</span></span></code></pre></td></tr></table></div></div><p>这些api资源是属于calico的，因此不建议使用kubectl来管理，推荐按照calicoctl来管理这些api资源。 将calicoctl安装为kubectl的插件:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>cd /usr/local/bin
</span></span><span class=line><span class=cl>curl -o kubectl-calico -O -L  &#34;https://github.com/projectcalico/calicoctl/releases/download/v3.21.2/calicoctl&#34; 
</span></span><span class=line><span class=cl>chmod +x kubectl-calico
</span></span></code></pre></td></tr></table></div></div><p>验证插件正常工作:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>kubectl calico -h
</span></span></code></pre></td></tr></table></div></div><h3 id=25-验证k8s-dns是否可用>2.5 验证k8s DNS是否可用</h3><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>kubectl run curl --image=radial/busyboxplus:curl -it
</span></span><span class=line><span class=cl>If you don&#39;t see a command prompt, try pressing enter.
</span></span><span class=line><span class=cl>[ root@curl:/ ]$
</span></span></code></pre></td></tr></table></div></div><p>进入后执行<code>nslookup kubernetes.default</code>确认解析正常:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>nslookup kubernetes.default
</span></span><span class=line><span class=cl>Server:    10.96.0.10
</span></span><span class=line><span class=cl>Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Name:      kubernetes.default
</span></span><span class=line><span class=cl>Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local
</span></span></code></pre></td></tr></table></div></div><h3 id=26-向kubernetes集群中添加node节点>2.6 向Kubernetes集群中添加Node节点</h3><p>下面将node2, node3添加到Kubernetes集群中，分别在node2, node3上执行:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>kubeadm join 192.168.96.151:6443 --token o7d0h6.i9taufdl7u1un4va \  --discovery-token-ca-cert-hash sha256:6c55b14e9d71ef098ad0e8f249d85004c41b48063dbcd7692997930f9637f22b 
</span></span></code></pre></td></tr></table></div></div><p>node2和node3加入集群很是顺利，在master节点上执行命令查看集群中的节点：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>kubectl get node
</span></span><span class=line><span class=cl>NAME    STATUS   ROLES                  AGE     VERSION
</span></span><span class=line><span class=cl>node1   Ready    control-plane,master   29m     v1.23.1
</span></span><span class=line><span class=cl>node2   Ready    &lt;none&gt;                 5m28s   v1.23.1
</span></span><span class=line><span class=cl>node3   Ready    &lt;none&gt;                 5m4s    v1.23.1
</span></span></code></pre></td></tr></table></div></div><h2 id=3kubernetes常用组件部署>3.Kubernetes常用组件部署</h2><h3 id=31-使用helm部署ingress-nginx>3.1 使用Helm部署ingress-nginx</h3><p>为了便于将集群中的服务暴露到集群外部，需要使用Ingress。接下来使用Helm将ingress-nginx部署到Kubernetes上。 Nginx Ingress Controller被部署在Kubernetes的边缘节点上。</p><p>这里将node1(192.168.96.151)作为边缘节点，打上Label：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>kubectl label node node1 node-role.kubernetes.io/edge=
</span></span></code></pre></td></tr></table></div></div><p>下载ingress-nginx的helm chart:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>wget https://github.com/kubernetes/ingress-nginx/releases/download/helm-chart-4.0.13/ingress-nginx-4.0.13.tgz 
</span></span></code></pre></td></tr></table></div></div><p>查看<code>ingress-nginx-4.0.13.tgz</code>这个chart的可定制配置:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>helm show values ingress-nginx-4.0.13.tgz 
</span></span></code></pre></td></tr></table></div></div><p>对values.yaml配置定制如下:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span><span class=lnt>25
</span><span class=lnt>26
</span><span class=lnt>27
</span><span class=lnt>28
</span><span class=lnt>29
</span><span class=lnt>30
</span><span class=lnt>31
</span><span class=lnt>32
</span><span class=lnt>33
</span><span class=lnt>34
</span><span class=lnt>35
</span><span class=lnt>36
</span><span class=lnt>37
</span><span class=lnt>38
</span><span class=lnt>39
</span><span class=lnt>40
</span><span class=lnt>41
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-yml data-lang=yml><span class=line><span class=cl><span class=nt>controller</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>ingressClassResource</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>name</span><span class=p>:</span><span class=w> </span><span class=l>nginx</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>enabled</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>default</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>controllerValue</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;k8s.io/ingress-nginx&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>admissionWebhooks</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>enabled</span><span class=p>:</span><span class=w> </span><span class=kc>false</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>replicaCount</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>image</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=c># registry: k8s.gcr.io</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=c># image: ingress-nginx/controller</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=c># tag: &#34;v1.1.0&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>registry</span><span class=p>:</span><span class=w> </span><span class=l>docker.io</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>image</span><span class=p>:</span><span class=w> </span><span class=l>unreachableg/k8s.gcr.io_ingress-nginx_controller</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>tag</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;v1.1.0&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>digest</span><span class=p>:</span><span class=w> </span><span class=l>sha256:4f5df867e9367f76acfc39a0f85487dc63526e27735fa82fc57d6a652bafbbf6</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>hostNetwork</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>nodeSelector</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>node-role.kubernetes.io/edge</span><span class=p>:</span><span class=w> </span><span class=s1>&#39;&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>affinity</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>podAntiAffinity</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>requiredDuringSchedulingIgnoredDuringExecution</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span>- <span class=nt>labelSelector</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span><span class=nt>matchExpressions</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=nt>key</span><span class=p>:</span><span class=w> </span><span class=l>app</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span><span class=nt>operator</span><span class=p>:</span><span class=w> </span><span class=l>In</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span><span class=nt>values</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>nginx-ingress</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>            </span>- <span class=nt>key</span><span class=p>:</span><span class=w> </span><span class=l>component</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span><span class=nt>operator</span><span class=p>:</span><span class=w> </span><span class=l>In</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span><span class=nt>values</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>              </span>- <span class=l>controller</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>          </span><span class=nt>topologyKey</span><span class=p>:</span><span class=w> </span><span class=l>kubernetes.io/hostname</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>tolerations</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>key</span><span class=p>:</span><span class=w> </span><span class=l>node-role.kubernetes.io/master</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>operator</span><span class=p>:</span><span class=w> </span><span class=l>Exists</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>effect</span><span class=p>:</span><span class=w> </span><span class=l>NoSchedule</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=nt>key</span><span class=p>:</span><span class=w> </span><span class=l>node-role.kubernetes.io/master</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>operator</span><span class=p>:</span><span class=w> </span><span class=l>Exists</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=nt>effect</span><span class=p>:</span><span class=w> </span><span class=l>PreferNoSchedule</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><p>nginx ingress controller的副本数replicaCount为1，将被调度到node1这个边缘节点上。这里并没有指定nginx ingress controller service的externalIPs，而是通过<code>hostNetwork: true</code>设置nginx ingress controller使用宿主机网络。 因为k8s.gcr.io被墙，这里替换成unreachableg/k8s.gcr.io_ingress-nginx_controller提前拉取一下镜像:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>crictl pull unreachableg/k8s.gcr.io_ingress-nginx_controller:v1.1.0 
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>helm install ingress-nginx ingress-nginx-4.0.13.tgz --create-namespace -n ingress-nginx -f values.yaml 
</span></span></code></pre></td></tr></table></div></div><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>kubectl get pod -n ingress-nginx
</span></span><span class=line><span class=cl>NAME                                        READY   STATUS    RESTARTS   AGE
</span></span><span class=line><span class=cl>ingress-nginx-controller-7f574989bc-xwbf4   1/1     Running   0          117s
</span></span></code></pre></td></tr></table></div></div><p>测试访问<code>http://192.168.96.151</code>返回默认的nginx 404页，则部署完成。</p><h3 id=32-使用helm部署dashboard>3.2 使用Helm部署dashboard</h3><p>先部署metrics-server：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>wget https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.5.2/components.yaml 
</span></span></code></pre></td></tr></table></div></div><p>修改components.yaml中的image为<code>docker.io/unreachableg/k8s.gcr.io_metrics-server_metrics-server:v0.5.2</code>。 修改components.yaml中容器的启动参数，加入<code>--kubelet-insecure-tls</code>。</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>kubectl apply -f components.yaml 
</span></span></code></pre></td></tr></table></div></div><p>metrics-server的pod正常启动后，等一段时间就可以使用<code>kubectl top</code>查看集群和pod的metrics信息:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>kubectl top node --use-protocol-buffers=true
</span></span><span class=line><span class=cl>NAME    CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
</span></span><span class=line><span class=cl>node1   219m         5%     3013Mi          39%
</span></span><span class=line><span class=cl>node2   102m         2%     1576Mi          20%
</span></span><span class=line><span class=cl>node3   110m         2%     1696Mi          21%
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>kubectl top pod -n kube-system --use-protocol-buffers=true
</span></span><span class=line><span class=cl>NAME                                    CPU(cores)   MEMORY(bytes)
</span></span><span class=line><span class=cl>coredns-59d64cd4d4-9mclj                4m           17Mi
</span></span><span class=line><span class=cl>coredns-59d64cd4d4-fj7xr                4m           17Mi
</span></span><span class=line><span class=cl>etcd-node1                              25m          154Mi
</span></span><span class=line><span class=cl>kube-apiserver-node1                    80m          465Mi
</span></span><span class=line><span class=cl>kube-controller-manager-node1           17m          61Mi
</span></span><span class=line><span class=cl>kube-proxy-hhlhc                        1m           21Mi
</span></span><span class=line><span class=cl>kube-proxy-nrhq7                        1m           19Mi
</span></span><span class=line><span class=cl>kube-proxy-phmrw                        1m           17Mi
</span></span><span class=line><span class=cl>kube-scheduler-node1                    4m           24Mi
</span></span><span class=line><span class=cl>kubernetes-dashboard-5cb95fd47f-6lfnm   3m           36Mi
</span></span><span class=line><span class=cl>metrics-server-9ddcc8ddf-jvlzs          5m           21Mi
</span></span></code></pre></td></tr></table></div></div><p>接下来使用helm部署k8s的dashboard，添加chart repo:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>helm repo add kubernetes-dashboard https://kubernetes.github.io/dashboard/
</span></span><span class=line><span class=cl>helm repo update
</span></span></code></pre></td></tr></table></div></div><p>查看chart的可定制配置:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>helm show values kubernetes-dashboard/kubernetes-dashboard 
</span></span></code></pre></td></tr></table></div></div><p>对value.yaml定制配置如下:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-yml data-lang=yml><span class=line><span class=cl><span class=nt>image</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>repository</span><span class=p>:</span><span class=w> </span><span class=l>kubernetesui/dashboard</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>tag</span><span class=p>:</span><span class=w> </span><span class=l>v2.4.0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>ingress</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>enabled</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>annotations</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>nginx.ingress.kubernetes.io/ssl-redirect</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;true&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>nginx.ingress.kubernetes.io/backend-protocol</span><span class=p>:</span><span class=w> </span><span class=s2>&#34;HTTPS&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>hosts</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=l>k8s.example.com</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>tls</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>secretName</span><span class=p>:</span><span class=w> </span><span class=l>example-com-tls-secret</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=nt>hosts</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>k8s.example.com</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=nt>metricsScraper</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>enabled</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span></code></pre></td></tr></table></div></div><p>先创建存放<code>k8s.example.com</code>ssl证书的secret:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>kubectl create secret tls example-com-tls-secret \
</span></span><span class=line><span class=cl>  --cert=cert.pem \
</span></span><span class=line><span class=cl>  --key=key.pem \
</span></span><span class=line><span class=cl>  -n kube-system
</span></span></code></pre></td></tr></table></div></div><p>使用helm部署dashboard:</p><p>helm install kubernetes-dashboard kubernetes-dashboard/kubernetes-dashboard<br>-n kube-system<br>-f values.yaml</p><p>确认上面的命令部署成功。</p><p>创建管理员sa:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>kubectl create serviceaccount kube-dashboard-admin-sa -n kube-system
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>kubectl create clusterrolebinding kube-dashboard-admin-sa \
</span></span><span class=line><span class=cl>--clusterrole=cluster-admin --serviceaccount=kube-system:kube-dashboard-admin-sa
</span></span></code></pre></td></tr></table></div></div><p>获取集群管理员登录dashboard所需token:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>kubectl -n kube-system get secret | grep kube-dashboard-admin-sa-token
</span></span><span class=line><span class=cl>kube-dashboard-admin-sa-token-rcwlb              kubernetes.io/service-account-token   3      68s
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>kubectl describe -n kube-system secret/kube-dashboard-admin-sa-token-rcwlb 
</span></span><span class=line><span class=cl>Name:         kube-dashboard-admin-sa-token-rcwlb
</span></span><span class=line><span class=cl>Namespace:    kube-system
</span></span><span class=line><span class=cl>Labels:       &lt;none&gt;
</span></span><span class=line><span class=cl>Annotations:  kubernetes.io/service-account.name: kube-dashboard-admin-sa
</span></span><span class=line><span class=cl>              kubernetes.io/service-account.uid: fcdf27f6-f6f9-4f76-b64e-edc91fb1479b
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Type:  kubernetes.io/service-account-token
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Data
</span></span><span class=line><span class=cl>====
</span></span><span class=line><span class=cl>namespace:  11 bytes
</span></span><span class=line><span class=cl>token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IkYxWTd5aDdzYWsyeWJVMFliUUhJMXI4YWtMZFd4dGFDT1N4eEZoam9HLUEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJrdWJlLWRhc2hib2FyZC1hZG1pbi1zYS10b2tlbi1yY3dsYiIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJrdWJlLWRhc2hib2FyZC1hZG1pbi1zYSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6ImZjZGYyN2Y2LWY2ZjktNGY3Ni1iNjRlLWVkYzkxZmIxNDc5YiIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTprdWJlLWRhc2hib2FyZC1hZG1pbi1zYSJ9.R3l19_Nal4B2EktKFSJ7CgOqAngG_MTgzHRRjWdREN7dLALyfiRXYIgZQ90hxM-a9z2sPXBzfJno4OGP4fPX33D8h_4fgxfpVLjKqjdlZ_HAks_6sV9PBzDNXb_loNW8ECfsleDgn6CZin8Vx1w7sgkoEIKq0H-iZ8V9pRV0fTuOZcB-70pV_JX6H6WBEOgRIAZswhAoyUMvH1qNl47J5xBNwKRgcqP57NCIODo6FiClxfY3MWo2vz44R5wYCuBJJ70p6aBWixjDSxnp5u9mUP0zMF_igICl_OfgKuPyaeuIL83U8dS5ovEwPPGzX5mHUgaPH7JLZmKRNXJqLhTweA
</span></span><span class=line><span class=cl>ca.crt:     1066 bytes
</span></span></code></pre></td></tr></table></div></div><p>使用上面的token登录k8s dashboard。</p><p><a href=https://blog.frognew.com/images/2021/06/k8s-1.21-dashboard.png><img src=https://blog.frognew.com/images/2021/06/k8s-1.21-dashboard.png alt=dashboard></a></p><h2 id=faq>FAQ</h2><ul><li><p>calico: <a href=https://www.jianshu.com/p/4b175e733cd3>BIRD is not ready: BGP not established</a></p><p>一种是通过正则指定网卡，类似这样:</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-csharp data-lang=csharp><span class=line><span class=cl><span class=p>-</span> <span class=n>name</span><span class=p>:</span> <span class=n>IP_AUTODETECTION_METHOD</span>
</span></span><span class=line><span class=cl><span class=k>value</span><span class=p>:</span> <span class=s>&#34;interface=ens.*&#34;</span>  <span class=err>#</span> <span class=n>ens</span> <span class=err>根据实际网卡开头配置</span>
</span></span></code></pre></td></tr></table></div></div><p>另一种是从部署节点到到达目的节点的,类似这样：</p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt>1
</span><span class=lnt>2
</span><span class=lnt>3
</span><span class=lnt>4
</span><span class=lnt>5
</span><span class=lnt>6
</span><span class=lnt>7
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Using IP addresses</span>
</span></span><span class=line><span class=cl><span class=nv>IP_AUTODETECTION_METHOD</span><span class=o>=</span>can-reach<span class=o>=</span>8.8.8.8
</span></span><span class=line><span class=cl><span class=nv>IP6_AUTODETECTION_METHOD</span><span class=o>=</span>can-reach<span class=o>=</span>2001:4860:4860::8888
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Using domain names</span>
</span></span><span class=line><span class=cl><span class=nv>IP_AUTODETECTION_METHOD</span><span class=o>=</span>can-reach<span class=o>=</span>www.google.com
</span></span><span class=line><span class=cl><span class=nv>IP6_AUTODETECTION_METHOD</span><span class=o>=</span>can-reach<span class=o>=</span>www.google.com
</span></span></code></pre></td></tr></table></div></div><p>如果是通过 Installation 安装的，需要修改一个CRD Installation</p></li><li></li></ul><h2 id=参考>参考</h2><ul><li><a href=https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/>Installing kubeadm</a></li><li><a href=https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm//>Creating a cluster with kubeadm</a></li><li><a href=https://github.com/containerd/containerd>https://github.com/containerd/containerd</a></li><li><a href=https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta2>https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta2</a></li><li><a href=https://docs.projectcalico.org/>https://docs.projectcalico.org/</a></li></ul></div><div class=post-copyright><p class=copyright-item><span class=item-title>Author</span>
<span class=item-content>yesplease</span></p><p class=copyright-item><span class=item-title>LastMod</span>
<span class=item-content>2022-03-01</span></p><p class=copyright-item><span class=item-title>License</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank>CC BY-NC-ND 4.0</a></span></p></div><footer class=post-footer><div class=post-tags><a href=http://cugbtang.github.io/tags/kubernetes/>kubernetes</a>
<a href=http://cugbtang.github.io/tags/kubeadm/>kubeadm</a>
<a href=http://cugbtang.github.io/tags/deploy/>deploy</a></div><nav class=post-nav><a class=prev href=/post/container/series-container-1/><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M691.908486 949.511495l75.369571-89.491197c10.963703-12.998035 10.285251-32.864502-1.499144-44.378743L479.499795 515.267417l277.93508-310.326815c11.338233-12.190647 11.035334-32.285311-.638543-44.850487l-80.46666-86.564541c-11.680017-12.583596-30.356378-12.893658-41.662889-.716314L257.233596 494.235404c-11.332093 12.183484-11.041474 32.266891.657986 44.844348l80.46666 86.564541c1.772366 1.910513 3.706415 3.533476 5.750981 4.877077l306.620399 321.703933C662.505829 963.726242 680.945807 962.528973 691.908486 949.511495z"/></svg></i><span class="prev-text nav-default">Container, how to play?</span>
<span class="prev-text nav-mobile">Prev</span></a>
<a class=next href=/post/go/series-go-1/><span class="next-text nav-default">Go, how to play?</span>
<span class="prev-text nav-mobile">Next</span>
<i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="18" height="18"><path d="M332.091514 74.487481l-75.369571 89.491197c-10.963703 12.998035-10.285251 32.864502 1.499144 44.378743l286.278095 300.375162L266.565125 819.058374c-11.338233 12.190647-11.035334 32.285311.638543 44.850487l80.46666 86.564541c11.680017 12.583596 30.356378 12.893658 41.662889.716314l377.434212-421.426145c11.332093-12.183484 11.041474-32.266891-.657986-44.844348l-80.46666-86.564541c-1.772366-1.910513-3.706415-3.533476-5.750981-4.877077L373.270379 71.774697c-11.777231-11.500939-30.216186-10.304694-41.178865 2.712784z"/></svg></i></a></nav></footer></article></div></div></main><footer id=footer class=footer><div class=icon-links><a href=http://cugbtang.github.io rel="me noopener" class=iconfont title=github target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="36" height="36"><path d="M512 12.672c-282.88.0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667.0-12.16-.426667-44.373333-.64-87.04C242.005334 929.664 211.968 830.08 211.968 830.08 188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333.0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333.0.0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667.0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72.0 68.522667-.64 123.562667-.64 140.202666.0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"/></svg></a><a href=http://cugbtang.github.io rel="me noopener" class=iconfont title=bilibili target=_blank><svg class="icon" viewBox="0 0 1024 1024" width="36" height="36" id="svg8"><path d="M744.60599.00486267A41.779915 41.779915.0 00710.4184 18.673394L548.5048 255.32642h-11.70046a41.779915 41.779915.0 00-10.80295-7.84928L235.66 97.084498a41.779915 41.779915.0 00-20.07193-4.960864 41.779915 41.779915.0 00-18.3748 79.145436L359.4859 255.32642H128.16909c-49.458302.0-89.27932 39.82105-89.27932 89.27932v508.65224c0 49.4583 39.821018 89.27934 89.27932 89.27934h19.48445C149.12802 984.5043 179.92773 1024 224.79179 1024c44.86407.0 75.66379-39.4957 77.13826-81.46268H719.98116C721.45559 984.5043 752.25533 1024 797.1194 1024c44.86406.0 75.6638-39.4957 77.13824-81.46268h21.57323c49.45831.0 89.27936-39.82104 89.27936-89.27934V344.60574c0-49.45827-39.82105-89.27932-89.27936-89.27932H649.74567L779.38103 65.866924A41.779915 41.779915.0 00744.60599.00486267zM644.49108 418.70871c6.29985.21538 12.44451 2.01107 17.86888 5.22196l171.36218 98.10771c18.23417 10.21935 24.63334 33.34627 14.24614 51.48533-10.38726 18.13909-33.57344 24.32718-51.61587 13.77296L624.9903 489.18895c-15.21356-8.41858-22.66871-26.1765-18.03211-42.93436 4.63664-16.75784 20.15573-28.14465 37.53289-27.54588zM350.2006 432.31846c16.89952.0317 31.69582 11.33328 36.17844 27.62747 4.48262 16.2942-2.44981 33.57765-16.95507 42.24898l-140.7157 86.91312c-17.68528 11.18244-41.09629 5.77692-52.08912-12.02686-10.99282-17.80373-5.33855-41.15658 12.58167-51.95857L329.9002 438.2095c6.0643-3.86439 13.10951-5.90891 20.3004-5.89104zM501.605 641.53985c3.75002-.15248 7.48645.53903 10.93349 2.0235.15842.0637.31618.12888.47325.19582.59328.27092 1.17574.56489 1.74609.88121.15868.0854.31643.17233.47325.2611.55694.32165 1.10131.66458 1.63185 1.02807.16455.1123.32777.2265.48956.34269.50382.36781.99371.75428 1.46868 1.15864.18724.15504.37218.31282.55484.47323.43271.38784.8518.79061 1.25653 1.20756.15449.16114.30679.32437.45693.48959.40798.44266.79989.89988 1.17494 1.37076.17799.22544.35205.45395.5222.68538.25932.34701.50964.70071.75064 1.06071.26712.39516.52286.79784.76699 1.20757.16907.29043.33231.58424.48957.88123.21836.41297.42513.83199.62009 1.25653.14836.32333.28983.64976.42429.97911.21319.51552.40915 1.03801.58747 1.5666.0677.19499.13296.39085.19582.58748.18652.60823.34984 1.22334.48957 1.84399.0397.16277.0779.32601.11423.48957.1436.69112.25788 1.38801.34269 2.08877.005.0381.0111.0761.0163.11424.0857.78056.13474 1.56471.14687 2.34988.005.0543.0111.10879.0163.1632.0.0-.008 1.12132.0 1.45234.0.0-.14697 17.84761 5.89102 34.12231 3.01902 8.13734 7.33278 15.10615 12.61433 19.61501 5.28157 4.50889 11.42894 7.62081 23.64572 7.62081 12.2168.0 18.36416-3.11192 23.64573-7.62081 5.28154-4.50886 9.5953-11.47767 12.6143-19.61501 6.03799-16.2747 5.89103-34.12231 5.89103-34.12231-.44885-13.87045 10.45922-25.46302 24.3311-25.86506 13.87189-.40201 25.42828 10.53953 25.78348 24.41272.0.0 1.11929 25.7226-9.00791 53.01927-5.06359 13.64832-13.1986 28.46036-27.05631 40.29073-13.85772 11.83039-33.5454 19.63135-56.20142 19.63135-22.65603.0-42.34371-7.80096-56.20141-19.63135-4.1801-3.56856-7.78733-7.42433-10.99878-11.42303-3.21235 4.00037-6.81703 7.85309-10.99876 11.42303-13.85773 11.83039-33.5454 19.63135-56.20144 19.63135-22.65601.0-42.3437-7.80096-56.2014-19.63135-13.85775-11.83037-21.99272-26.64241-27.05632-40.29073-10.12725-27.29667-9.00789-53.01928-9.00789-53.01927.20714-13.83687 11.58744-24.88848 25.42444-24.69013 14.1263.19991 25.2971 12.0278 24.69011 26.14247.0.0-.14697 17.84761 5.89103 34.12231 3.01902 8.13734 7.31646 15.10615 12.598 19.61501 5.28155 4.50889 11.44526 7.62081 23.66203 7.62081 12.21681.0 18.36418-3.11192 23.64573-7.62081 5.28154-4.50886 9.57899-11.47767 12.598-19.61501 5.76352-15.53489 5.89112-32.05691 5.89103-33.56746.006-.37466.0111-1.05336.0163-1.20759-.0117-.74583.0105-1.49177.0652-2.23565.009-.15784.0204-.31561.0327-.47324.14204-1.56859.43163-3.12027.86487-4.63449.0213-.0763.0433-.15244.0652-.22848 3.0335-10.25748 12.24157-17.46007 22.92769-17.93417z" id="rect824"/></svg></a><a href=http://cugbtang.github.io/index.xml rel="noopener alternate" type=application/rss+xml class=iconfont title=rss target=_blank><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="30" height="30"><path d="M819.157333 1024C819.157333 574.592 449.408 204.8.0 204.8V0c561.706667.0 1024 462.293333 1024 1024H819.157333zM140.416 743.04a140.8 140.8.0 01140.501333 140.586667A140.928 140.928.0 01140.074667 1024C62.72 1024 0 961.109333.0 883.626667S62.933333 743.082667 140.416 743.04zM678.784 1024h-199.04c0-263.210667-216.533333-479.786667-479.744-479.786667v-199.04c372.352.0 678.784 306.517333 678.784 678.826667z"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a></span>
<span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a></span>
<span class=copyright-year>&copy;
2017 -
2022
<span class=heart><i class=iconfont><svg class="icon" viewBox="0 0 1025 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="14" height="14"><path d="M1000.1 247.9c-15.5-37.3-37.6-70.6-65.7-98.9-54.4-54.8-125.8-85-201-85-85.7.0-166 39-221.4 107.4C456.6 103 376.3 64 290.6 64c-75.1.0-146.5 30.4-201.1 85.6-28.2 28.5-50.4 61.9-65.8 99.3-16 38.8-24 79.9-23.6 122.2.7 91.7 40.1 177.2 108.1 234.8 3.1 2.6 6 5.1 8.9 7.8 14.9 13.4 58 52.8 112.6 102.7 93.5 85.5 209.9 191.9 257.5 234.2 7 6.1 15.8 9.5 24.9 9.5 9.2.0 18.1-3.4 24.9-9.5 34.5-30.7 105.8-95.9 181.4-165 74.2-67.8 150.9-138 195.8-178.2 69.5-57.9 109.6-144.4 109.9-237.3.1-42.5-8-83.6-24-122.2z" fill="#8a8a8a"/></svg></i></span><span class=author>cugbtang</span></span></div></footer><div class=back-to-top id=back-to-top><i class=iconfont><svg class="icon" viewBox="0 0 1024 1024" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" width="35" height="35"><path d="M510.866688 227.694839 95.449397 629.218702h235.761562L329.15309 958.01517h362.40389L691.55698 628.188232l241.942331-3.089361L510.866688 227.694839zM63.840492 63.962777h894.052392v131.813095H63.840492V63.962777zm0 0"/></svg></i></div></div><script type=text/javascript src=/lib/jquery/jquery-3.2.1.min.js></script>
<script type=text/javascript src=/lib/slideout/slideout-1.0.1.min.js></script>
<script type=text/javascript src=/js/main.638251f4230630f0335d8c6748e53a96f94b72670920b60c09a56fdc8bece214.js integrity="sha256-Y4JR9CMGMPAzXYxnSOU6lvlLcmcJILYMCaVv3Ivs4hQ=" crossorigin=anonymous></script>
<script type=text/javascript src=/js/load-photoswipe.js></script>
<script type=text/javascript src=/lib/photoswipe/photoswipe.min.js></script>
<script type=text/javascript src=/lib/photoswipe/photoswipe-ui-default.min.js></script></body></html>