<!doctype html><html lang=en itemscope itemtype=http://schema.org/WebPage data-theme=light><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><title>kubeadm startup Kubernetes more than v1.20.0 (centos7+containerd+ipvs+calico) - ✌yesplease's blog</title><meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,user-scalable=yes"><meta name=MobileOptimized content="width"><meta name=HandheldFriendly content="true"><meta name=applicable-device content="pc,mobile"><meta name=color-scheme content="light dark"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=mobile-web-app-capable content="yes"><meta name=generator content="Hugo 0.152.2"><link rel=canonical href=http://localhost:1313/post/kubernetes/series-kubernetes-3/><meta name=author content="yesplease"><meta name=description content="这篇文章的作者部署的是kubernetes v1.23，但其实是基于kubernetes对CRI的改动执行的较为流行的方案。
我绝的主要是针对Docker的支持问题，因为在1.24中才正式将docker-shim剔除。以下列举了较为流行的部署方案：
"><meta name=keywords content="kubernetes,kubeadm,deploy"><meta property="og:url" content="http://localhost:1313/post/kubernetes/series-kubernetes-3/"><meta property="og:site_name" content="✌yesplease's blog"><meta property="og:title" content="kubeadm startup Kubernetes more than v1.20.0 (centos7+containerd+ipvs+calico)"><meta property="og:description" content="这篇文章的作者部署的是kubernetes v1.23，但其实是基于kubernetes对CRI的改动执行的较为流行的方案。
我绝的主要是针对Docker的支持问题，因为在1.24中才正式将docker-shim剔除。以下列举了较为流行的部署方案："><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="post"><meta property="article:published_time" content="2022-03-01T16:01:23+08:00"><meta property="article:modified_time" content="2022-03-01T16:01:23+08:00"><meta property="article:tag" content="Kubernetes"><meta property="article:tag" content="Kubeadm"><meta property="article:tag" content="Deploy"><meta itemprop=name content="kubeadm startup Kubernetes more than v1.20.0 (centos7+containerd+ipvs+calico)"><meta itemprop=description content="这篇文章的作者部署的是kubernetes v1.23，但其实是基于kubernetes对CRI的改动执行的较为流行的方案。
我绝的主要是针对Docker的支持问题，因为在1.24中才正式将docker-shim剔除。以下列举了较为流行的部署方案："><meta itemprop=datePublished content="2022-03-01T16:01:23+08:00"><meta itemprop=dateModified content="2022-03-01T16:01:23+08:00"><meta itemprop=wordCount content="6555"><meta itemprop=keywords content="Kubernetes,Kubeadm,Deploy"><meta name=twitter:card content="summary"><meta name=twitter:title content="kubeadm startup Kubernetes more than v1.20.0 (centos7+containerd+ipvs+calico)"><meta name=twitter:description content="这篇文章的作者部署的是kubernetes v1.23，但其实是基于kubernetes对CRI的改动执行的较为流行的方案。
我绝的主要是针对Docker的支持问题，因为在1.24中才正式将docker-shim剔除。以下列举了较为流行的部署方案："><link rel=icon href=/favicon.ico><link rel=stylesheet href=/css/style.min.e7c52960f769ac11bea62d460dc48cd995591740192e6c6f8c0f5585fb135c9d.css integrity="sha256-58UpYPdprBG+pi1GDcSM2ZVZF0AZLmxvjA9VhfsTXJ0=" media=screen crossorigin=anonymous><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script><script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--><script>(function(){var e=localStorage.getItem("theme")||"light";document.documentElement.setAttribute("data-theme",e)})()</script></head><body><div id=back-to-top></div><header class=site-header><div class=desktop-header><div class=desktop-header-logo><a href=/ class=logo>✌yesplease</a></div><nav class=desktop-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=http://localhost:1313/>This is Home</a></li><li class=menu-item><a class=menu-item-link href=http://localhost:1313/post/>Archives</a></li><li class=menu-item><a class=menu-item-link href=http://localhost:1313/tags/>Tags</a></li><li class=menu-item><a class=menu-item-link href=http://localhost:1313/about/>About</a></li><li class=menu-item><a class="theme-toggle menu-item-link" href=javascript:void(0);><svg aria-hidden="true" class="lucide lucide-sun hi-svg-inline theme-icon-light" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><circle cx="12" cy="12" r="4"/><path d="M12 2v2"/><path d="M12 20v2"/><path d="m4.93 4.93 1.41 1.41"/><path d="m17.66 17.66 1.41 1.41"/><path d="M2 12h2"/><path d="M20 12h2"/><path d="m6.34 17.66-1.41 1.41"/><path d="m19.07 4.93-1.41 1.41"/></svg>
<svg aria-hidden="true" class="lucide lucide-moon hi-svg-inline theme-icon-dark" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M12 3a6 6 0 009 9 9 9 0 11-9-9z"/></svg></a></li><li class=menu-item><a class=menu-item-link href=http://localhost:1313/index.xml rel="noopener alternate" type=application/rss+xml title=rss target=_blank><svg aria-hidden="true" class="lucide lucide-rss hi-svg-inline icon--rss" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></li></ul></nav></div><div class=mobile-header><div id=mobile-navbar class=mobile-navbar><div id=mobile-navbar-icon class=mobile-navbar-icon><svg aria-hidden="true" class="lucide lucide-menu hi-svg-inline icon--menu" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><line x1="4" x2="20" y1="12" y2="12"/><line x1="4" x2="20" y1="6" y2="6"/><line x1="4" x2="20" y1="18" y2="18"/></svg></div><div class=mobile-navbar-logo><a href=/ class=logo>✌yesplease</a></div></div><div id=mobile-menu-close-modal class=mobile-menu-close-modal></div><nav id=mobile-menu class=mobile-menu><ul class=mobile-menu-list><li class=mobile-menu-item><a class=menu-item-link href=http://localhost:1313/>This is Home</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://localhost:1313/post/>Archives</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://localhost:1313/tags/>Tags</a></li><li class=mobile-menu-item><a class=menu-item-link href=http://localhost:1313/about/>About</a></li><li class=mobile-menu-item><a class="theme-toggle menu-item-link" href=javascript:void(0);><svg aria-hidden="true" class="lucide lucide-sun hi-svg-inline theme-icon-light" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><circle cx="12" cy="12" r="4"/><path d="M12 2v2"/><path d="M12 20v2"/><path d="m4.93 4.93 1.41 1.41"/><path d="m17.66 17.66 1.41 1.41"/><path d="M2 12h2"/><path d="M20 12h2"/><path d="m6.34 17.66-1.41 1.41"/><path d="m19.07 4.93-1.41 1.41"/></svg>
<svg aria-hidden="true" class="lucide lucide-moon hi-svg-inline theme-icon-dark" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M12 3a6 6 0 009 9 9 9 0 11-9-9z"/></svg></a></li><li class=mobile-menu-item><a class=menu-item-link href=http://localhost:1313/index.xml rel="noopener alternate" type=application/rss+xml title=rss target=_blank><svg aria-hidden="true" class="lucide lucide-rss hi-svg-inline icon--rss" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></li></ul></nav></div></header><main id=main class="main pico container"><div class=content-wrapper><aside class=left-sidebar><nav class=toc id=toc><div class=toc-title>Table of Contents</div><div class="toc-content custom-scrollbar"><nav id=TableOfContents><ul><li><a href=#1准备>1.准备</a><ul><li><a href=#11-系统配置>1.1 系统配置</a></li><li><a href=#12-部署容器运行时containerd>1.2 部署容器运行时Containerd</a></li></ul></li><li><a href=#2使用kubeadm部署kubernetes>2.使用kubeadm部署Kubernetes</a><ul><li><a href=#21-安装kubeadm和kubelet>2.1 安装kubeadm和kubelet</a></li><li><a href=#22-使用kubeadm-init初始化集群>2.2 使用kubeadm init初始化集群</a></li><li><a href=#23-安装包管理器helm-3>2.3 安装包管理器helm 3</a></li><li><a href=#24-部署pod-network组件calico>2.4 部署Pod Network组件Calico</a></li><li><a href=#25-验证k8s-dns是否可用>2.5 验证k8s DNS是否可用</a></li><li><a href=#26-向kubernetes集群中添加node节点>2.6 向Kubernetes集群中添加Node节点</a></li></ul></li><li><a href=#3kubernetes常用组件部署>3.Kubernetes常用组件部署</a><ul><li><a href=#31-使用helm部署ingress-nginx>3.1 使用Helm部署ingress-nginx</a></li><li><a href=#32-使用helm部署dashboard>3.2 使用Helm部署dashboard</a></li></ul></li><li><a href=#faq>FAQ</a></li><li><a href=#参考>参考</a></li></ul></nav></div></nav></aside><div id=content class=content><article class=post><header class=post-header><h1 class=post-title>kubeadm startup Kubernetes more than v1.20.0 (centos7+containerd+ipvs+calico)</h1><div class=post-meta-list><div class="post-meta-item post-meta-author"><svg aria-hidden="true" class="lucide lucide-user-round-pen hi-svg-inline" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M2 21a8 8 0 0110.821-7.487"/><path d="M21.378 16.626a1 1 0 00-3.004-3.004l-4.01 4.012a2 2 0 00-.506.854l-.837 2.87a.5.5.0 00.62.62l2.87-.837a2 2 0 00.854-.506z"/><circle cx="10" cy="8" r="5"/></svg>
<a href=/about><span class=post-meta-author-name>yesplease</span></a></div><div class="post-meta-item post-meta-time"><svg aria-hidden="true" class="lucide lucide-calendar-days hi-svg-inline" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M8 2v4"/><path d="M16 2v4"/><rect width="18" height="18" x="3" y="4" rx="2"/><path d="M3 10h18"/><path d="M8 14h.01"/><path d="M12 14h.01"/><path d="M16 14h.01"/><path d="M8 18h.01"/><path d="M12 18h.01"/><path d="M16 18h.01"/></svg>
<time datetime=2022-03-01>2022-03-01</time></div><div class=post-meta__right><div class="post-meta-item post-meta-category"><a href=http://localhost:1313/categories/kubernetes/>kubernetes</a>
<a href=http://localhost:1313/categories/cloudnative/>cloudnative</a></div></div></div></header><div class=post-content><p>这篇文章的作者部署的是kubernetes v1.23，但其实是基于kubernetes对CRI的改动执行的较为流行的方案。</p><p>我绝的主要是针对Docker的支持问题，因为在1.24中才正式将docker-shim剔除。以下列举了较为流行的部署方案：</p><ul><li><p>kubernetes &lt; 1.20 + centos7 + docker + iptables + flannel</p></li><li><p>kubernetes &lt; 1.20 + centos7 + docker + ipvs + calico</p></li><li><p>1.20 &lt;kubernetes &lt; 1.24 + centos7 + docker + ipvs + calico</p></li><li><p>kubernetes > 1.24 + centos7 + containerd + ipvs + calico</p></li><li><p>kubernetes > 1.24 + centos7 + cri-o + ipvs + calico</p></li><li><p>kubernetes > 1.24 + centos7 + cri-dockerd + docker + ipvs + calico</p></li></ul><p><a href=https://blog.frognew.com/2021/12/kubeadm-install-kubernetes-1.23.html#1%E5%87%86%E5%A4%87>转载声明：使用kubeadm部署Kubernetes 1.23</a></p><p>kubeadm是Kubernetes官方提供的用于快速安部署Kubernetes集群的工具，伴随Kubernetes每个版本的发布都会同步更新，kubeadm会对集群配置方面的一些实践做调整，通过实验kubeadm可以学习到Kubernetes官方在集群配置上一些新的最佳实践。</p><h2 id=1准备>1.准备</h2><h3 id=11-系统配置>1.1 系统配置</h3><p>在安装之前，需要先做好如下准备。3台CentOS 7.9主机如下：</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>cat /etc/hosts
</span></span><span style=display:flex><span>192.168.96.151    node1
</span></span><span style=display:flex><span>192.168.96.152    node2
</span></span><span style=display:flex><span>192.168.96.153    node3</span></span></code></pre></div></div><p>在<strong>各个主机</strong>上完成下面的系统配置。</p><ul><li>yum:</li></ul><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#75715e>#备份本地 yum 源</span>
</span></span><span style=display:flex><span>$ mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo_bak 
</span></span><span style=display:flex><span><span style=color:#75715e># 获取阿里 yum 源配置文件</span>
</span></span><span style=display:flex><span>$ wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 
</span></span><span style=display:flex><span><span style=color:#75715e>#清理 yum</span>
</span></span><span style=display:flex><span>$ yum clean all
</span></span><span style=display:flex><span><span style=color:#75715e>#更新软件版本并且更新现有软件</span>
</span></span><span style=display:flex><span>$ yum -y update</span></span></code></pre></div></div><ul><li>防火墙：</li></ul><p>如果各个主机启用了防火墙策略，需要开放Kubernetes各个组件所需要的端口，可以查看<a href=https://kubernetes.io/docs/setup/independent/install-kubeadm/>Installing kubeadm</a>中的"Check required ports"一节开放相关端口或者关闭主机的防火墙。</p><ul><li>禁用SELINUX：</li></ul><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>setenforce <span style=color:#ae81ff>0</span></span></span></code></pre></div></div><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>vi /etc/selinux/config
</span></span><span style=display:flex><span>SELINUX<span style=color:#f92672>=</span>disabled</span></span></code></pre></div></div><ul><li>加载需要的内核模块</li></ul><p>创建/etc/modules-load.d/containerd.conf配置文件:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>cat <span style=color:#e6db74>&lt;&lt; EOF &gt; /etc/modules-load.d/containerd.conf
</span></span></span><span style=display:flex><span><span style=color:#e6db74>overlay
</span></span></span><span style=display:flex><span><span style=color:#e6db74>br_netfilter
</span></span></span><span style=display:flex><span><span style=color:#e6db74>EOF</span></span></span></code></pre></div></div><p>执行以下命令使配置生效:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>modprobe overlay
</span></span><span style=display:flex><span>modprobe br_netfilter</span></span></code></pre></div></div><p>创建/etc/sysctl.d/99-kubernetes-cri.conf配置文件：</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>cat <span style=color:#e6db74>&lt;&lt; EOF &gt; /etc/sysctl.d/99-kubernetes-cri.conf
</span></span></span><span style=display:flex><span><span style=color:#e6db74>net.bridge.bridge-nf-call-ip6tables = 1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>net.bridge.bridge-nf-call-iptables = 1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>net.ipv4.ip_forward = 1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>user.max_user_namespaces=28633
</span></span></span><span style=display:flex><span><span style=color:#e6db74>EOF</span></span></span></code></pre></div></div><p>执行以下命令使配置生效:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>sysctl -p /etc/sysctl.d/99-kubernetes-cri.conf</span></span></code></pre></div></div><ul><li>配置服务器支持开启ipvs的前提条件</li></ul><p>由于ipvs已经加入到了内核的主干，所以为kube-proxy开启ipvs的前提需要加载以下的内核模块：</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>ip_vs
</span></span><span style=display:flex><span>ip_vs_rr
</span></span><span style=display:flex><span>ip_vs_wrr
</span></span><span style=display:flex><span>ip_vs_sh
</span></span><span style=display:flex><span>nf_conntrack_ipv4 </span></span></code></pre></div></div><p>在各个服务器节点上执行以下脚本:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>cat &gt; /etc/sysconfig/modules/ipvs.modules <span style=color:#e6db74>&lt;&lt;EOF
</span></span></span><span style=display:flex><span><span style=color:#e6db74>#!/bin/bash
</span></span></span><span style=display:flex><span><span style=color:#e6db74>modprobe -- ip_vs
</span></span></span><span style=display:flex><span><span style=color:#e6db74>modprobe -- ip_vs_rr
</span></span></span><span style=display:flex><span><span style=color:#e6db74>modprobe -- ip_vs_wrr
</span></span></span><span style=display:flex><span><span style=color:#e6db74>modprobe -- ip_vs_sh
</span></span></span><span style=display:flex><span><span style=color:#e6db74>modprobe -- nf_conntrack_ipv4
</span></span></span><span style=display:flex><span><span style=color:#e6db74>EOF</span>
</span></span><span style=display:flex><span>chmod <span style=color:#ae81ff>755</span> /etc/sysconfig/modules/ipvs.modules <span style=color:#f92672>&amp;&amp;</span> bash /etc/sysconfig/modules/ipvs.modules <span style=color:#f92672>&amp;&amp;</span> lsmod | grep -e ip_vs -e nf_conntrack_ipv4</span></span></code></pre></div></div><blockquote><p>注：内核4版本以上 nf_conntrack 替换 nf_conntrack_ipv4</p></blockquote><p>上面脚本创建了的<code>/etc/sysconfig/modules/ipvs.modules</code>文件，保证在节点重启后能自动加载所需模块。 使用<code>lsmod | grep -e ip_vs -e nf_conntrack_ipv4</code>命令查看是否已经正确加载所需的内核模块。</p><p>接下来还需要确保各个节点上已经安装了ipset软件包，为了便于查看ipvs的代理规则，最好安装一下管理工具ipvsadm。</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>yum install -y ipset ipvsadm</span></span></code></pre></div></div><p>如果以上前提条件如果不满足，则即使kube-proxy的配置开启了ipvs模式，也会退回到iptables模式。</p><h3 id=12-部署容器运行时containerd>1.2 部署容器运行时Containerd</h3><p>在各个服务器节点上安装容器运行时Containerd。</p><p>下载Containerd的二进制包:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>wget https://github.com/containerd/containerd/releases/download/v1.5.8/cri-containerd-cni-1.5.8-linux-amd64.tar.gz</span></span></code></pre></div></div><p><code>cri-containerd-cni-1.5.8-linux-amd64.tar.gz</code>压缩包中已经按照官方二进制部署推荐的目录结构布局好。 里面包含了systemd配置文件，containerd以及cni的部署文件。 将解压缩到系统的根目录<code>/</code>中:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>tar -zxvf cri-containerd-cni-1.5.8-linux-amd64.tar.gz -C /
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>etc/
</span></span><span style=display:flex><span>etc/systemd/
</span></span><span style=display:flex><span>etc/systemd/system/
</span></span><span style=display:flex><span>etc/systemd/system/containerd.service
</span></span><span style=display:flex><span>etc/crictl.yaml
</span></span><span style=display:flex><span>etc/cni/
</span></span><span style=display:flex><span>etc/cni/net.d/
</span></span><span style=display:flex><span>etc/cni/net.d/10-containerd-net.conflist
</span></span><span style=display:flex><span>usr/
</span></span><span style=display:flex><span>usr/local/
</span></span><span style=display:flex><span>usr/local/sbin/
</span></span><span style=display:flex><span>usr/local/sbin/runc
</span></span><span style=display:flex><span>usr/local/bin/
</span></span><span style=display:flex><span>usr/local/bin/critest
</span></span><span style=display:flex><span>usr/local/bin/containerd-shim
</span></span><span style=display:flex><span>usr/local/bin/containerd-shim-runc-v1
</span></span><span style=display:flex><span>usr/local/bin/ctd-decoder
</span></span><span style=display:flex><span>usr/local/bin/containerd
</span></span><span style=display:flex><span>usr/local/bin/containerd-shim-runc-v2
</span></span><span style=display:flex><span>usr/local/bin/containerd-stress
</span></span><span style=display:flex><span>usr/local/bin/ctr
</span></span><span style=display:flex><span>usr/local/bin/crictl
</span></span><span style=display:flex><span>......
</span></span><span style=display:flex><span>opt/cni/
</span></span><span style=display:flex><span>opt/cni/bin/
</span></span><span style=display:flex><span>opt/cni/bin/bridge
</span></span><span style=display:flex><span>......</span></span></code></pre></div></div><p>注意经测试cri-containerd-cni-1.5.8-linux-amd64.tar.gz包中包含的runc在CentOS 7下的动态链接有问题，这里从runc的github上单独下载runc，并替换上面安装的containerd中的runc</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>wget https://github.com/opencontainers/runc/releases/download/v1.1.0-rc.1/runc.amd64</span></span></code></pre></div></div><p>接下来生成containerd的配置文件:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>mkdir -p /etc/containerd
</span></span><span style=display:flex><span>containerd config default &gt; /etc/containerd/config.toml</span></span></code></pre></div></div><p>根据文档<a href=https://kubernetes.io/docs/setup/production-environment/container-runtimes/>Container runtimes </a>中的内容，对于使用systemd作为init system的Linux的发行版，使用systemd作为容器的cgroup driver可以确保服务器节点在资源紧张的情况更加稳定，因此这里配置各个节点上containerd的cgroup driver为systemd。</p><p>修改前面生成的配置文件<code>/etc/containerd/config.toml</code>：</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>plugins.<span style=color:#e6db74>&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.runc<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>  ...
</span></span><span style=display:flex><span>  <span style=color:#f92672>[</span>plugins.<span style=color:#e6db74>&#34;io.containerd.grpc.v1.cri&#34;</span>.containerd.runtimes.runc.options<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>    SystemdCgroup <span style=color:#f92672>=</span> true</span></span></code></pre></div></div><p>再修改<code>/etc/containerd/config.toml</code>中的</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#f92672>[</span>plugins.<span style=color:#e6db74>&#34;io.containerd.grpc.v1.cri&#34;</span><span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>  ...
</span></span><span style=display:flex><span>  <span style=color:#75715e># sandbox_image = &#34;k8s.gcr.io/pause:3.5&#34;</span>
</span></span><span style=display:flex><span>  sandbox_image <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;registry.aliyuncs.com/google_containers/pause:3.6&#34;</span></span></span></code></pre></div></div><p>配置containerd开机启动，并启动containerd</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>systemctl enable containerd --now</span></span></code></pre></div></div><p>使用crictl测试一下，确保可以打印出版本信息并且没有错误信息输出:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>crictl version
</span></span><span style=display:flex><span>Version:  0.1.0
</span></span><span style=display:flex><span>RuntimeName:  containerd
</span></span><span style=display:flex><span>RuntimeVersion:  v1.5.8
</span></span><span style=display:flex><span>RuntimeApiVersion:  v1alpha2</span></span></code></pre></div></div><h2 id=2使用kubeadm部署kubernetes>2.使用kubeadm部署Kubernetes</h2><h3 id=21-安装kubeadm和kubelet>2.1 安装kubeadm和kubelet</h3><p>下面在各节点安装kubeadm和kubelet：</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>cat <span style=color:#e6db74>&lt;&lt;EOF &gt; /etc/yum.repos.d/kubernetes.repo
</span></span></span><span style=display:flex><span><span style=color:#e6db74>[kubernetes]
</span></span></span><span style=display:flex><span><span style=color:#e6db74>name=Kubernetes
</span></span></span><span style=display:flex><span><span style=color:#e6db74>baseurl=http://mirrors.aliyun.com/kubernetes/yum/repos/kubernetes-el7-x86_64
</span></span></span><span style=display:flex><span><span style=color:#e6db74>enabled=1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>gpgcheck=1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>repo_gpgcheck=1
</span></span></span><span style=display:flex><span><span style=color:#e6db74>gpgkey=http://mirrors.aliyun.com/kubernetes/yum/doc/yum-key.gpg
</span></span></span><span style=display:flex><span><span style=color:#e6db74>        http://mirrors.aliyun.com/kubernetes/yum/doc/rpm-package-key.gpg
</span></span></span><span style=display:flex><span><span style=color:#e6db74>EOF</span></span></span></code></pre></div></div><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>yum makecache fast
</span></span><span style=display:flex><span>yum install kubelet kubeadm kubectl</span></span></code></pre></div></div><p>运行<code>kubelet --help</code>可以看到原来kubelet的绝大多数命令行flag参数都被<code>DEPRECATED</code>了，官方推荐我们使用<code>--config</code>指定配置文件，并在配置文件中指定原来这些flag所配置的内容。具体内容可以查看这里<a href=https://kubernetes.io/docs/tasks/administer-cluster/kubelet-config-file/>Set Kubelet parameters via a config file</a>。这也是Kubernetes为了支持动态Kubelet配置（Dynamic Kubelet Configuration）才这么做的，参考<a href=https://kubernetes.io/docs/tasks/administer-cluster/reconfigure-kubelet/>Reconfigure a Node’s Kubelet in a Live Cluster</a>。</p><p>kubelet的配置文件必须是json或yaml格式，具体可查看<a href=https://github.com/kubernetes/kubelet/blob/release-1.23/config/v1beta1/types.go>这里</a>。</p><p>Kubernetes 1.8开始要求关闭系统的Swap，如果不关闭，默认配置下kubelet将无法启动。 关闭系统的Swap方法如下:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>swapoff -a</span></span></code></pre></div></div><p>修改 /etc/fstab 文件，注释掉 SWAP 的自动挂载，使用<code>free -m</code>确认swap已经关闭。</p><p>swappiness参数调整，修改/etc/sysctl.d/99-kubernetes-cri.conf添加下面一行：</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>vm.swappiness<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span></span></span></code></pre></div></div><p>执行<code>sysctl -p /etc/sysctl.d/99-kubernetes-cri.conf</code>使修改生效。</p><h3 id=22-使用kubeadm-init初始化集群>2.2 使用kubeadm init初始化集群</h3><p>在各节点开机启动kubelet服务：</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>systemctl enable kubelet.service</span></span></code></pre></div></div><p>使用<code>kubeadm config print init-defaults --component-configs KubeletConfiguration</code>可以打印集群初始化默认的使用的配置：</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>apiVersion: kubeadm.k8s.io/v1beta3
</span></span><span style=display:flex><span>bootstrapTokens:
</span></span><span style=display:flex><span>- groups:
</span></span><span style=display:flex><span>  - system:bootstrappers:kubeadm:default-node-token
</span></span><span style=display:flex><span>  token: abcdef.0123456789abcdef
</span></span><span style=display:flex><span>  ttl: 24h0m0s
</span></span><span style=display:flex><span>  usages:
</span></span><span style=display:flex><span>  - signing
</span></span><span style=display:flex><span>  - authentication
</span></span><span style=display:flex><span>kind: InitConfiguration
</span></span><span style=display:flex><span>localAPIEndpoint:
</span></span><span style=display:flex><span>  advertiseAddress: 1.2.3.4
</span></span><span style=display:flex><span>  bindPort: <span style=color:#ae81ff>6443</span>
</span></span><span style=display:flex><span>nodeRegistration:
</span></span><span style=display:flex><span>  criSocket: /var/run/dockershim.sock
</span></span><span style=display:flex><span>  imagePullPolicy: IfNotPresent
</span></span><span style=display:flex><span>  name: node
</span></span><span style=display:flex><span>  taints: null
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiServer:
</span></span><span style=display:flex><span>  timeoutForControlPlane: 4m0s
</span></span><span style=display:flex><span>apiVersion: kubeadm.k8s.io/v1beta3
</span></span><span style=display:flex><span>certificatesDir: /etc/kubernetes/pki
</span></span><span style=display:flex><span>clusterName: kubernetes
</span></span><span style=display:flex><span>controllerManager: <span style=color:#f92672>{}</span>
</span></span><span style=display:flex><span>dns: <span style=color:#f92672>{}</span>
</span></span><span style=display:flex><span>etcd:
</span></span><span style=display:flex><span>  local:
</span></span><span style=display:flex><span>    dataDir: /var/lib/etcd
</span></span><span style=display:flex><span>imageRepository: k8s.gcr.io
</span></span><span style=display:flex><span>kind: ClusterConfiguration
</span></span><span style=display:flex><span>kubernetesVersion: 1.23.0
</span></span><span style=display:flex><span>networking:
</span></span><span style=display:flex><span>  dnsDomain: cluster.local
</span></span><span style=display:flex><span>  serviceSubnet: 10.96.0.0/12
</span></span><span style=display:flex><span>scheduler: <span style=color:#f92672>{}</span>
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: kubelet.config.k8s.io/v1beta1
</span></span><span style=display:flex><span>authentication:
</span></span><span style=display:flex><span>  anonymous:
</span></span><span style=display:flex><span>    enabled: false
</span></span><span style=display:flex><span>  webhook:
</span></span><span style=display:flex><span>    cacheTTL: 0s
</span></span><span style=display:flex><span>    enabled: true
</span></span><span style=display:flex><span>  x509:
</span></span><span style=display:flex><span>    clientCAFile: /etc/kubernetes/pki/ca.crt
</span></span><span style=display:flex><span>authorization:
</span></span><span style=display:flex><span>  mode: Webhook
</span></span><span style=display:flex><span>  webhook:
</span></span><span style=display:flex><span>    cacheAuthorizedTTL: 0s
</span></span><span style=display:flex><span>    cacheUnauthorizedTTL: 0s
</span></span><span style=display:flex><span>cgroupDriver: systemd
</span></span><span style=display:flex><span>clusterDNS:
</span></span><span style=display:flex><span>- 10.96.0.10
</span></span><span style=display:flex><span>clusterDomain: cluster.local
</span></span><span style=display:flex><span>cpuManagerReconcilePeriod: 0s
</span></span><span style=display:flex><span>evictionPressureTransitionPeriod: 0s
</span></span><span style=display:flex><span>fileCheckFrequency: 0s
</span></span><span style=display:flex><span>healthzBindAddress: 127.0.0.1
</span></span><span style=display:flex><span>healthzPort: <span style=color:#ae81ff>10248</span>
</span></span><span style=display:flex><span>httpCheckFrequency: 0s
</span></span><span style=display:flex><span>imageMinimumGCAge: 0s
</span></span><span style=display:flex><span>kind: KubeletConfiguration
</span></span><span style=display:flex><span>logging:
</span></span><span style=display:flex><span>  flushFrequency: <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>  options:
</span></span><span style=display:flex><span>    json:
</span></span><span style=display:flex><span>      infoBufferSize: <span style=color:#e6db74>&#34;0&#34;</span>
</span></span><span style=display:flex><span>  verbosity: <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>memorySwap: <span style=color:#f92672>{}</span>
</span></span><span style=display:flex><span>nodeStatusReportFrequency: 0s
</span></span><span style=display:flex><span>nodeStatusUpdateFrequency: 0s
</span></span><span style=display:flex><span>rotateCertificates: true
</span></span><span style=display:flex><span>runtimeRequestTimeout: 0s
</span></span><span style=display:flex><span>shutdownGracePeriod: 0s
</span></span><span style=display:flex><span>shutdownGracePeriodCriticalPods: 0s
</span></span><span style=display:flex><span>staticPodPath: /etc/kubernetes/manifests
</span></span><span style=display:flex><span>streamingConnectionIdleTimeout: 0s
</span></span><span style=display:flex><span>syncFrequency: 0s
</span></span><span style=display:flex><span>volumeStatsAggPeriod: 0s</span></span></code></pre></div></div><p>从默认的配置中可以看到，可以使用<code>imageRepository</code>定制在集群初始化时拉取k8s所需镜像的地址。基于默认配置定制出本次使用kubeadm初始化集群所需的配置文件kubeadm.yaml：</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>apiVersion: kubeadm.k8s.io/v1beta3
</span></span><span style=display:flex><span>kind: InitConfiguration
</span></span><span style=display:flex><span>localAPIEndpoint:
</span></span><span style=display:flex><span>  advertiseAddress: 192.168.96.151
</span></span><span style=display:flex><span>  bindPort: <span style=color:#ae81ff>6443</span>
</span></span><span style=display:flex><span>nodeRegistration:
</span></span><span style=display:flex><span>  criSocket: /run/containerd/containerd.sock
</span></span><span style=display:flex><span>  taints:
</span></span><span style=display:flex><span>  - effect: PreferNoSchedule
</span></span><span style=display:flex><span>    key: node-role.kubernetes.io/master
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: kubeadm.k8s.io/v1beta2
</span></span><span style=display:flex><span>kind: ClusterConfiguration
</span></span><span style=display:flex><span>kubernetesVersion: v1.22.0
</span></span><span style=display:flex><span>imageRepository: registry.aliyuncs.com/google_containers
</span></span><span style=display:flex><span>networking:
</span></span><span style=display:flex><span>  podSubnet: 10.244.0.0/16
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: kubelet.config.k8s.io/v1beta1
</span></span><span style=display:flex><span>kind: KubeletConfiguration
</span></span><span style=display:flex><span>cgroupDriver: systemd
</span></span><span style=display:flex><span>failSwapOn: false
</span></span><span style=display:flex><span>---
</span></span><span style=display:flex><span>apiVersion: kubeproxy.config.k8s.io/v1alpha1
</span></span><span style=display:flex><span>kind: KubeProxyConfiguration
</span></span><span style=display:flex><span>mode: ipvs</span></span></code></pre></div></div><p>这里定制了<code>imageRepository</code>为阿里云的registry，避免因gcr被墙，无法直接拉取镜像。<code>criSocket</code>设置了容器运行时为containerd。 同时设置kubelet的<code>cgroupDriver</code>为systemd，设置kube-proxy代理模式为ipvs。</p><p>在开始初始化集群之前可以使用<code>kubeadm config images pull --config kubeadm.yaml</code>预先在各个服务器节点上拉取所k8s需要的容器镜像。</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubeadm config images pull --config kubeadm.yaml
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>config/images<span style=color:#f92672>]</span> Pulled registry.aliyuncs.com/google_containers/kube-apiserver:v1.23.1
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>config/images<span style=color:#f92672>]</span> Pulled registry.aliyuncs.com/google_containers/kube-controller-manager:v1.23.1
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>config/images<span style=color:#f92672>]</span> Pulled registry.aliyuncs.com/google_containers/kube-scheduler:v1.23.1
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>config/images<span style=color:#f92672>]</span> Pulled registry.aliyuncs.com/google_containers/kube-proxy:v1.23.1
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>config/images<span style=color:#f92672>]</span> Pulled registry.aliyuncs.com/google_containers/pause:3.6
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>config/images<span style=color:#f92672>]</span> Pulled registry.aliyuncs.com/google_containers/etcd:3.5.1-0
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>config/images<span style=color:#f92672>]</span> Pulled registry.aliyuncs.com/google_containers/coredns:v1.8.6</span></span></code></pre></div></div><p>接下来使用kubeadm初始化集群，选择node1作为Master Node，在node1上执行下面的命令：</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubeadm init --config kubeadm.yaml
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>init<span style=color:#f92672>]</span> Using Kubernetes version: v1.23.1
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>preflight<span style=color:#f92672>]</span> Running pre-flight checks
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>preflight<span style=color:#f92672>]</span> Pulling images required <span style=color:#66d9ef>for</span> setting up a Kubernetes cluster
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>preflight<span style=color:#f92672>]</span> This might take a minute or two, depending on the speed of your internet connection
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>preflight<span style=color:#f92672>]</span> You can also perform this action in beforehand using <span style=color:#e6db74>&#39;kubeadm config images pull&#39;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>certs<span style=color:#f92672>]</span> Using certificateDir folder <span style=color:#e6db74>&#34;/etc/kubernetes/pki&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>certs<span style=color:#f92672>]</span> Generating <span style=color:#e6db74>&#34;ca&#34;</span> certificate and key
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>certs<span style=color:#f92672>]</span> Generating <span style=color:#e6db74>&#34;apiserver&#34;</span> certificate and key
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>certs<span style=color:#f92672>]</span> apiserver serving cert is signed <span style=color:#66d9ef>for</span> DNS names <span style=color:#f92672>[</span>kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local node1<span style=color:#f92672>]</span> and IPs <span style=color:#f92672>[</span>10.96.0.1 192.168.96.151<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>certs<span style=color:#f92672>]</span> Generating <span style=color:#e6db74>&#34;apiserver-kubelet-client&#34;</span> certificate and key
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>certs<span style=color:#f92672>]</span> Generating <span style=color:#e6db74>&#34;front-proxy-ca&#34;</span> certificate and key
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>certs<span style=color:#f92672>]</span> Generating <span style=color:#e6db74>&#34;front-proxy-client&#34;</span> certificate and key
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>certs<span style=color:#f92672>]</span> Generating <span style=color:#e6db74>&#34;etcd/ca&#34;</span> certificate and key
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>certs<span style=color:#f92672>]</span> Generating <span style=color:#e6db74>&#34;etcd/server&#34;</span> certificate and key
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>certs<span style=color:#f92672>]</span> etcd/server serving cert is signed <span style=color:#66d9ef>for</span> DNS names <span style=color:#f92672>[</span>localhost node1<span style=color:#f92672>]</span> and IPs <span style=color:#f92672>[</span>192.168.96.151 127.0.0.1 ::1<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>certs<span style=color:#f92672>]</span> Generating <span style=color:#e6db74>&#34;etcd/peer&#34;</span> certificate and key
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>certs<span style=color:#f92672>]</span> etcd/peer serving cert is signed <span style=color:#66d9ef>for</span> DNS names <span style=color:#f92672>[</span>localhost node1<span style=color:#f92672>]</span> and IPs <span style=color:#f92672>[</span>192.168.96.151 127.0.0.1 ::1<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>certs<span style=color:#f92672>]</span> Generating <span style=color:#e6db74>&#34;etcd/healthcheck-client&#34;</span> certificate and key
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>certs<span style=color:#f92672>]</span> Generating <span style=color:#e6db74>&#34;apiserver-etcd-client&#34;</span> certificate and key
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>certs<span style=color:#f92672>]</span> Generating <span style=color:#e6db74>&#34;sa&#34;</span> key and public key
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>kubeconfig<span style=color:#f92672>]</span> Using kubeconfig folder <span style=color:#e6db74>&#34;/etc/kubernetes&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>kubeconfig<span style=color:#f92672>]</span> Writing <span style=color:#e6db74>&#34;admin.conf&#34;</span> kubeconfig file
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>kubeconfig<span style=color:#f92672>]</span> Writing <span style=color:#e6db74>&#34;kubelet.conf&#34;</span> kubeconfig file
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>kubeconfig<span style=color:#f92672>]</span> Writing <span style=color:#e6db74>&#34;controller-manager.conf&#34;</span> kubeconfig file
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>kubeconfig<span style=color:#f92672>]</span> Writing <span style=color:#e6db74>&#34;scheduler.conf&#34;</span> kubeconfig file
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>kubelet-start<span style=color:#f92672>]</span> Writing kubelet environment file with flags to file <span style=color:#e6db74>&#34;/var/lib/kubelet/kubeadm-flags.env&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>kubelet-start<span style=color:#f92672>]</span> Writing kubelet configuration to file <span style=color:#e6db74>&#34;/var/lib/kubelet/config.yaml&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>kubelet-start<span style=color:#f92672>]</span> Starting the kubelet
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>control-plane<span style=color:#f92672>]</span> Using manifest folder <span style=color:#e6db74>&#34;/etc/kubernetes/manifests&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>control-plane<span style=color:#f92672>]</span> Creating static Pod manifest <span style=color:#66d9ef>for</span> <span style=color:#e6db74>&#34;kube-apiserver&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>control-plane<span style=color:#f92672>]</span> Creating static Pod manifest <span style=color:#66d9ef>for</span> <span style=color:#e6db74>&#34;kube-controller-manager&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>control-plane<span style=color:#f92672>]</span> Creating static Pod manifest <span style=color:#66d9ef>for</span> <span style=color:#e6db74>&#34;kube-scheduler&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>etcd<span style=color:#f92672>]</span> Creating static Pod manifest <span style=color:#66d9ef>for</span> local etcd in <span style=color:#e6db74>&#34;/etc/kubernetes/manifests&#34;</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>wait-control-plane<span style=color:#f92672>]</span> Waiting <span style=color:#66d9ef>for</span> the kubelet to boot up the control plane as static Pods from directory <span style=color:#e6db74>&#34;/etc/kubernetes/manifests&#34;</span>. This can take up to 4m0s
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>apiclient<span style=color:#f92672>]</span> All control plane components are healthy after 16.003580 seconds
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>upload-config<span style=color:#f92672>]</span> Storing the configuration used in ConfigMap <span style=color:#e6db74>&#34;kubeadm-config&#34;</span> in the <span style=color:#e6db74>&#34;kube-system&#34;</span> Namespace
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>kubelet<span style=color:#f92672>]</span> Creating a ConfigMap <span style=color:#e6db74>&#34;kubelet-config-1.23&#34;</span> in namespace kube-system with the configuration <span style=color:#66d9ef>for</span> the kubelets in the cluster
</span></span><span style=display:flex><span>NOTE: The <span style=color:#e6db74>&#34;kubelet-config-1.23&#34;</span> naming of the kubelet ConfigMap is deprecated. Once the UnversionedKubeletConfigMap feature gate graduates to Beta the default name will become just <span style=color:#e6db74>&#34;kubelet-config&#34;</span>. Kubeadm upgrade will handle this transition transparently.
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>upload-certs<span style=color:#f92672>]</span> Skipping phase. Please see --upload-certs
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>mark-control-plane<span style=color:#f92672>]</span> Marking the node node1 as control-plane by adding the labels: <span style=color:#f92672>[</span>node-role.kubernetes.io/master<span style=color:#f92672>(</span>deprecated<span style=color:#f92672>)</span> node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>mark-control-plane<span style=color:#f92672>]</span> Marking the node node1 as control-plane by adding the taints <span style=color:#f92672>[</span>node-role.kubernetes.io/master:PreferNoSchedule<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>bootstrap-token<span style=color:#f92672>]</span> Using token: o7d0h6.i9taufdl7u1un4va
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>bootstrap-token<span style=color:#f92672>]</span> Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>bootstrap-token<span style=color:#f92672>]</span> configured RBAC rules to allow Node Bootstrap tokens to get nodes
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>bootstrap-token<span style=color:#f92672>]</span> configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order <span style=color:#66d9ef>for</span> nodes to get long term certificate credentials
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>bootstrap-token<span style=color:#f92672>]</span> configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>bootstrap-token<span style=color:#f92672>]</span> configured RBAC rules to allow certificate rotation <span style=color:#66d9ef>for</span> all node client certificates in the cluster
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>bootstrap-token<span style=color:#f92672>]</span> Creating the <span style=color:#e6db74>&#34;cluster-info&#34;</span> ConfigMap in the <span style=color:#e6db74>&#34;kube-public&#34;</span> namespace
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>kubelet-finalize<span style=color:#f92672>]</span> Updating <span style=color:#e6db74>&#34;/etc/kubernetes/kubelet.conf&#34;</span> to point to a rotatable kubelet client certificate and key
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>addons<span style=color:#f92672>]</span> Applied essential addon: CoreDNS
</span></span><span style=display:flex><span><span style=color:#f92672>[</span>addons<span style=color:#f92672>]</span> Applied essential addon: kube-proxy
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Your Kubernetes control-plane has initialized successfully!
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>To start using your cluster, you need to run the following as a regular user:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  mkdir -p $HOME/.kube
</span></span><span style=display:flex><span>  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style=display:flex><span>  sudo chown <span style=color:#66d9ef>$(</span>id -u<span style=color:#66d9ef>)</span>:<span style=color:#66d9ef>$(</span>id -g<span style=color:#66d9ef>)</span> $HOME/.kube/config
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Alternatively, <span style=color:#66d9ef>if</span> you are the root user, you can run:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>  export KUBECONFIG<span style=color:#f92672>=</span>/etc/kubernetes/admin.conf
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>You should now deploy a pod network to the cluster.
</span></span><span style=display:flex><span>Run <span style=color:#e6db74>&#34;kubectl apply -f [podnetwork].yaml&#34;</span> with one of the options listed at:
</span></span><span style=display:flex><span>  https://kubernetes.io/docs/concepts/cluster-administration/addons/
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>Then you can join any number of worker nodes by running the following on each as root:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>kubeadm join 192.168.96.151:6443 --token o7d0h6.i9taufdl7u1un4va <span style=color:#ae81ff>\
</span></span></span><span style=display:flex><span><span style=color:#ae81ff></span>	--discovery-token-ca-cert-hash sha256:6c55b14e9d71ef098ad0e8f249d85004c41b48063dbcd7692997930f9637f22b</span></span></code></pre></div></div><p>上面记录了完成的初始化输出的内容，根据输出的内容基本上可以看出手动初始化安装一个Kubernetes集群所需要的关键步骤。 其中有以下关键内容：</p><ul><li><code>[certs]</code>生成相关的各种证书</li><li><code>[kubeconfig]</code>生成相关的kubeconfig文件</li><li><code>[kubelet-start]</code> 生成kubelet的配置文件"/var/lib/kubelet/config.yaml"</li><li><code>[control-plane]</code>使用<code>/etc/kubernetes/manifests</code>目录中的yaml文件创建apiserver、controller-manager、scheduler的静态pod</li><li><code>[bootstraptoken]</code>生成token记录下来，后边使用<code>kubeadm join</code>往集群中添加节点时会用到</li><li>下面的命令是配置常规用户如何使用kubectl访问集群：</li></ul><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>mkdir -p $HOME/.kube
</span></span><span style=display:flex><span>sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
</span></span><span style=display:flex><span>sudo chown <span style=color:#66d9ef>$(</span>id -u<span style=color:#66d9ef>)</span>:<span style=color:#66d9ef>$(</span>id -g<span style=color:#66d9ef>)</span> $HOME/.kube/config</span></span></code></pre></div></div><ul><li>最后给出了将节点加入集群的命令<code>kubeadm join 192.168.96.151:6443 --token o7d0h6.i9taufdl7u1un4va \ --discovery-token-ca-cert-hash sha256:6c55b14e9d71ef098ad0e8f249d85004c41b48063dbcd7692997930f9637f22b</code></li></ul><p>查看一下集群状态，确认个组件都处于healthy状态，结果出现了错误:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl get cs
</span></span><span style=display:flex><span>Warning: v1 ComponentStatus is deprecated in v1.19+
</span></span><span style=display:flex><span>NAME                 STATUS      MESSAGE                                                                                       ERROR
</span></span><span style=display:flex><span>controller-manager   Unhealthy   Get <span style=color:#e6db74>&#34;http://127.0.0.1:10252/healthz&#34;</span>: dial tcp 127.0.0.1:10252: connect: connection refused
</span></span><span style=display:flex><span>scheduler            Unhealthy   Get <span style=color:#e6db74>&#34;http://127.0.0.1:10251/healthz&#34;</span>: dial tcp 127.0.0.1:10251: connect: connection refused
</span></span><span style=display:flex><span>etcd-0               Healthy     <span style=color:#f92672>{</span><span style=color:#e6db74>&#34;health&#34;</span>:<span style=color:#e6db74>&#34;true&#34;</span><span style=color:#f92672>}</span></span></span></code></pre></div></div><p>controller-manager和scheduler为不健康状态，修改<code>/etc/kubernetes/manifests/</code>下的静态pod配置文件<code>kube-controller-manager.yaml</code>和<code>kube-scheduler.yaml</code>，删除这两个文件中命令选项中的<code>- --port=0</code>这行，重启kubelet，再次查看一切正常。</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl get cs
</span></span><span style=display:flex><span>Warning: v1 ComponentStatus is deprecated in v1.19+
</span></span><span style=display:flex><span>NAME                 STATUS    MESSAGE                         ERROR
</span></span><span style=display:flex><span>scheduler            Healthy   ok
</span></span><span style=display:flex><span>controller-manager   Healthy   ok
</span></span><span style=display:flex><span>etcd-0               Healthy   <span style=color:#f92672>{</span><span style=color:#e6db74>&#34;health&#34;</span>:<span style=color:#e6db74>&#34;true&#34;</span>,<span style=color:#e6db74>&#34;reason&#34;</span>:<span style=color:#e6db74>&#34;&#34;</span><span style=color:#f92672>}</span></span></span></code></pre></div></div><p>集群初始化如果遇到问题，可以使用<code>kubeadm reset</code>命令进行清理。</p><h3 id=23-安装包管理器helm-3>2.3 安装包管理器helm 3</h3><p>Helm是Kubernetes的包管理器，后续流程也将使用Helm安装Kubernetes的常用组件。 这里先在master节点node1上按照helm。</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>wget https://get.helm.sh/helm-v3.7.2-linux-amd64.tar.gz
</span></span><span style=display:flex><span>tar -zxvf helm-v3.7.2-linux-amd64.tar.gz
</span></span><span style=display:flex><span>mv linux-amd64/helm  /usr/local/bin/</span></span></code></pre></div></div><p>执行<code>helm list</code>确认没有错误输出。</p><h3 id=24-部署pod-network组件calico>2.4 部署Pod Network组件Calico</h3><p>选择calico作为k8s的Pod网络组件，下面使用helm在k8s集群中按照calico。</p><p>下载<code>tigera-operator</code>的helm chart:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>wget https://github.com/projectcalico/calico/releases/download/v3.21.2/tigera-operator-v3.21.2-1.tgz</span></span></code></pre></div></div><p>查看这个chart的中可定制的配置:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>helm show values tigera-operator-v3.21.2-1.tgz
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>imagePullSecrets: <span style=color:#f92672>{}</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>installation:
</span></span><span style=display:flex><span>  enabled: true
</span></span><span style=display:flex><span>  kubernetesProvider: <span style=color:#e6db74>&#34;&#34;</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>apiServer:
</span></span><span style=display:flex><span>  enabled: true
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>certs:
</span></span><span style=display:flex><span>  node:
</span></span><span style=display:flex><span>    key:
</span></span><span style=display:flex><span>    cert:
</span></span><span style=display:flex><span>    commonName:
</span></span><span style=display:flex><span>  typha:
</span></span><span style=display:flex><span>    key:
</span></span><span style=display:flex><span>    cert:
</span></span><span style=display:flex><span>    commonName:
</span></span><span style=display:flex><span>    caBundle:
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Configuration for the tigera operator</span>
</span></span><span style=display:flex><span>tigeraOperator:
</span></span><span style=display:flex><span>  image: tigera/operator
</span></span><span style=display:flex><span>  version: v1.23.3
</span></span><span style=display:flex><span>  registry: quay.io
</span></span><span style=display:flex><span>calicoctl:
</span></span><span style=display:flex><span>  image: quay.io/docker.io/calico/ctl
</span></span><span style=display:flex><span>  tag: v3.21.2</span></span></code></pre></div></div><p>定制的<code>values.yaml</code>如下:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span><span style=color:#75715e># 可针对上面的配置进行定制,例如calico的镜像改成从私有库拉取。</span>
</span></span><span style=display:flex><span><span style=color:#75715e># 这里只是个人本地环境测试k8s新版本，因此保留value.yaml为空即可</span></span></span></code></pre></div></div><p>使用helm安装calico：</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>helm install calico tigera-operator-v3.21.2-1.tgz -f values.yaml</span></span></code></pre></div></div><p>等待并确认所有pod处于Running状态:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>watch kubectl get pods -n calico-system
</span></span><span style=display:flex><span>NAME                                       READY   STATUS    RESTARTS   AGE
</span></span><span style=display:flex><span>calico-kube-controllers-7f58dbcbbd-kdnlg   1/1     Running   <span style=color:#ae81ff>0</span>          2m34s
</span></span><span style=display:flex><span>calico-node-nv794                          1/1     Running   <span style=color:#ae81ff>0</span>          2m34s
</span></span><span style=display:flex><span>calico-typha-65f579bc5d-4pbfz              1/1     Running   <span style=color:#ae81ff>0</span>          2m34s</span></span></code></pre></div></div><p>查看一下calico向k8s中添加的api资源:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh><span style=display:flex><span>kubectl api-resources | grep calico
</span></span><span style=display:flex><span>bgpconfigurations                              crd.projectcalico.org/v1               false        BGPConfiguration
</span></span><span style=display:flex><span>bgppeers                                       crd.projectcalico.org/v1               false        BGPPeer
</span></span><span style=display:flex><span>blockaffinities                                crd.projectcalico.org/v1               false        BlockAffinity
</span></span><span style=display:flex><span>caliconodestatuses                             crd.projectcalico.org/v1               false        CalicoNodeStatus
</span></span><span style=display:flex><span>clusterinformations                            crd.projectcalico.org/v1               false        ClusterInformation
</span></span><span style=display:flex><span>felixconfigurations                            crd.projectcalico.org/v1               false        FelixConfiguration
</span></span><span style=display:flex><span>globalnetworkpolicies                          crd.projectcalico.org/v1               false        GlobalNetworkPolicy
</span></span><span style=display:flex><span>globalnetworksets                              crd.projectcalico.org/v1               false        GlobalNetworkSet
</span></span><span style=display:flex><span>hostendpoints                                  crd.projectcalico.org/v1               false        HostEndpoint
</span></span><span style=display:flex><span>ipamblocks                                     crd.projectcalico.org/v1               false        IPAMBlock
</span></span><span style=display:flex><span>ipamconfigs                                    crd.projectcalico.org/v1               false        IPAMConfig
</span></span><span style=display:flex><span>ipamhandles                                    crd.projectcalico.org/v1               false        IPAMHandle
</span></span><span style=display:flex><span>ippools                                        crd.projectcalico.org/v1               false        IPPool
</span></span><span style=display:flex><span>ipreservations                                 crd.projectcalico.org/v1               false        IPReservation
</span></span><span style=display:flex><span>kubecontrollersconfigurations                  crd.projectcalico.org/v1               false        KubeControllersConfiguration
</span></span><span style=display:flex><span>networkpolicies                                crd.projectcalico.org/v1               true         NetworkPolicy
</span></span><span style=display:flex><span>networksets                                    crd.projectcalico.org/v1               true         NetworkSet</span></span></code></pre></div></div><p>这些api资源是属于calico的，因此不建议使用kubectl来管理，推荐按照calicoctl来管理这些api资源。 将calicoctl安装为kubectl的插件:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><pre tabindex=0><code class=language-fallback data-lang=fallback>cd /usr/local/bin
curl -o kubectl-calico -O -L  &#34;https://github.com/projectcalico/calicoctl/releases/download/v3.21.2/calicoctl&#34; 
chmod +x kubectl-calico</code></pre></div><p>验证插件正常工作:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><pre tabindex=0><code class=language-fallback data-lang=fallback>kubectl calico -h</code></pre></div><h3 id=25-验证k8s-dns是否可用>2.5 验证k8s DNS是否可用</h3><div class=highlight-container><button class="copy-code-btn outline">Copy</button><pre tabindex=0><code class=language-fallback data-lang=fallback>kubectl run curl --image=radial/busyboxplus:curl -it
If you don&#39;t see a command prompt, try pressing enter.
[ root@curl:/ ]$</code></pre></div><p>进入后执行<code>nslookup kubernetes.default</code>确认解析正常:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><pre tabindex=0><code class=language-fallback data-lang=fallback>nslookup kubernetes.default
Server:    10.96.0.10
Address 1: 10.96.0.10 kube-dns.kube-system.svc.cluster.local

Name:      kubernetes.default
Address 1: 10.96.0.1 kubernetes.default.svc.cluster.local</code></pre></div><h3 id=26-向kubernetes集群中添加node节点>2.6 向Kubernetes集群中添加Node节点</h3><p>下面将node2, node3添加到Kubernetes集群中，分别在node2, node3上执行:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><pre tabindex=0><code>kubeadm join 192.168.96.151:6443 --token o7d0h6.i9taufdl7u1un4va \  --discovery-token-ca-cert-hash sha256:6c55b14e9d71ef098ad0e8f249d85004c41b48063dbcd7692997930f9637f22b </code></pre></div><p>node2和node3加入集群很是顺利，在master节点上执行命令查看集群中的节点：</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><pre tabindex=0><code class=language-fallback data-lang=fallback>kubectl get node
NAME    STATUS   ROLES                  AGE     VERSION
node1   Ready    control-plane,master   29m     v1.23.1
node2   Ready    &lt;none&gt;                 5m28s   v1.23.1
node3   Ready    &lt;none&gt;                 5m4s    v1.23.1</code></pre></div><h2 id=3kubernetes常用组件部署>3.Kubernetes常用组件部署</h2><h3 id=31-使用helm部署ingress-nginx>3.1 使用Helm部署ingress-nginx</h3><p>为了便于将集群中的服务暴露到集群外部，需要使用Ingress。接下来使用Helm将ingress-nginx部署到Kubernetes上。 Nginx Ingress Controller被部署在Kubernetes的边缘节点上。</p><p>这里将node1(192.168.96.151)作为边缘节点，打上Label：</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><pre tabindex=0><code class=language-fallback data-lang=fallback>kubectl label node node1 node-role.kubernetes.io/edge=</code></pre></div><p>下载ingress-nginx的helm chart:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><pre tabindex=0><code>wget https://github.com/kubernetes/ingress-nginx/releases/download/helm-chart-4.0.13/ingress-nginx-4.0.13.tgz </code></pre></div><p>查看<code>ingress-nginx-4.0.13.tgz</code>这个chart的可定制配置:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><pre tabindex=0><code>helm show values ingress-nginx-4.0.13.tgz </code></pre></div><p>对values.yaml配置定制如下:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yml data-lang=yml><span style=display:flex><span><span style=color:#f92672>controller</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>ingressClassResource</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>name</span>: <span style=color:#ae81ff>nginx</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>enabled</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>default</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>controllerValue</span>: <span style=color:#e6db74>&#34;k8s.io/ingress-nginx&#34;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>admissionWebhooks</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>enabled</span>: <span style=color:#66d9ef>false</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>replicaCount</span>: <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>image</span>:
</span></span><span style=display:flex><span>    <span style=color:#75715e># registry: k8s.gcr.io</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># image: ingress-nginx/controller</span>
</span></span><span style=display:flex><span>    <span style=color:#75715e># tag: &#34;v1.1.0&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>registry</span>: <span style=color:#ae81ff>docker.io</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>image</span>: <span style=color:#ae81ff>unreachableg/k8s.gcr.io_ingress-nginx_controller</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>tag</span>: <span style=color:#e6db74>&#34;v1.1.0&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>digest</span>: <span style=color:#ae81ff>sha256:4f5df867e9367f76acfc39a0f85487dc63526e27735fa82fc57d6a652bafbbf6</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>hostNetwork</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>nodeSelector</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>node-role.kubernetes.io/edge</span>: <span style=color:#e6db74>&#39;&#39;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>affinity</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>podAntiAffinity</span>:
</span></span><span style=display:flex><span>        <span style=color:#f92672>requiredDuringSchedulingIgnoredDuringExecution</span>:
</span></span><span style=display:flex><span>        - <span style=color:#f92672>labelSelector</span>:
</span></span><span style=display:flex><span>            <span style=color:#f92672>matchExpressions</span>:
</span></span><span style=display:flex><span>            - <span style=color:#f92672>key</span>: <span style=color:#ae81ff>app</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>In</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>values</span>:
</span></span><span style=display:flex><span>              - <span style=color:#ae81ff>nginx-ingress</span>
</span></span><span style=display:flex><span>            - <span style=color:#f92672>key</span>: <span style=color:#ae81ff>component</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>In</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>values</span>:
</span></span><span style=display:flex><span>              - <span style=color:#ae81ff>controller</span>
</span></span><span style=display:flex><span>          <span style=color:#f92672>topologyKey</span>: <span style=color:#ae81ff>kubernetes.io/hostname</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>tolerations</span>:
</span></span><span style=display:flex><span>      - <span style=color:#f92672>key</span>: <span style=color:#ae81ff>node-role.kubernetes.io/master</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>Exists</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>effect</span>: <span style=color:#ae81ff>NoSchedule</span>
</span></span><span style=display:flex><span>      - <span style=color:#f92672>key</span>: <span style=color:#ae81ff>node-role.kubernetes.io/master</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>operator</span>: <span style=color:#ae81ff>Exists</span>
</span></span><span style=display:flex><span>        <span style=color:#f92672>effect</span>: <span style=color:#ae81ff>PreferNoSchedule</span></span></span></code></pre></div></div><p>nginx ingress controller的副本数replicaCount为1，将被调度到node1这个边缘节点上。这里并没有指定nginx ingress controller service的externalIPs，而是通过<code>hostNetwork: true</code>设置nginx ingress controller使用宿主机网络。 因为k8s.gcr.io被墙，这里替换成unreachableg/k8s.gcr.io_ingress-nginx_controller提前拉取一下镜像:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><pre tabindex=0><code>crictl pull unreachableg/k8s.gcr.io_ingress-nginx_controller:v1.1.0 </code></pre></div><div class=highlight-container><button class="copy-code-btn outline">Copy</button><pre tabindex=0><code>helm install ingress-nginx ingress-nginx-4.0.13.tgz --create-namespace -n ingress-nginx -f values.yaml </code></pre></div><div class=highlight-container><button class="copy-code-btn outline">Copy</button><pre tabindex=0><code class=language-fallback data-lang=fallback>kubectl get pod -n ingress-nginx
NAME                                        READY   STATUS    RESTARTS   AGE
ingress-nginx-controller-7f574989bc-xwbf4   1/1     Running   0          117s</code></pre></div><p>测试访问<code>http://192.168.96.151</code>返回默认的nginx 404页，则部署完成。</p><h3 id=32-使用helm部署dashboard>3.2 使用Helm部署dashboard</h3><p>先部署metrics-server：</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><pre tabindex=0><code>wget https://github.com/kubernetes-sigs/metrics-server/releases/download/v0.5.2/components.yaml </code></pre></div><p>修改components.yaml中的image为<code>docker.io/unreachableg/k8s.gcr.io_metrics-server_metrics-server:v0.5.2</code>。 修改components.yaml中容器的启动参数，加入<code>--kubelet-insecure-tls</code>。</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><pre tabindex=0><code>kubectl apply -f components.yaml </code></pre></div><p>metrics-server的pod正常启动后，等一段时间就可以使用<code>kubectl top</code>查看集群和pod的metrics信息:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><pre tabindex=0><code class=language-fallback data-lang=fallback>kubectl top node --use-protocol-buffers=true
NAME    CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
node1   219m         5%     3013Mi          39%
node2   102m         2%     1576Mi          20%
node3   110m         2%     1696Mi          21%

kubectl top pod -n kube-system --use-protocol-buffers=true
NAME                                    CPU(cores)   MEMORY(bytes)
coredns-59d64cd4d4-9mclj                4m           17Mi
coredns-59d64cd4d4-fj7xr                4m           17Mi
etcd-node1                              25m          154Mi
kube-apiserver-node1                    80m          465Mi
kube-controller-manager-node1           17m          61Mi
kube-proxy-hhlhc                        1m           21Mi
kube-proxy-nrhq7                        1m           19Mi
kube-proxy-phmrw                        1m           17Mi
kube-scheduler-node1                    4m           24Mi
kubernetes-dashboard-5cb95fd47f-6lfnm   3m           36Mi
metrics-server-9ddcc8ddf-jvlzs          5m           21Mi</code></pre></div><p>接下来使用helm部署k8s的dashboard，添加chart repo:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><pre tabindex=0><code class=language-fallback data-lang=fallback>helm repo add kubernetes-dashboard https://kubernetes.github.io/dashboard/
helm repo update</code></pre></div><p>查看chart的可定制配置:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><pre tabindex=0><code>helm show values kubernetes-dashboard/kubernetes-dashboard </code></pre></div><p>对value.yaml定制配置如下:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yml data-lang=yml><span style=display:flex><span><span style=color:#f92672>image</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>repository</span>: <span style=color:#ae81ff>kubernetesui/dashboard</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>tag</span>: <span style=color:#ae81ff>v2.4.0</span>
</span></span><span style=display:flex><span><span style=color:#f92672>ingress</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>enabled</span>: <span style=color:#66d9ef>true</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>annotations</span>:
</span></span><span style=display:flex><span>    <span style=color:#f92672>nginx.ingress.kubernetes.io/ssl-redirect</span>: <span style=color:#e6db74>&#34;true&#34;</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>nginx.ingress.kubernetes.io/backend-protocol</span>: <span style=color:#e6db74>&#34;HTTPS&#34;</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>hosts</span>:
</span></span><span style=display:flex><span>  - <span style=color:#ae81ff>k8s.example.com</span>
</span></span><span style=display:flex><span>  <span style=color:#f92672>tls</span>:
</span></span><span style=display:flex><span>    - <span style=color:#f92672>secretName</span>: <span style=color:#ae81ff>example-com-tls-secret</span>
</span></span><span style=display:flex><span>      <span style=color:#f92672>hosts</span>:
</span></span><span style=display:flex><span>      - <span style=color:#ae81ff>k8s.example.com</span>
</span></span><span style=display:flex><span><span style=color:#f92672>metricsScraper</span>:
</span></span><span style=display:flex><span>  <span style=color:#f92672>enabled</span>: <span style=color:#66d9ef>true</span></span></span></code></pre></div></div><p>先创建存放<code>k8s.example.com</code>ssl证书的secret:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><pre tabindex=0><code class=language-fallback data-lang=fallback>kubectl create secret tls example-com-tls-secret \
  --cert=cert.pem \
  --key=key.pem \
  -n kube-system</code></pre></div><p>使用helm部署dashboard:</p><p>helm install kubernetes-dashboard kubernetes-dashboard/kubernetes-dashboard<br>-n kube-system<br>-f values.yaml</p><p>确认上面的命令部署成功。</p><p>创建管理员sa:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><pre tabindex=0><code class=language-fallback data-lang=fallback>kubectl create serviceaccount kube-dashboard-admin-sa -n kube-system

kubectl create clusterrolebinding kube-dashboard-admin-sa \
--clusterrole=cluster-admin --serviceaccount=kube-system:kube-dashboard-admin-sa</code></pre></div><p>获取集群管理员登录dashboard所需token:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><pre tabindex=0><code class=language-fallback data-lang=fallback>kubectl -n kube-system get secret | grep kube-dashboard-admin-sa-token
kube-dashboard-admin-sa-token-rcwlb              kubernetes.io/service-account-token   3      68s

kubectl describe -n kube-system secret/kube-dashboard-admin-sa-token-rcwlb 
Name:         kube-dashboard-admin-sa-token-rcwlb
Namespace:    kube-system
Labels:       &lt;none&gt;
Annotations:  kubernetes.io/service-account.name: kube-dashboard-admin-sa
              kubernetes.io/service-account.uid: fcdf27f6-f6f9-4f76-b64e-edc91fb1479b

Type:  kubernetes.io/service-account-token

Data
====
namespace:  11 bytes
token:      eyJhbGciOiJSUzI1NiIsImtpZCI6IkYxWTd5aDdzYWsyeWJVMFliUUhJMXI4YWtMZFd4dGFDT1N4eEZoam9HLUEifQ.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJrdWJlLWRhc2hib2FyZC1hZG1pbi1zYS10b2tlbi1yY3dsYiIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50Lm5hbWUiOiJrdWJlLWRhc2hib2FyZC1hZG1pbi1zYSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VydmljZS1hY2NvdW50LnVpZCI6ImZjZGYyN2Y2LWY2ZjktNGY3Ni1iNjRlLWVkYzkxZmIxNDc5YiIsInN1YiI6InN5c3RlbTpzZXJ2aWNlYWNjb3VudDprdWJlLXN5c3RlbTprdWJlLWRhc2hib2FyZC1hZG1pbi1zYSJ9.R3l19_Nal4B2EktKFSJ7CgOqAngG_MTgzHRRjWdREN7dLALyfiRXYIgZQ90hxM-a9z2sPXBzfJno4OGP4fPX33D8h_4fgxfpVLjKqjdlZ_HAks_6sV9PBzDNXb_loNW8ECfsleDgn6CZin8Vx1w7sgkoEIKq0H-iZ8V9pRV0fTuOZcB-70pV_JX6H6WBEOgRIAZswhAoyUMvH1qNl47J5xBNwKRgcqP57NCIODo6FiClxfY3MWo2vz44R5wYCuBJJ70p6aBWixjDSxnp5u9mUP0zMF_igICl_OfgKuPyaeuIL83U8dS5ovEwPPGzX5mHUgaPH7JLZmKRNXJqLhTweA
ca.crt:     1066 bytes</code></pre></div><p>使用上面的token登录k8s dashboard。</p><p><a href=https://blog.frognew.com/images/2021/06/k8s-1.21-dashboard.png><img src=https://blog.frognew.com/images/2021/06/k8s-1.21-dashboard.png alt=dashboard></a></p><h2 id=faq>FAQ</h2><ul><li><p>calico: <a href=https://www.jianshu.com/p/4b175e733cd3>BIRD is not ready: BGP not established</a></p><p>一种是通过正则指定网卡，类似这样:</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-csharp data-lang=csharp><span style=display:flex><span>- name: IP_AUTODETECTION_METHOD
</span></span><span style=display:flex><span><span style=color:#66d9ef>value</span>: <span style=color:#e6db74>&#34;interface=ens.*&#34;</span>  <span style=color:#960050;background-color:#1e0010>#</span> ens <span style=color:#960050;background-color:#1e0010>根据实际网卡开头配置</span></span></span></code></pre></div></div><p>另一种是从部署节点到到达目的节点的,类似这样：</p><div class=highlight-container><button class="copy-code-btn outline">Copy</button><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#75715e># Using IP addresses</span>
</span></span><span style=display:flex><span>IP_AUTODETECTION_METHOD<span style=color:#f92672>=</span>can-reach<span style=color:#f92672>=</span>8.8.8.8
</span></span><span style=display:flex><span>IP6_AUTODETECTION_METHOD<span style=color:#f92672>=</span>can-reach<span style=color:#f92672>=</span>2001:4860:4860::8888
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Using domain names</span>
</span></span><span style=display:flex><span>IP_AUTODETECTION_METHOD<span style=color:#f92672>=</span>can-reach<span style=color:#f92672>=</span>www.google.com
</span></span><span style=display:flex><span>IP6_AUTODETECTION_METHOD<span style=color:#f92672>=</span>can-reach<span style=color:#f92672>=</span>www.google.com</span></span></code></pre></div></div><p>如果是通过 Installation 安装的，需要修改一个CRD Installation</p></li><li></li></ul><h2 id=参考>参考</h2><ul><li><a href=https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/>Installing kubeadm</a></li><li><a href=https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm//>Creating a cluster with kubeadm</a></li><li><a href=https://github.com/containerd/containerd>https://github.com/containerd/containerd</a></li><li><a href=https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta2>https://pkg.go.dev/k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/v1beta2</a></li><li><a href=https://docs.projectcalico.org/>https://docs.projectcalico.org/</a></li></ul></div><div class=post-copyright><p class=copyright-item><span class=item-title>Author</span>
<span class=item-content>yesplease</span></p><p class=copyright-item><span class=item-title>LastMod</span>
<span class=item-content>2022-03-01</span></p><p class=copyright-item><span class=item-title>License</span>
<span class=item-content><a rel="license noopener" href=https://creativecommons.org/licenses/by-nc-nd/4.0/ target=_blank>CC BY-NC-ND 4.0</a></span></p></div><footer class=post-footer><div class=post-tags><a href=http://localhost:1313/tags/kubernetes/>kubernetes</a>
<a href=http://localhost:1313/tags/kubeadm/>kubeadm</a>
<a href=http://localhost:1313/tags/deploy/>deploy</a></div><nav class=post-nav><a class=prev href=/post/kubernetes/series-kubernetes-4/><i class=iconfont><svg aria-hidden="true" class="lucide lucide-chevron-left hi-svg-inline" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="m15 18-6-6 6-6"/></svg>
</i><span class="prev-text nav-default">kubernetes1.24.0, Why use docker in production environment ?</span>
<span class="prev-text nav-mobile">Prev</span>
</a><a class=next href=/post/go/deep/series-go-1/><span class="next-text nav-default">Go io, how to play?</span>
<span class="prev-text nav-mobile">Next</span>
<i class=iconfont><svg aria-hidden="true" class="lucide lucide-chevron-right hi-svg-inline" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="m9 18 6-6-6-6"/></svg></i></a></nav></footer></article></div><aside class=right-sidebar></aside></div></main><footer id=footer class=site-footer><div class=social-icon-links><a href=mailto:cugbtang@sina.com rel="me noopener" class=social-icon-link title=email><svg aria-hidden="true" class="icon hi-svg-inline" fill="currentColor" height="1em" viewBox="0 0 1451 1024" width="1em" xlink="http://www.w3.org/1999/xlink"><path d="M664.781909 681.472759.0 97.881301C0 3.997201 71.046997.0 71.046997.0H474.477909 961.649408h399.992405s71.046998 3.997201 71.046998 97.881301L771.345323 681.472759S764.482731 685.154773 753.594283 688.65053V688.664858C741.602731 693.493018 729.424896 695.068979 718.077952 694.839748 706.731093 695.068979 694.553173 693.493018 682.561621 688.664858V688.65053C671.644501 685.140446 664.781909 681.472759 664.781909 681.472759zm53.281707 130.131124C693.779541 811.016482 658.879232 802.205449 619.10784 767.734955 542.989056 701.759633.0 212.052267.0 212.052267V942.809523S0 1024 83.726336 1024H682.532949 753.579947h595.368192C1432.688811 1024 1432.688811 942.809523 1432.688811 942.809523V212.052267S893.138176 701.759633 817.019477 767.734955c-39.771477 34.470494-74.671786 43.295855-98.955861 43.868928z"/></svg>
</a><a href=https://github.com/cugbtang rel="me noopener" class=social-icon-link title=github target=_blank><svg aria-hidden="true" class="icon hi-svg-inline" fill="currentColor" height="1em" viewBox="0 0 1024 1024" width="1em" xlink="http://www.w3.org/1999/xlink"><path d="M512 12.672c-282.88.0-512 229.248-512 512 0 226.261333 146.688 418.133333 350.08 485.76 25.6 4.821333 34.986667-11.008 34.986667-24.618667.0-12.16-.426667-44.373333-.64-87.04C242.005334 929.664 211.968 830.08 211.968 830.08 188.672 770.986667 155.008 755.2 155.008 755.2c-46.378667-31.744 3.584-31.104 3.584-31.104 51.413333 3.584 78.421333 52.736 78.421333 52.736 45.653333 78.293333 119.850667 55.68 149.12 42.581333 4.608-33.109333 17.792-55.68 32.426667-68.48-113.706667-12.8-233.216-56.832-233.216-253.013333.0-55.893333 19.84-101.546667 52.693333-137.386667-5.76-12.928-23.04-64.981333 4.48-135.509333.0.0 42.88-13.738667 140.8 52.48 40.96-11.392 84.48-17.024 128-17.28 43.52.256 87.04 5.888 128 17.28 97.28-66.218667 140.16-52.48 140.16-52.48 27.52 70.528 10.24 122.581333 5.12 135.509333 32.64 35.84 52.48 81.493333 52.48 137.386667.0 196.693333-119.68 240-233.6 252.586667 17.92 15.36 34.56 46.762667 34.56 94.72.0 68.522667-.64 123.562667-.64 140.202666.0 13.44 8.96 29.44 35.2 24.32C877.44 942.592 1024 750.592 1024 524.672c0-282.752-229.248-512-512-512"/></svg>
</a><a href=http://localhost:1313/index.xml rel="noopener alternate" type=application/rss+xml class=social-icon-link title=rss target=_blank><svg aria-hidden="true" class="lucide lucide-rss hi-svg-inline" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M4 11a9 9 0 019 9"/><path d="M4 4a16 16 0 0116 16"/><circle cx="5" cy="19" r="1"/></svg></a></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a>
</span><span class=division>|</span>
<span class=theme-info>Theme - <a class=theme-link href=https://github.com/xianmin/hugo-theme-jane>Jane</a>
</span><span class=copyright-year>&copy;
2017 -
2025
<span class=heart><i class=iconfont><svg aria-hidden="true" class="lucide lucide-heart hi-svg-inline" fill="none" height="1em" stroke="currentColor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2" viewBox="0 0 24 24" width="1em"><path d="M19 14c1.49-1.46 3-3.21 3-5.5A5.5 5.5.0 0016.5 3c-1.76.0-3 .5-4.5 2-1.5-1.5-2.74-2-4.5-2A5.5 5.5.0 002 8.5c0 2.3 1.5 4.05 3 5.5l7 7z"/></svg>
</i></span><span class=author>yesplease</span></span></div></footer><script type=text/javascript src=/js/main.002d1a80e7bd914cb4592a8c6486c23920f3d9827531bd1c79b3b5716dcf0bd5.js integrity="sha256-AC0agOe9kUy0WSqMZIbCOSDz2YJ1Mb0cebO1cW3PC9U=" crossorigin=anonymous></script><script type=text/javascript src=/lib/photoswipe/photoswipe.min.js></script><script type=text/javascript src=/lib/photoswipe/photoswipe-ui-default.min.js></script></body></html>