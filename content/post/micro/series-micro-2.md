---
title: "Go-micro advance, how to play?"
date: 2023-09-15T15:44:23+08:00
lastmod: 2023-09-15T16:44:23+08:00
draft: false
tags: [ "go", "micro","go-micro"]
categories: ["go", "micro","go-micro"]
author: "yesplease"
---
# Go Micro é«˜çº§ç‰¹æ€§æ·±åº¦è§£æï¼šä»ç†è®ºåˆ°å®è·µ

## ğŸŒ æœåŠ¡å‘ç°ï¼šå®¢æˆ·ç«¯å¦‚ä½•æ„ŸçŸ¥æœåŠ¡æ³¨å†Œå˜åŒ–

### åŸç†æ·±åº¦è§£æ

Go Micro çš„æœåŠ¡å‘ç°æœºåˆ¶åŸºäºæ³¨å†Œä¸­å¿ƒçš„**è®¢é˜…-é€šçŸ¥æ¨¡å¼**ï¼Œå®¢æˆ·ç«¯é€šè¿‡ Watcher æœºåˆ¶å®æ—¶æ„ŸçŸ¥æœåŠ¡å®ä¾‹çš„å˜åŒ–ã€‚è¿™ç§æœºåˆ¶ç¡®ä¿äº†æœåŠ¡å‘ç°çš„åŠ¨æ€æ€§å’Œå®æ—¶æ€§ã€‚

### æ ¸å¿ƒå®ç°æœºåˆ¶

#### 1. **Watcher æ¥å£è®¾è®¡**
```go
type Watcher interface {
    // ä¸‹ä¸€ä¸ªæœåŠ¡å˜æ›´äº‹ä»¶
    Next() (*Result, error)
    // åœæ­¢ç›‘å¬
    Stop()
}

type Result struct {
    // æœåŠ¡å®ä¾‹
    Service *Service
    // æ“ä½œç±»å‹ï¼šregister, deregister, update
    Action string
    // æ—¶é—´æˆ³
    Timestamp time.Time
}
```

#### 2. **æœåŠ¡è®¢é˜…å®Œæ•´å®ç°**
```go
package main

import (
    "context"
    "fmt"
    "log"
    "sync"
    "time"

    "github.com/go-micro/go-micro/v4"
    "github.com/go-micro/go-micro/v4/registry"
    "github.com/go-micro/go-micro/plugins/v4/registry/consul"
)

type ServiceWatcher struct {
    registry registry.Registry
    services map[string][]*registry.Service
    mu       sync.RWMutex
}

func NewServiceWatcher(reg registry.Registry) *ServiceWatcher {
    return &ServiceWatcher{
        registry: reg,
        services: make(map[string][]*registry.Service),
    }
}

// ç›‘å¬æœåŠ¡å˜åŒ–
func (sw *ServiceWatcher) WatchService(ctx context.Context, serviceName string) error {
    // åˆ›å»º watcher
    watcher, err := sw.registry.Watch(
        registry.WatchService(serviceName),
    )
    if err != nil {
        return fmt.Errorf("failed to create watcher: %w", err)
    }
    defer watcher.Stop()

    log.Printf("å¼€å§‹ç›‘å¬æœåŠ¡ %s çš„å˜åŒ–...", serviceName)

    for {
        select {
        case <-ctx.Done():
            log.Println("åœæ­¢ç›‘å¬æœåŠ¡å˜åŒ–")
            return nil
        default:
            // è·å–ä¸‹ä¸€ä¸ªäº‹ä»¶
            result, err := watcher.Next()
            if err != nil {
                log.Printf("è·å–æœåŠ¡å˜åŒ–äº‹ä»¶å¤±è´¥: %v", err)
                time.Sleep(2 * time.Second)
                continue
            }

            // å¤„ç†æœåŠ¡å˜åŒ–
            sw.handleServiceChange(result)
        }
    }
}

// å¤„ç†æœåŠ¡å˜åŒ–
func (sw *ServiceWatcher) handleServiceChange(result *registry.Result) {
    sw.mu.Lock()
    defer sw.mu.Unlock()

    serviceName := result.Service.Name
    action := result.Action

    switch action {
    case "register", "update":
        log.Printf("æœåŠ¡ %s æ³¨å†Œ/æ›´æ–°: %+v", serviceName, result.Service.Nodes)
        sw.services[serviceName] = []*registry.Service{result.Service}

    case "deregister":
        log.Printf("æœåŠ¡ %s æ³¨é”€: %+v", serviceName, result.Service.Nodes)
        delete(sw.services, serviceName)

    default:
        log.Printf("æœªçŸ¥çš„æœåŠ¡å˜åŒ–åŠ¨ä½œ: %s", action)
    }
}

// è·å–å¯ç”¨æœåŠ¡å®ä¾‹
func (sw *ServiceWatcher) GetServiceInstances(serviceName string) []*registry.Node {
    sw.mu.RLock()
    defer sw.mu.RUnlock()

    services, exists := sw.services[serviceName]
    if !exists || len(services) == 0 {
        return nil
    }

    var nodes []*registry.Node
    for _, service := range services {
        nodes = append(nodes, service.Nodes...)
    }

    return nodes
}

func main() {
    // åˆ›å»º Consul æ³¨å†Œä¸­å¿ƒ
    reg := consul.NewRegistry(
        registry.Addrs("127.0.0.1:8500"),
    )

    watcher := NewServiceWatcher(reg)

    // åˆ›å»ºä¸Šä¸‹æ–‡
    ctx, cancel := context.WithCancel(context.Background())
    defer cancel()

    // å¯åŠ¨å¤šä¸ªæœåŠ¡çš„ç›‘å¬
    services := []string{"user-service", "order-service", "payment-service"}

    for _, serviceName := range services {
        go func(name string) {
            if err := watcher.WatchService(ctx, name); err != nil {
                log.Printf("ç›‘å¬æœåŠ¡ %s å¤±è´¥: %v", name, err)
            }
        }(serviceName)
    }

    // æ¨¡æ‹Ÿå®¢æˆ·ç«¯è·å–æœåŠ¡å®ä¾‹
    go func() {
        for {
            time.Sleep(5 * time.Second)

            for _, serviceName := range services {
                instances := watcher.GetServiceInstances(serviceName)
                log.Printf("æœåŠ¡ %s çš„å¯ç”¨å®ä¾‹: %d", serviceName, len(instances))

                for i, instance := range instances {
                    log.Printf("  å®ä¾‹ %d: %s:%d", i+1, instance.Address, instance.Port)
                }
            }
        }
    }()

    // ç­‰å¾…ç¨‹åºé€€å‡º
    select {}
}
```

#### 3. **äº‹ä»¶é©±åŠ¨ç¼“å­˜æœºåˆ¶**
```go
type ServiceCache struct {
    cache    map[string][]*registry.Service
    watchers map[string]registry.Watcher
    mu       sync.RWMutex
    registry registry.Registry
}

func (sc *ServiceCache) GetService(name string) ([]*registry.Service, error) {
    sc.mu.RLock()
    services, exists := sc.cache[name]
    sc.mu.RUnlock()

    if exists && len(services) > 0 {
        return services, nil
    }

    // ç¼“å­˜ä¸­æ²¡æœ‰ï¼Œä»æ³¨å†Œä¸­å¿ƒè·å–
    services, err := sc.registry.GetService(name)
    if err != nil {
        return nil, err
    }

    sc.mu.Lock()
    sc.cache[name] = services
    sc.mu.Unlock()

    // å¯åŠ¨ç›‘å¬
    sc.startWatching(name)

    return services, nil
}

func (sc *ServiceCache) startWatching(name string) {
    sc.mu.Lock()
    defer sc.mu.Unlock()

    if _, exists := sc.watchers[name]; exists {
        return
    }

    watcher, err := sc.registry.Watch(registry.WatchService(name))
    if err != nil {
        log.Printf("åˆ›å»º watcher å¤±è´¥: %v", err)
        return
    }

    sc.watchers[name] = watcher

    go func() {
        defer watcher.Stop()

        for {
            result, err := watcher.Next()
            if err != nil {
                log.Printf("è·å–æœåŠ¡å˜åŒ–äº‹ä»¶å¤±è´¥: %v", err)
                break
            }

            sc.updateCache(name, result)
        }
    }()
}

func (sc *ServiceCache) updateCache(name string, result *registry.Result) {
    sc.mu.Lock()
    defer sc.mu.Unlock()

    switch result.Action {
    case "register", "update":
        sc.cache[name] = []*registry.Service{result.Service}
    case "deregister":
        delete(sc.cache, name)
    }
}
```

### é«˜çº§ç‰¹æ€§

#### **å¤šçº§ç¼“å­˜ç­–ç•¥**
```go
type MultiLevelCache struct {
    l1Cache *LocalCache    // æœ¬åœ°å†…å­˜ç¼“å­˜
    l2Cache *RedisCache    // åˆ†å¸ƒå¼Redisç¼“å­˜
    l3Cache *RegistryCache  // æ³¨å†Œä¸­å¿ƒç¼“å­˜
    stats   *CacheStats
    mu      sync.RWMutex
}

type LocalCache struct {
    items map[string]*CacheItem
    ttl   time.Duration
    mu    sync.RWMutex
}

type CacheItem struct {
    Value      interface{}
    Expiration time.Time
    Hits       int64
    Misses     int64
}

func (mlc *MultiLevelCache) GetService(ctx context.Context, serviceName string) ([]*registry.Service, error) {
    // L1: æœ¬åœ°å†…å­˜ç¼“å­˜
    if services, err := mlc.l1Cache.Get(serviceName); err == nil {
        mlc.stats.IncL1Hit()
        log.Printf("L1 Cache hit for service: %s", serviceName)
        return services, nil
    }
    mlc.stats.IncL1Miss()

    // L2: Redisç¼“å­˜
    if services, err := mlc.l2Cache.Get(ctx, serviceName); err == nil {
        // å›å¡«L1ç¼“å­˜
        mlc.l1Cache.Set(serviceName, services, time.Minute*5)
        mlc.stats.IncL2Hit()
        log.Printf("L2 Cache hit for service: %s", serviceName)
        return services, nil
    }
    mlc.stats.IncL2Miss()

    // L3: æ³¨å†Œä¸­å¿ƒç¼“å­˜
    if services, err := mlc.l3Cache.GetService(serviceName); err == nil {
        // å›å¡«L1å’ŒL2ç¼“å­˜
        mlc.l1Cache.Set(serviceName, services, time.Minute*5)
        mlc.l2Cache.Set(ctx, serviceName, services, time.Minute*30)
        mlc.stats.IncL3Hit()
        log.Printf("L3 Cache hit for service: %s", serviceName)
        return services, nil
    }
    mlc.stats.IncL3Miss()

    return nil, registry.ErrNotFound
}

func (mlc *MultiLevelCache) UpdateService(serviceName string, services []*registry.Service) {
    mlc.mu.Lock()
    defer mlc.mu.Unlock()

    // åŒæ­¥æ›´æ–°æ‰€æœ‰ç¼“å­˜çº§åˆ«
    mlc.l1Cache.Set(serviceName, services, time.Minute*5)
    mlc.l2Cache.Set(context.Background(), serviceName, services, time.Minute*30)
    mlc.l3Cache.UpdateService(serviceName, services)

    log.Printf("Service cache updated: %s", serviceName)
}

// ç¼“å­˜é¢„çƒ­æœºåˆ¶
func (mlc *MultiLevelCache) WarmUp(ctx context.Context, serviceNames []string) error {
    var wg sync.WaitGroup
    errChan := make(chan error, len(serviceNames))
    sem := make(chan struct{}, 10) // é™åˆ¶å¹¶å‘æ•°

    for _, name := range serviceNames {
        wg.Add(1)
        go func(serviceName string) {
            defer wg.Done()
            sem <- struct{}{}
            defer func() { <-sem }()

            services, err := mlc.l3Cache.GetService(serviceName)
            if err != nil {
                errChan <- fmt.Errorf("é¢„çƒ­æœåŠ¡ %s å¤±è´¥: %w", serviceName, err)
                return
            }

            mlc.l1Cache.Set(serviceName, services, time.Minute*5)
            mlc.l2Cache.Set(ctx, serviceName, services, time.Minute*30)
            log.Printf("æœåŠ¡ %s é¢„çƒ­å®Œæˆ", serviceName)
        }(name)
    }

    wg.Wait()
    close(errChan)

    for err := range errChan {
        if err != nil {
            return err
        }
    }

    return nil
}
```

#### **æ™ºèƒ½æœåŠ¡è·¯ç”±**
```go
type SmartRouter struct {
    registry       registry.Registry
    loadBalancer   LoadBalancer
    healthChecker HealthChecker
    router        *RouterEngine
    metrics       *RouterMetrics
}

type RouteRule struct {
    ServiceName   string            `json:"service_name"`
    Weight       int               `json:"weight"`
    Conditions   []RouteCondition  `json:"conditions"`
    Priority     int               `json:"priority"`
    Metadata     map[string]string `json:"metadata"`
}

type RouteCondition struct {
    Field    string      `json:"field"`
    Operator string      `json:"operator"`
    Value    interface{} `json:"value"`
}

func (sr *SmartRouter) SelectService(ctx context.Context, serviceName string, request interface{}) (*registry.Service, error) {
    // è·å–è·¯ç”±è§„åˆ™
    rules, err := sr.router.GetRules(serviceName)
    if err != nil {
        return nil, fmt.Errorf("è·å–è·¯ç”±è§„åˆ™å¤±è´¥: %w", err)
    }

    // è¯„ä¼°è·¯ç”±æ¡ä»¶
    matchedRules := sr.evaluateRules(rules, request)
    if len(matchedRules) == 0 {
        // æ²¡æœ‰åŒ¹é…è§„åˆ™ï¼Œä½¿ç”¨é»˜è®¤è´Ÿè½½å‡è¡¡
        return sr.defaultSelect(serviceName)
    }

    // æ ¹æ®æƒé‡é€‰æ‹©è§„åˆ™
    selectedRule := sr.selectRuleByWeight(matchedRules)
    if selectedRule == nil {
        return sr.defaultSelect(serviceName)
    }

    // åº”ç”¨è·¯ç”±ç­–ç•¥
    return sr.applyRouteStrategy(ctx, selectedRule, serviceName)
}

func (sr *SmartRouter) evaluateRules(rules []RouteRule, request interface{}) []RouteRule {
    var matched []RouteRule

    for _, rule := range rules {
        if sr.matchConditions(rule.Conditions, request) {
            matched = append(matched, rule)
        }
    }

    // æŒ‰ä¼˜å…ˆçº§æ’åº
    sort.Slice(matched, func(i, j int) bool {
        return matched[i].Priority > matched[j].Priority
    })

    return matched
}

func (sr *SmartRouter) matchConditions(conditions []RouteCondition, request interface{}) bool {
    requestMap, ok := request.(map[string]interface{})
    if !ok {
        return false
    }

    for _, condition := range conditions {
        value, exists := requestMap[condition.Field]
        if !exists {
            return false
        }

        if !sr.compareValues(value, condition.Operator, condition.Value) {
            return false
        }
    }

    return true
}

func (sr *SmartRouter) compareValues(actual, operator string, expected interface{}) bool {
    switch operator {
    case "equals":
        return fmt.Sprintf("%v", actual) == fmt.Sprintf("%v", expected)
    case "not_equals":
        return fmt.Sprintf("%v", actual) != fmt.Sprintf("%v", expected)
    case "contains":
        return strings.Contains(fmt.Sprintf("%v", actual), fmt.Sprintf("%v", expected))
    case "in":
        expectedList, ok := expected.([]interface{})
        if !ok {
            return false
        }
        for _, item := range expectedList {
            if fmt.Sprintf("%v", actual) == fmt.Sprintf("%v", item) {
                return true
            }
        }
        return false
    default:
        return false
    }
}

// ç°åº¦å‘å¸ƒè·¯ç”±
func (sr *SmartRouter) CanaryRouting(ctx context.Context, serviceName string, userID string) (*registry.Service, error) {
    // åŸºäºç”¨æˆ·IDçš„ç°åº¦è·¯ç”±
    hash := fnv.New32a()
    hash.Write([]byte(userID))
    userHash := hash.Sum32()

    // è·å–ç°åº¦é…ç½®
    canaryConfig, err := sr.router.GetCanaryConfig(serviceName)
    if err != nil {
        return sr.defaultSelect(serviceName)
    }

    // è®¡ç®—ç°åº¦æ¯”ä¾‹
    threshold := uint32(canaryConfig.Percentage * 100)
    if userHash%100 < threshold {
        // èµ°ç°åº¦æœåŠ¡
        return sr.selectServiceByVersion(serviceName, canaryConfig.CanaryVersion)
    }

    // èµ°ç¨³å®šæœåŠ¡
    return sr.selectServiceByVersion(serviceName, canaryConfig.StableVersion)
}
```

#### **æœåŠ¡å¥åº·çŠ¶æ€è¿‡æ»¤**
```go
func (sw *ServiceWatcher) GetHealthyInstances(serviceName string) []*registry.Node {
    sw.mu.RLock()
    defer sw.mu.RUnlock()

    services, exists := sw.services[serviceName]
    if !exists {
        return nil
    }

    var healthyNodes []*registry.Node
    for _, service := range services {
        for _, node := range service.Nodes {
            if sw.isNodeHealthy(node) {
                healthyNodes = append(healthyNodes, node)
            }
        }
    }

    return healthyNodes
}

func (sw *ServiceWatcher) isNodeHealthy(node *registry.Node) bool {
    // æ£€æŸ¥èŠ‚ç‚¹å…ƒæ•°æ®ä¸­çš„å¥åº·çŠ¶æ€
    if health, exists := node.Metadata["health"]; exists {
        return health == "healthy"
    }

    // æ£€æŸ¥æœ€è¿‘çš„å¿ƒè·³æ—¶é—´
    if lastHeartbeat, exists := node.Metadata["last_heartbeat"]; exists {
        if heartbeatTime, err := time.Parse(time.RFC3339, lastHeartbeat); err == nil {
            if time.Since(heartbeatTime) > 30*time.Second {
                return false
            }
        }
    }

    // é»˜è®¤è®¤ä¸ºèŠ‚ç‚¹å¥åº·
    return true
}

// åŠ¨æ€å¥åº·æ£€æŸ¥è°ƒåº¦å™¨
type HealthScheduler struct {
    watcher      *ServiceWatcher
    interval     time.Duration
    stopChan     chan struct{}
    healthChecks map[string]HealthCheckFunc
    mu          sync.RWMutex
}

type HealthCheckFunc func(ctx context.Context, node *registry.Node) (bool, string)

func NewHealthScheduler(watcher *ServiceWatcher, interval time.Duration) *HealthScheduler {
    return &HealthScheduler{
        watcher:      watcher,
        interval:     interval,
        stopChan:     make(chan struct{}),
        healthChecks: make(map[string]HealthCheckFunc),
    }
}

func (hs *HealthScheduler) RegisterHealthCheck(serviceName string, checkFunc HealthCheckFunc) {
    hs.mu.Lock()
    defer hs.mu.Unlock()
    hs.healthChecks[serviceName] = checkFunc
}

func (hs *HealthScheduler) Start() {
    go func() {
        ticker := time.NewTicker(hs.interval)
        defer ticker.Stop()

        for {
            select {
            case <-ticker.C:
                hs.performHealthChecks()
            case <-hs.stopChan:
                return
            }
        }
    }()
}

func (hs *HealthScheduler) performHealthChecks() {
    hs.mu.RLock()
    defer hs.mu.RUnlock()

    for serviceName, checkFunc := range hs.healthChecks {
        go func(name string, check HealthCheckFunc) {
            ctx, cancel := context.WithTimeout(context.Background(), 10*time.Second)
            defer cancel()

            instances := hs.watcher.GetServiceInstances(name)
            for _, instance := range instances {
                healthy, reason := checkFunc(ctx, instance)
                hs.watcher.UpdateHealthStatus(name, instance.Id, healthy, reason)
            }
        }(serviceName, checkFunc)
    }
}

func (hs *HealthScheduler) Stop() {
    close(hs.stopChan)
}

// æ•…éšœèŠ‚ç‚¹è‡ªåŠ¨æ¢å¤æœºåˆ¶
type FailureRecovery struct {
    watcher          *ServiceWatcher
    recoveryTimeout  time.Duration
    maxRetries      int
    recoveryAttempts map[string]int
    mu              sync.RWMutex
}

func NewFailureRecovery(watcher *ServiceWatcher, timeout time.Duration, maxRetries int) *FailureRecovery {
    return &FailureRecovery{
        watcher:          watcher,
        recoveryTimeout:  timeout,
        maxRetries:      maxRetries,
        recoveryAttempts: make(map[string]int),
    }
}

func (fr *FailureRecovery) MonitorRecovery(serviceName, nodeID string) {
    fr.mu.Lock()
    attempts := fr.recoveryAttempts[serviceName+nodeID]
    fr.mu.Unlock()

    if attempts >= fr.maxRetries {
        log.Printf("èŠ‚ç‚¹ %s-%s å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œåœæ­¢æ¢å¤å°è¯•", serviceName, nodeID)
        return
    }

    go func() {
        // ç­‰å¾…æ¢å¤è¶…æ—¶
        time.Sleep(fr.recoveryTimeout)

        // æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦æ¢å¤
        if fr.watcher.CheckNodeRecovery(serviceName, nodeID) {
            fr.mu.Lock()
            delete(fr.recoveryAttempts, serviceName+nodeID)
            fr.mu.Unlock()

            log.Printf("èŠ‚ç‚¹ %s-%s å·²è‡ªåŠ¨æ¢å¤", serviceName, nodeID)
            return
        }

        // è®°å½•æ¢å¤å¤±è´¥
        fr.mu.Lock()
        fr.recoveryAttempts[serviceName+nodeID]++
        fr.mu.Unlock()

        // ç»§ç»­ä¸‹ä¸€æ¬¡æ¢å¤å°è¯•
        fr.MonitorRecovery(serviceName, nodeID)
    }()
}
```

### æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

#### **è¿æ¥æ± ç®¡ç†**
```go
type ConnectionPool struct {
    pools  map[string]*connPool
    mu     sync.RWMutex
    maxConns int
}

type connPool struct {
    conns    chan *grpc.ClientConn
    createFn func() (*grpc.ClientConn, error)
}

func (cp *ConnectionPool) GetConnection(address string) (*grpc.ClientConn, error) {
    cp.mu.RLock()
    pool, exists := cp.pools[address]
    cp.mu.RUnlock()

    if !exists {
        cp.mu.Lock()
        pool = &connPool{
            conns:    make(chan *grpc.ClientConn, cp.maxConns),
            createFn: func() (*grpc.ClientConn, error) {
                return grpc.Dial(address, grpc.WithInsecure())
            },
        }
        cp.pools[address] = pool
        cp.mu.Unlock()
    }

    select {
    case conn := <-pool.conns:
        return conn, nil
    default:
        return pool.createFn()
    }
}
```

## ğŸ” æ³¨å†Œä¸­å¿ƒå¥åº·æ£€æŸ¥æœºåˆ¶æ·±åº¦è§£æ

### Consul å¥åº·æ£€æŸ¥æ¶æ„

Consul çš„å¥åº·æ£€æŸ¥æœºåˆ¶æ˜¯å…¶æœåŠ¡å‘ç°ç³»ç»Ÿçš„æ ¸å¿ƒç»„ä»¶ï¼Œé€šè¿‡ä¸»åŠ¨å’Œè¢«åŠ¨ç›¸ç»“åˆçš„æ–¹å¼ï¼Œç¡®ä¿æœåŠ¡å®ä¾‹çš„å¯ç”¨æ€§èƒ½å¤Ÿè¢«åŠæ—¶å‘ç°ã€‚

### é»˜è®¤å¥åº·æ£€æŸ¥æœºåˆ¶è¯¦è§£

#### **HTTP å¥åº·æ£€æŸ¥é…ç½®**
```go
package main

import (
    "log"
    "time"

    "github.com/go-micro/go-micro/v4"
    "github.com/go-micro/go-micro/v4/registry"
    "github.com/go-micro/plugins/v4/registry/consul"
)

type HealthCheckConfig struct {
    HTTP     string        `json:"http"`      // HTTP æ£€æŸ¥åœ°å€
    Interval time.Duration `json:"interval"` // æ£€æŸ¥é—´éš”
    Timeout  time.Duration `json:"timeout"`  // è¶…æ—¶æ—¶é—´
    DeregisterCriticalServiceAfter time.Duration `json:"deregister_critical_service_after"`
}

func main() {
    // åˆ›å»º Consul æ³¨å†Œä¸­å¿ƒ
    reg := consul.NewRegistry(
        registry.Addrs("127.0.0.1:8500"),
    )

    // åˆ›å»ºæœåŠ¡é…ç½®
    service := micro.NewService(
        micro.Name("user-service"),
        micro.Registry(reg),
        micro.RegisterTTL(time.Second*30), // æœåŠ¡æ³¨å†ŒTTL
        micro.RegisterInterval(time.Second*15), // é‡æ–°æ³¨å†Œé—´éš”
    )

    // è·å–æœåŠ¡èŠ‚ç‚¹ä¿¡æ¯
    node := Â®istry.Node{
        Id:      "user-service-1",
        Address: "192.168.1.100",
        Port:    8080,
        Metadata: map[string]string{
            "health_check_url": "http://192.168.1.100:8080/health",
            "health_check_method": "GET",
            "health_check_interval": "10s",
            "health_check_timeout": "1s",
        },
    }

    // æ³¨å†Œå¥åº·æ£€æŸ¥
    if err := registerHealthCheck(reg, node); err != nil {
        log.Fatalf("æ³¨å†Œå¥åº·æ£€æŸ¥å¤±è´¥: %v", err)
    }

    log.Println("æœåŠ¡å·²å¯åŠ¨ï¼Œå¥åº·æ£€æŸ¥å·²æ³¨å†Œ")
}

// æ³¨å†Œå¥åº·æ£€æŸ¥
func registerHealthCheck(reg registry.Registry, node *registry.Node) error {
    // å¥åº·æ£€æŸ¥é…ç½®
    healthCheck := Â®istry.HealthCheck{
        ID:                            node.Id + "-health",
        Name:                          node.Id + "-health",
        Interval:                       time.Second * 10,
        Timeout:                        time.Second * 1,
        DeregisterCriticalServiceAfter:    time.Minute * 5,
        HTTP:                          node.Metadata["health_check_url"],
        Method:                         node.Metadata["health_check_method"],
    }

    // æ³¨å†ŒæœåŠ¡æ—¶åŒ…å«å¥åº·æ£€æŸ¥
    service := Â®istry.Service{
        Name:  "user-service",
        Nodes: []*registry.Node{node},
    }

    return reg.Register(service, registry.RegisterHealthCheck(healthCheck))
}
```

#### **å¥åº·æ£€æŸ¥ç«¯ç‚¹å®ç°**
```go
package main

import (
    "encoding/json"
    "net/http"
    "runtime"
    "time"

    "github.com/gorilla/mux"
)

type HealthStatus struct {
    Status    string    `json:"status"`
    Timestamp time.Time `json:"timestamp"`
    Version   string    `json:"version"`
    Uptime    int64     `json:"uptime"`
    Memory    Memory    `json:"memory"`
    Database  Database  `json:"database"`
    Cache     Cache     `json:"cache"`
}

type Memory struct {
    Alloc      uint64 `json:"alloc"`
    TotalAlloc uint64 `json:"total_alloc"`
    Sys        uint64 `json:"sys"`
    NumGC      uint32 `json:"num_gc"`
}

type Database struct {
    Status   string `json:"status"`
    Latency  int64  `json:"latency_ms"`
}

type Cache struct {
    Status   string `json:"status"`
    HitRate  float64 `json:"hit_rate"`
}

var startTime = time.Now()

func main() {
    r := mux.NewRouter()

    // å¥åº·æ£€æŸ¥ç«¯ç‚¹
    r.HandleFunc("/health", healthCheckHandler).Methods("GET")
    r.HandleFunc("/health/ready", readinessCheckHandler).Methods("GET")
    r.HandleFunc("/health/live", livenessCheckHandler).Methods("GET")

    srv := &http.Server{
        Addr:    ":8080",
        Handler: r,
    }

    log.Println("æœåŠ¡å¯åŠ¨ï¼Œç›‘å¬ç«¯å£ 8080")
    log.Fatal(srv.ListenAndServe())
}

// åŸºç¡€å¥åº·æ£€æŸ¥
func healthCheckHandler(w http.ResponseWriter, r *http.Request) {
    var m runtime.MemStats
    runtime.ReadMemStats(&m)

    status := HealthStatus{
        Status:    "healthy",
        Timestamp: time.Now(),
        Version:   "1.0.0",
        Uptime:    int64(time.Since(startTime).Seconds()),
        Memory: Memory{
            Alloc:      m.Alloc,
            TotalAlloc: m.TotalAlloc,
            Sys:        m.Sys,
            NumGC:      m.NumGC,
        },
        Database: checkDatabase(),
        Cache:    checkCache(),
    }

    // æ ¹æ®ç»„ä»¶çŠ¶æ€åˆ¤æ–­æ•´ä½“å¥åº·çŠ¶æ€
    if status.Database.Status != "healthy" || status.Cache.Status != "healthy" {
        status.Status = "unhealthy"
        w.WriteHeader(http.StatusServiceUnavailable)
    } else {
        w.WriteHeader(http.StatusOK)
    }

    json.NewEncoder(w).Encode(status)
}

// å°±ç»ªæ£€æŸ¥
func readinessCheckHandler(w http.ResponseWriter, r *http.Request) {
    // æ£€æŸ¥ä¾èµ–æœåŠ¡æ˜¯å¦å°±ç»ª
    if !isDatabaseReady() || !isCacheReady() {
        w.WriteHeader(http.StatusServiceUnavailable)
        json.NewEncoder(w).Encode(map[string]string{
            "status":  "not_ready",
            "message": "ä¾èµ–æœåŠ¡æœªå°±ç»ª",
        })
        return
    }

    w.WriteHeader(http.StatusOK)
    json.NewEncoder(w).Encode(map[string]string{
        "status": "ready",
    })
}

// å­˜æ´»æ£€æŸ¥
func livenessCheckHandler(w http.ResponseWriter, r *http.Request) {
    // ç®€å•çš„å­˜æ´»æ£€æŸ¥ï¼Œè¿”å›200è¡¨ç¤ºæœåŠ¡å­˜æ´»
    w.WriteHeader(http.StatusOK)
    json.NewEncoder(w).Encode(map[string]string{
        "status": "alive",
    })
}

func checkDatabase() Database {
    start := time.Now()
    // æ¨¡æ‹Ÿæ•°æ®åº“è¿æ¥æ£€æŸ¥
    // err := db.Ping()
    // if err != nil {
    //     return Database{Status: "unhealthy"}
    // }

    latency := time.Since(start).Milliseconds()
    return Database{
        Status:  "healthy",
        Latency: latency,
    }
}

func checkCache() Cache {
    // æ¨¡æ‹Ÿç¼“å­˜è¿æ¥æ£€æŸ¥
    return Cache{
        Status:  "healthy",
        HitRate: 0.95,
    }
}

func isDatabaseReady() bool {
    // æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å°±ç»ª
    return true
}

func isCacheReady() bool {
    // æ£€æŸ¥ç¼“å­˜æ˜¯å¦å°±ç»ª
    return true
}
```

### é«˜çº§å¥åº·æ£€æŸ¥ç­–ç•¥

#### **å¤šçº§å¥åº·æ£€æŸ¥**
```go
type HealthChecker struct {
    checks map[string]CheckFunc
    status map[string]string
    mu     sync.RWMutex
}

type CheckFunc func() (bool, string)

func NewHealthChecker() *HealthChecker {
    return &HealthChecker{
        checks: make(map[string]CheckFunc),
        status: make(map[string]string),
    }
}

// æ³¨å†Œæ£€æŸ¥é¡¹
func (hc *HealthChecker) RegisterCheck(name string, check CheckFunc) {
    hc.mu.Lock()
    defer hc.mu.Unlock()
    hc.checks[name] = check
}

// æ‰§è¡Œæ‰€æœ‰æ£€æŸ¥
func (hc *HealthChecker) RunChecks() map[string]string {
    hc.mu.Lock()
    defer hc.mu.Unlock()

    for name, check := range hc.checks {
        if healthy, reason := check(); healthy {
            hc.status[name] = "healthy"
        } else {
            hc.status[name] = "unhealthy: " + reason
        }
    }

    return hc.status
}

// è·å–æ•´ä½“çŠ¶æ€
func (hc *HealthChecker) GetOverallStatus() string {
    hc.mu.RLock()
    defer hc.mu.RUnlock()

    for _, status := range hc.status {
        if status != "healthy" {
            return "unhealthy"
        }
    }
    return "healthy"
}

// ä½¿ç”¨ç¤ºä¾‹
func main() {
    healthChecker := NewHealthChecker()

    // æ³¨å†Œå„ç§æ£€æŸ¥é¡¹
    healthChecker.RegisterCheck("database", checkDatabaseConnection)
    healthChecker.RegisterCheck("cache", checkCacheConnection)
    healthChecker.RegisterCheck("external_api", checkExternalAPI)
    healthChecker.RegisterCheck("disk_space", checkDiskSpace)
    healthChecker.RegisterCheck("memory_usage", checkMemoryUsage)

    // å®šæœŸæ‰§è¡Œå¥åº·æ£€æŸ¥
    go func() {
        ticker := time.NewTicker(30 * time.Second)
        defer ticker.Stop()

        for range ticker.C {
            results := healthChecker.RunChecks()
            overallStatus := healthChecker.GetOverallStatus()

            log.Printf("å¥åº·æ£€æŸ¥ç»“æœ: %+v", results)
            log.Printf("æ•´ä½“çŠ¶æ€: %s", overallStatus)

            // å¦‚æœçŠ¶æ€ä¸å¥åº·ï¼Œå¯ä»¥è§¦å‘å‘Šè­¦
            if overallStatus == "unhealthy" {
                triggerAlert(results)
            }
        }
    }()
}

func checkDatabaseConnection() (bool, string) {
    // å®ç°æ•°æ®åº“è¿æ¥æ£€æŸ¥
    return true, ""
}

func checkCacheConnection() (bool, string) {
    // å®ç°ç¼“å­˜è¿æ¥æ£€æŸ¥
    return true, ""
}

func checkExternalAPI() (bool, string) {
    // å®ç°å¤–éƒ¨APIæ£€æŸ¥
    return true, ""
}

func checkDiskSpace() (bool, string) {
    // å®ç°ç£ç›˜ç©ºé—´æ£€æŸ¥
    return true, ""
}

func checkMemoryUsage() (bool, string) {
    // å®ç°å†…å­˜ä½¿ç”¨æ£€æŸ¥
    return true, ""
}

func triggerAlert(results map[string]string) {
    // è§¦å‘å‘Šè­¦é€»è¾‘
    log.Printf("ç³»ç»Ÿå‘Šè­¦: %+v", results)
}
```

#### **å¥åº·æ£€æŸ¥ä¸è´Ÿè½½å‡è¡¡é›†æˆ**
```go
type HealthAwareBalancer struct {
    registry    registry.Registry
    selector    selector.Selector
    healthCache *HealthCache
}

type HealthCache struct {
    services map[string]map[string]bool
    mu       sync.RWMutex
}

func NewHealthAwareBalancer(reg registry.Registry) *HealthAwareBalancer {
    return &HealthAwareBalancer{
        registry:    reg,
        selector:    selector.NewSelector(),
        healthCache: NewHealthCache(),
    }
}

func (hab *HealthAwareBalancer) Select(service string, opts ...selector.SelectOption) (next selector.Next, error) {
    // è·å–æœåŠ¡èŠ‚ç‚¹
    services, err := hab.registry.GetService(service)
    if err != nil {
        return nil, err
    }

    // è¿‡æ»¤å¥åº·èŠ‚ç‚¹
    var healthyNodes []*registry.Node
    for _, svc := range services {
        for _, node := range svc.Nodes {
            if hab.healthCache.IsHealthy(service, node.Id) {
                healthyNodes = append(healthyNodes, node)
            }
        }
    }

    if len(healthyNodes) == 0 {
        return nil, fmt.Errorf("no healthy nodes available for service %s", service)
    }

    // ä½¿ç”¨é€‰æ‹©å™¨é€‰æ‹©èŠ‚ç‚¹
    return hab.selector.Select(service, opts...)
}

func (hab *HealthAwareBalancer) UpdateHealth(service, nodeID string, healthy bool) {
    hab.healthCache.Update(service, nodeID, healthy)
}

func NewHealthCache() *HealthCache {
    return &HealthCache{
        services: make(map[string]map[string]bool),
    }
}

func (hc *HealthCache) IsHealthy(service, nodeID string) bool {
    hc.mu.RLock()
    defer hc.mu.RUnlock()

    if nodes, exists := hc.services[service]; exists {
        if healthy, nodeExists := nodes[nodeID]; nodeExists {
            return healthy
        }
    }

    // é»˜è®¤è¿”å›trueï¼Œè®¤ä¸ºæ˜¯å¥åº·çš„
    return true
}

func (hc *HealthCache) Update(service, nodeID string, healthy bool) {
    hc.mu.Lock()
    defer hc.mu.Unlock()

    if _, exists := hc.services[service]; !exists {
        hc.services[service] = make(map[string]bool)
    }

    hc.services[service][nodeID] = healthy
}
```

### å¥åº·æ£€æŸ¥æœ€ä½³å®è·µ

#### **æ™ºèƒ½å¥åº·æ£€æŸ¥ç­–ç•¥**
```go
type AdaptiveHealthChecker struct {
    checkers        map[string]HealthChecker
    thresholds      map[string]HealthThreshold
    metrics         *HealthMetrics
    adaptivePolicy  *AdaptivePolicy
    mu              sync.RWMutex
}

type HealthThreshold struct {
    SuccessRate    float64 `json:"success_rate"`
    Latency        int64   `json:"latency_ms"`
    ErrorRate      float64 `json:"error_rate"`
    ConsecutiveFail int     `json:"consecutive_failures"`
}

type AdaptivePolicy struct {
    SampleSize       int           `json:"sample_size"`
    WindowSize       time.Duration `json:"window_size"`
    GracePeriod      time.Duration `json:"grace_period"`
    RampUpPeriod    time.Duration `json:"ramp_up_period"`
}

func (ahc *AdaptiveHealthChecker) EvaluateServiceHealth(serviceName string) HealthStatus {
    ahc.mu.RLock()
    checker, exists := ahc.checkers[serviceName]
    threshold := ahc.thresholds[serviceName]
    ahc.mu.RUnlock()

    if !exists {
        return HealthStatus{Status: "unknown"}
    }

    metrics := ahc.metrics.GetServiceMetrics(serviceName)

    // åŸºäºå¤šç»´åº¦æŒ‡æ ‡è¯„ä¼°å¥åº·çŠ¶æ€
    status := ahc.calculateHealthScore(metrics, threshold)

    // åº”ç”¨è‡ªé€‚åº”ç­–ç•¥
    adjustedStatus := ahc.applyAdaptivePolicy(serviceName, status, metrics)

    return adjustedStatus
}

func (ahc *AdaptiveHealthChecker) calculateHealthScore(metrics *ServiceMetrics, threshold HealthThreshold) HealthStatus {
    score := 100.0

    // æˆåŠŸç‡è¯„åˆ†
    if metrics.SuccessRate < threshold.SuccessRate {
        score -= (threshold.SuccessRate - metrics.SuccessRate) * 100
    }

    // å»¶è¿Ÿè¯„åˆ†
    if metrics.AvgLatency > time.Duration(threshold.Latency)*time.Millisecond {
        latencyRatio := float64(metrics.AvgLatency) / float64(threshold.Latency*1000000)
        score -= math.Min(latencyRatio*10, 30)
    }

    // é”™è¯¯ç‡è¯„åˆ†
    if metrics.ErrorRate > threshold.ErrorRate {
        score -= (metrics.ErrorRate - threshold.ErrorRate) * 50
    }

    // è¿ç»­å¤±è´¥æƒ©ç½š
    if metrics.ConsecutiveFailures > threshold.ConsecutiveFail {
        score -= float64(metrics.ConsecutiveFailures - threshold.ConsecutiveFail) * 15
    }

    // ç¡®å®šå¥åº·çŠ¶æ€
    switch {
    case score >= 90:
        return HealthStatus{Status: "healthy", Score: score}
    case score >= 70:
        return HealthStatus{Status: "degraded", Score: score}
    case score >= 50:
        return HealthStatus{Status: "warning", Score: score}
    default:
        return HealthStatus{Status: "critical", Score: score}
    }
}

func (ahc *AdaptiveHealthChecker) applyAdaptivePolicy(serviceName string, status HealthStatus, metrics *ServiceMetrics) HealthStatus {
    policy := ahc.adaptivePolicy

    // é‡‡æ ·æœŸåˆ¤æ–­
    if metrics.TotalRequests < policy.SampleSize {
        return HealthStatus{Status: "sampling", Score: status.Score}
    }

    // ç¼“å­˜æœŸç­–ç•¥
    if status.Status == "healthy" && metrics.Uptime < policy.GracePeriod {
        return HealthStatus{Status: "warming", Score: status.Score}
    }

    // æµé‡çªå¢å¤„ç†
    if metrics.RequestGrowth > 2.0 && status.Status != "critical" {
        return HealthStatus{Status: "scaling", Score: status.Score}
    }

    return status
}
```

#### **å¤šå±‚æ¬¡å¥åº·æ£€æŸ¥æ¶æ„**
```go
type MultiLevelHealthChecker struct {
    networkChecker   *NetworkHealthChecker
    applicationChecker *ApplicationHealthChecker
    dependencyChecker *DependencyHealthChecker
    resourceChecker  *ResourceHealthChecker
    coordinator     *HealthCoordinator
}

type HealthCoordinator struct {
    levels          map[string]HealthLevel
    weights         map[string]float64
    combinationRule  string // "weighted", "strict", "majority"
    cascadePolicy   CascadePolicy
}

type CascadePolicy struct {
    CriticalLevel  string   `json:"critical_level"`
    Affects        []string `json:"affects"`
    TriggerTimeout time.Duration `json:"trigger_timeout"`
}

func (mlhc *MultiLevelHealthChecker) GetCompositeHealth(serviceName string) (*CompositeHealthResult, error) {
    ctx, cancel := context.WithTimeout(context.Background(), 15*time.Second)
    defer cancel()

    var wg sync.WaitGroup
    results := make(chan *LevelHealthResult, 4)

    // å¹¶è¡Œæ‰§è¡Œå„å±‚çº§å¥åº·æ£€æŸ¥
    wg.Add(4)
    go mlhc.checkNetworkLevel(ctx, serviceName, &wg, results)
    go mlhc.checkApplicationLevel(ctx, serviceName, &wg, results)
    go mlhc.checkDependencyLevel(ctx, serviceName, &wg, results)
    go mlhc.checkResourceLevel(ctx, serviceName, &wg, results)

    go func() {
        wg.Wait()
        close(results)
    }()

    // æ”¶é›†ç»“æœ
    levelResults := make(map[string]*LevelHealthResult)
    for result := range results {
        levelResults[result.Level] = result
    }

    // åè°ƒå„å±‚çº§ç»“æœ
    return mlhc.coordinator.CoordinateResults(serviceName, levelResults)
}

// ç½‘ç»œå±‚å¥åº·æ£€æŸ¥
func (mlhc *MultiLevelHealthChecker) checkNetworkLevel(ctx context.Context, serviceName string, wg *sync.WaitGroup, results chan<- *LevelHealthResult) {
    defer wg.Done()

    result := &LevelHealthResult{
        Level:     "network",
        Timestamp: time.Now(),
    }

    // TCPè¿æ¥æ£€æŸ¥
    if err := mlhc.networkChecker.TCPConnectivity(ctx, serviceName); err != nil {
        result.Status = "unhealthy"
        result.Details = append(result.Details, fmt.Sprintf("TCPè¿æ¥å¤±è´¥: %v", err))
        results <- result
        return
    }

    // DNSè§£ææ£€æŸ¥
    if err := mlhc.networkChecker.DNSResolution(ctx, serviceName); err != nil {
        result.Status = "degraded"
        result.Details = append(result.Details, fmt.Sprintf("DNSè§£æå¤±è´¥: %v", err))
    } else {
        result.Status = "healthy"
    }

    // å¸¦å®½æµ‹è¯•
    bandwidth, err := mlhc.networkChecker.BandwidthTest(ctx, serviceName)
    if err == nil {
        result.Metrics = map[string]interface{}{
            "bandwidth_mbps": bandwidth,
        }
    }

    results <- result
}

// åº”ç”¨å±‚å¥åº·æ£€æŸ¥
func (mlhc *MultiLevelHealthChecker) checkApplicationLevel(ctx context.Context, serviceName string, wg *sync.WaitGroup, results chan<- *LevelHealthResult) {
    defer wg.Done()

    result := &LevelHealthResult{
        Level:     "application",
        Timestamp: time.Now(),
    }

    // HTTPå¥åº·æ£€æŸ¥
    httpStatus, latency, err := mlhc.applicationChecker.HTTPHealthCheck(ctx, serviceName)
    if err != nil {
        result.Status = "unhealthy"
        result.Details = append(result.Details, fmt.Sprintf("HTTPå¥åº·æ£€æŸ¥å¤±è´¥: %v", err))
        results <- result
        return
    }

    // åº”ç”¨æŒ‡æ ‡æ”¶é›†
    metrics, err := mlhc.applicationChecker.GetApplicationMetrics(ctx, serviceName)
    if err != nil {
        result.Status = "degraded"
        result.Details = append(result.Details, fmt.Sprintf("åº”ç”¨æŒ‡æ ‡æ”¶é›†å¤±è´¥: %v", err))
    } else {
        result.Status = mlhc.evaluateApplicationHealth(httpStatus, metrics)
        result.Metrics = metrics
    }

    result.Metrics["http_status"] = httpStatus
    result.Metrics["latency_ms"] = latency.Milliseconds()

    results <- result
}

// ä¾èµ–å±‚å¥åº·æ£€æŸ¥
func (mlhc *MultiLevelHealthChecker) checkDependencyLevel(ctx context.Context, serviceName string, wg *sync.WaitGroup, results chan<- *LevelHealthResult) {
    defer wg.Done()

    result := &LevelHealthResult{
        Level:     "dependency",
        Timestamp: time.Now(),
    }

    dependencies, err := mlhc.dependencyChecker.GetDependencies(serviceName)
    if err != nil {
        result.Status = "unknown"
        result.Details = append(result.Details, fmt.Sprintf("è·å–ä¾èµ–åˆ—è¡¨å¤±è´¥: %v", err))
        results <- result
        return
    }

    var healthyCount, totalCount int
    dependencyStatus := make(map[string]interface{})

    for _, dep := range dependencies {
        depHealth, err := mlhc.dependencyChecker.CheckDependencyHealth(ctx, dep)
        if err != nil {
            dependencyStatus[dep.Name] = map[string]interface{}{
                "status": "unhealthy",
                "error":  err.Error(),
            }
        } else {
            dependencyStatus[dep.Name] = depHealth
            if depHealth.Status == "healthy" {
                healthyCount++
            }
        }
        totalCount++
    }

    if totalCount == 0 {
        result.Status = "healthy"
    } else {
        healthRatio := float64(healthyCount) / float64(totalCount)
        switch {
        case healthRatio >= 0.9:
            result.Status = "healthy"
        case healthRatio >= 0.7:
            result.Status = "degraded"
        case healthRatio >= 0.5:
            result.Status = "warning"
        default:
            result.Status = "unhealthy"
        }
    }

    result.Metrics = map[string]interface{}{
        "dependencies": dependencyStatus,
        "healthy_ratio":  float64(healthyCount) / float64(totalCount),
    }

    results <- result
}

// èµ„æºå±‚å¥åº·æ£€æŸ¥
func (mlhc *MultiLevelHealthChecker) checkResourceLevel(ctx context.Context, serviceName string, wg *sync.WaitGroup, results chan<- *LevelHealthResult) {
    defer wg.Done()

    result := &LevelHealthResult{
        Level:     "resource",
        Timestamp: time.Now(),
    }

    // CPUä½¿ç”¨ç‡
    cpuUsage, err := mlhc.resourceChecker.GetCPUUsage(ctx, serviceName)
    if err != nil {
        result.Status = "unknown"
        result.Details = append(result.Details, fmt.Sprintf("CPUä½¿ç”¨ç‡è·å–å¤±è´¥: %v", err))
    }

    // å†…å­˜ä½¿ç”¨ç‡
    memUsage, err := mlhc.resourceChecker.GetMemoryUsage(ctx, serviceName)
    if err != nil {
        result.Status = "unknown"
        result.Details = append(result.Details, fmt.Sprintf("å†…å­˜ä½¿ç”¨ç‡è·å–å¤±è´¥: %v", err))
    }

    // ç£ç›˜ä½¿ç”¨ç‡
    diskUsage, err := mlhc.resourceChecker.GetDiskUsage(ctx, serviceName)
    if err != nil {
        result.Status = "unknown"
        result.Details = append(result.Details, fmt.Sprintf("ç£ç›˜ä½¿ç”¨ç‡è·å–å¤±è´¥: %v", err))
    }

    if result.Status == "unknown" && len(result.Details) == 0 {
        result.Status = mlhc.evaluateResourceHealth(cpuUsage, memUsage, diskUsage)
    }

    result.Metrics = map[string]interface{}{
        "cpu_usage_percent":    cpuUsage,
        "memory_usage_percent": memUsage,
        "disk_usage_percent":   diskUsage,
    }

    results <- result
}
```

#### **ä¼˜é›…é™çº§ç­–ç•¥**
```go
type GracefulDegradation struct {
    service         *micro.Service
    healthChecker   *HealthChecker
    degradedMode    bool
    mu             sync.RWMutex
    degradationRules []DegradationRule
    rollbackPlan    *RollbackPlan
    metrics        *DegradationMetrics
}

type DegradationRule struct {
    Name           string
    CheckFunc      func() bool
    DegradationFunc func()
    Priority       int
    Timeout        time.Duration
    RollbackFunc   func()
}

type RollbackPlan struct {
    Steps         []RollbackStep
    CheckInterval  time.Duration
    MaxRetries    int
}

type RollbackStep struct {
    Name          string
    ExecuteFunc   func() error
    ValidateFunc  func() bool
    Timeout       time.Duration
}

func (gd *GracefulDegradation) Start() {
    go func() {
        ticker := time.NewTicker(10 * time.Second)
        defer ticker.Stop()

        for range ticker.C {
            gd.checkAndDegrade()
        }
    }()
}

func (gd *GracefulDegradation) checkAndDegrade() {
    results := gd.healthChecker.RunChecks()
    overallStatus := gd.healthChecker.GetOverallStatus()

    gd.mu.Lock()
    defer gd.mu.Unlock()

    if overallStatus == "healthy" && gd.degradedMode {
        // æ¢å¤æ­£å¸¸æ¨¡å¼
        gd.recoverFromDegradation()
    } else if overallStatus == "unhealthy" && !gd.degradedMode {
        // è¿›å…¥é™çº§æ¨¡å¼
        gd.enterDegradationMode(results)
    } else if overallStatus == "degraded" && !gd.degradedMode {
        // éƒ¨åˆ†é™çº§
        gd.enterPartialDegradation(results)
    }
}

func (gd *GracefulDegradation) enterDegradationMode(results map[string]string) {
    log.Println("è¿›å…¥é™çº§æ¨¡å¼")
    gd.degradedMode = true

    // æŒ‰ä¼˜å…ˆçº§æ‰§è¡Œé™çº§è§„åˆ™
    sort.Slice(gd.degradationRules, func(i, j int) bool {
        return gd.degradationRules[i].Priority > gd.degradationRules[j].Priority
    })

    for _, rule := range gd.degradationRules {
        if !rule.CheckFunc() {
            log.Printf("æ‰§è¡Œé™çº§è§„åˆ™: %s", rule.Name)

            // è¶…æ—¶æ§åˆ¶
            timeoutCtx, cancel := context.WithTimeout(context.Background(), rule.Timeout)
            defer cancel()

            done := make(chan struct{})
            go func() {
                rule.DegradationFunc()
                close(done)
            }()

            select {
            case <-done:
                log.Printf("é™çº§è§„åˆ™ %s æ‰§è¡Œå®Œæˆ", rule.Name)
                gd.metrics.RecordDegradation(rule.Name, "success")
            case <-timeoutCtx.Done():
                log.Printf("é™çº§è§„åˆ™ %s æ‰§è¡Œè¶…æ—¶", rule.Name)
                gd.metrics.RecordDegradation(rule.Name, "timeout")

                // æ‰§è¡Œå›æ»š
                if rule.RollbackFunc != nil {
                    go rule.RollbackFunc()
                }
            }
        }
    }

    // å‘é€å‘Šè­¦
    gd.sendAlert(results)
}

func (gd *GracefulDegradation) enterPartialDegradation(results map[string]string) {
    log.Println("è¿›å…¥éƒ¨åˆ†é™çº§æ¨¡å¼")

    // ä»…æ‰§è¡Œå…³é”®é™çº§è§„åˆ™
    for _, rule := range gd.degradationRules {
        if rule.Priority >= 10 && !rule.CheckFunc() {
            log.Printf("æ‰§è¡Œå…³é”®é™çº§è§„åˆ™: %s", rule.Name)
            rule.DegradationFunc()
            gd.metrics.RecordDegradation(rule.Name, "partial")
        }
    }
}

func (gd *GracefulDegradation) recoverFromDegradation() {
    log.Println("ä»é™çº§æ¨¡å¼æ¢å¤")
    gd.degradedMode = false

    // æ‰§è¡Œå›æ»šè®¡åˆ’
    if gd.rollbackPlan != nil {
        success := gd.executeRollbackPlan()
        if !success {
            log.Println("å›æ»šè®¡åˆ’æ‰§è¡Œå¤±è´¥ï¼Œä¿æŒé™çº§æ¨¡å¼")
            gd.degradedMode = true
            return
        }
    }

    // æ¢å¤æœåŠ¡
    gd.recoverServices()
    gd.sendRecoveryNotification()
    gd.metrics.RecordRecovery()
}

func (gd *GracefulDegradation) executeRollbackPlan() bool {
    for _, step := range gd.rollbackPlan.Steps {
        for attempt := 0; attempt < gd.rollbackPlan.MaxRetries; attempt++ {
            timeoutCtx, cancel := context.WithTimeout(context.Background(), step.Timeout)
            defer cancel()

            done := make(chan struct{})
            errChan := make(chan error, 1)

            go func() {
                if err := step.ExecuteFunc(); err != nil {
                    errChan <- err
                } else {
                    close(done)
                }
            }()

            select {
            case <-done:
                // éªŒè¯å›æ»šç»“æœ
                if step.ValidateFunc() {
                    log.Printf("å›æ»šæ­¥éª¤ %s æ‰§è¡ŒæˆåŠŸ", step.Name)
                    break
                }
                log.Printf("å›æ»šæ­¥éª¤ %s éªŒè¯å¤±è´¥ï¼Œé‡è¯•ä¸­...", step.Name)

            case <-timeoutCtx.Done():
                log.Printf("å›æ»šæ­¥éª¤ %s æ‰§è¡Œè¶…æ—¶", step.Name)
                return false

            case err := <-errChan:
                log.Printf("å›æ»šæ­¥éª¤ %s æ‰§è¡Œå¤±è´¥: %v", step.Name, err)
                if attempt == gd.rollbackPlan.MaxRetries-1 {
                    return false
                }
            }

            time.Sleep(gd.rollbackPlan.CheckInterval)
        }
    }

    return true
}
```

è¿™äº›å¥åº·æ£€æŸ¥æœºåˆ¶ç¡®ä¿äº† Go Micro æœåŠ¡çš„å¯ç”¨æ€§å’Œç¨³å®šæ€§ï¼Œé€šè¿‡å¤šå±‚æ¬¡ã€å¤šè§’åº¦çš„å¥åº·ç›‘æ§ï¼ŒåŠæ—¶å‘ç°å’Œå¤„ç†æœåŠ¡å¼‚å¸¸ï¼Œä¸ºç”Ÿäº§ç¯å¢ƒæä¾›äº†å¼ºå¤§çš„ä¿éšœã€‚

## âš–ï¸ å®¢æˆ·ç«¯è´Ÿè½½å‡è¡¡ç­–ç•¥æ·±åº¦è§£æ

### è´Ÿè½½å‡è¡¡æ¶æ„æ¦‚è¿°

Go Micro çš„å®¢æˆ·ç«¯è´Ÿè½½å‡è¡¡é‡‡ç”¨**é€‰æ‹©å™¨æ¨¡å¼**ï¼ˆSelector Patternï¼‰ï¼Œå®ƒä½äºå®¢æˆ·ç«¯å’ŒæœåŠ¡å‘ç°å±‚ä¹‹é—´ï¼Œè´Ÿè´£ä»å¤šä¸ªå¯ç”¨æœåŠ¡å®ä¾‹ä¸­é€‰æ‹©æœ€ä¼˜çš„ä¸€ä¸ªè¿›è¡Œè¯·æ±‚åˆ†å‘ã€‚

### æ ¸å¿ƒè´Ÿè½½å‡è¡¡ç­–ç•¥

#### **1. Round-Robin è½®è¯¢ç­–ç•¥**
```go
package balancer

import (
    "github.com/go-micro/go-micro/v4/selector"
    "github.com/go-micro/go-micro/v4/registry"
)

type RoundRobinBalancer struct {
    index map[string]int
    mu    sync.RWMutex
}

func NewRoundRobinBalancer() selector.Balancer {
    return &RoundRobinBalancer{
        index: make(map[string]int),
    }
}

func (r *RoundRobinBalancer) Select(service string, nodes []*registry.Node) (*registry.Node, error) {
    if len(nodes) == 0 {
        return nil, selector.ErrNoneAvailable
    }

    r.mu.Lock()
    defer r.mu.Unlock()

    // è·å–å½“å‰æœåŠ¡çš„ç´¢å¼•
    currentIndex := r.index[service]
    selectedIndex := currentIndex % len(nodes)

    // æ›´æ–°ç´¢å¼•
    r.index[service] = currentIndex + 1

    return nodes[selectedIndex], nil
}

func (r *RoundRobinBalancer) String() string {
    return "roundrobin"
}

// ä½¿ç”¨ç¤ºä¾‹
func main() {
    // åˆ›å»ºé€‰æ‹©å™¨å¹¶è®¾ç½®è½®è¯¢å‡è¡¡å™¨
    selector := selector.NewSelector(
        selector.SetBalancer(NewRoundRobinBalancer()),
    )

    service := micro.NewService(
        micro.Name("client-service"),
        micro.Selector(selector),
    )

    // è¿›è¡ŒæœåŠ¡è°ƒç”¨
    client := service.Client()
    response := proto.UserResponse{}
    err := client.Call(context.Background(),
        "user-service",
        "GetUser",
        &proto.UserRequest{UserId: "123"},
        &response)
}
```

#### **2. Random éšæœºç­–ç•¥**
```go
type RandomBalancer struct{}

func NewRandomBalancer() selector.Balancer {
    return &RandomBalancer{}
}

func (r *RandomBalancer) Select(service string, nodes []*registry.Node) (*registry.Node, error) {
    if len(nodes) == 0 {
        return nil, selector.ErrNoneAvailable
    }

    // éšæœºé€‰æ‹©èŠ‚ç‚¹
    randomIndex := rand.Intn(len(nodes))
    return nodes[randomIndex], nil
}

func (r *RandomBalancer) String() string {
    return "random"
}
```

#### **3. Least Connection æœ€å°‘è¿æ¥ç­–ç•¥**
```go
type ConnectionTracker struct {
    connections map[string]int // service -> nodeID -> connectionCount
    mu           sync.RWMutex
}

type LeastConnectionBalancer struct {
    tracker *ConnectionTracker
}

func NewLeastConnectionBalancer() *LeastConnectionBalancer {
    return &LeastConnectionBalancer{
        tracker: NewConnectionTracker(),
    }
}

func (l *LeastConnectionBalancer) Select(service string, nodes []*registry.Node) (*registry.Node, error) {
    if len(nodes) == 0 {
        return nil, selector.ErrNoneAvailable
    }

    // è·å–æ¯ä¸ªèŠ‚ç‚¹çš„è¿æ¥æ•°
    var nodeStats []*NodeStats
    for _, node := range nodes {
        connections := l.tracker.GetConnectionCount(service, node.Id)
        nodeStats = append(nodeStats, &NodeStats{
            Node:        node,
            Connections: connections,
        })
    }

    // æŒ‰è¿æ¥æ•°æ’åº
    sort.Slice(nodeStats, func(i, j int) bool {
        return nodeStats[i].Connections < nodeStats[j].Connections
    })

    return nodeStats[0].Node, nil
}

func (l *LeastConnectionBalancer) String() string {
    return "least-connection"
}

type NodeStats struct {
    Node        *registry.Node
    Connections int
}

type ConnectionTracker struct {
    connections map[string]map[string]int // service -> nodeID -> connectionCount
    mu           sync.RWMutex
}

func NewConnectionTracker() *ConnectionTracker {
    return &ConnectionTracker{
        connections: make(map[string]map[string]int),
    }
}

func (ct *ConnectionTracker) Increment(service, nodeID string) {
    ct.mu.Lock()
    defer ct.mu.Unlock()

    if _, exists := ct.connections[service]; !exists {
        ct.connections[service] = make(map[string]int)
    }

    ct.connections[service][nodeID]++
}

func (ct *ConnectionTracker) Decrement(service, nodeID string) {
    ct.mu.Lock()
    defer ct.mu.Unlock()

    if _, exists := ct.connections[service]; exists {
        if count, nodeExists := ct.connections[service][nodeID]; nodeExists && count > 0 {
            ct.connections[service][nodeID]--
        }
    }
}

func (ct *ConnectionTracker) GetConnectionCount(service, nodeID string) int {
    ct.mu.RLock()
    defer ct.mu.RUnlock()

    if _, exists := ct.connections[service]; exists {
        return ct.connections[service][nodeID]
    }

    return 0
}
```

#### **4. Weighted åŠ æƒç­–ç•¥**
```go
type WeightedBalancer struct {
    weightCalculator WeightCalculator
}

type WeightCalculator interface {
    CalculateWeight(node *registry.Node) int
}

type NodeWeightCalculator struct{}

func (n *NodeWeightCalculator) CalculateWeight(node *registry.Node) int {
    // ä»èŠ‚ç‚¹å…ƒæ•°æ®ä¸­è·å–æƒé‡
    if weightStr, exists := node.Metadata["weight"]; exists {
        if weight, err := strconv.Atoi(weightStr); err == nil {
            return weight
        }
    }

    // é»˜è®¤æƒé‡
    return 1
}

func NewWeightedBalancer(calculator WeightCalculator) *WeightedBalancer {
    if calculator == nil {
        calculator = &NodeWeightCalculator{}
    }
    return &WeightedBalancer{
        weightCalculator: calculator,
    }
}

func (w *WeightedBalancer) Select(service string, nodes []*registry.Node) (*registry.Node, error) {
    if len(nodes) == 0 {
        return nil, selector.ErrNoneAvailable
    }

    // è®¡ç®—æ€»æƒé‡
    var totalWeight int
    var weightedNodes []*WeightedNode
    for _, node := range nodes {
        weight := w.weightCalculator.CalculateWeight(node)
        totalWeight += weight
        weightedNodes = append(weightedNodes, &WeightedNode{
            Node:   node,
            Weight: weight,
        })
    }

    if totalWeight == 0 {
        return nil, selector.ErrNoneAvailable
    }

    // ç”Ÿæˆéšæœºæ•°é€‰æ‹©èŠ‚ç‚¹
    randomWeight := rand.Intn(totalWeight)
    currentWeight := 0

    for _, weightedNode := range weightedNodes {
        currentWeight += weightedNode.Weight
        if randomWeight < currentWeight {
            return weightedNode.Node, nil
        }
    }

    return weightedNodes[len(weightedNodes)-1].Node, nil
}

func (w *WeightedBalancer) String() string {
    return "weighted"
}

type WeightedNode struct {
    Node   *registry.Node
    Weight int
}
```

### é«˜çº§è´Ÿè½½å‡è¡¡ç‰¹æ€§

#### **è‡ªé€‚åº”å»¶è¿Ÿæ„ŸçŸ¥è´Ÿè½½å‡è¡¡**
```go
type AdaptiveLatencyBalancer struct {
    latencyTracker    *AdaptiveLatencyTracker
    regionAwareness  *RegionAwareness
    congestionControl *CongestionControl
    trendAnalyzer    *TrendAnalyzer
    metrics         *BalancerMetrics
}

type AdaptiveLatencyTracker struct {
    latencies       map[string]map[string]*LatencyWindow // service -> nodeID -> latency window
    weights         map[string]map[string]float64        // service -> nodeID -> dynamic weight
    regionLatencies map[string]map[string]time.Duration // region -> service -> avg latency
    mu              sync.RWMutex
    windowSize      int
    sampleInterval time.Duration
}

type LatencyWindow struct {
    samples []time.Duration
    mean     time.Duration
    stdDev   time.Duration
    trend    string // "improving", "stable", "degrading"
    updated  time.Time
}

type CongestionControl struct {
    thresholds      map[string]int64 // nodeID -> current threshold
    backpressure    map[string]bool // nodeID -> under backpressure
    recoveryTime    map[string]time.Time
    adaptiveWindow  bool
    minThreshold   int64
    maxThreshold   int64
}

func NewAdaptiveLatencyBalancer() *AdaptiveLatencyBalancer {
    return &AdaptiveLatencyBalancer{
        latencyTracker:    NewAdaptiveLatencyTracker(20, time.Second*30),
        regionAwareness:  NewRegionAwareness(),
        congestionControl: NewCongestionControl(true),
        trendAnalyzer:    NewTrendAnalyzer(),
        metrics:         NewBalancerMetrics(),
    }
}

func (alb *AdaptiveLatencyBalancer) Select(service string, nodes []*registry.Node) (*registry.Node, error) {
    if len(nodes) == 0 {
        return nil, selector.ErrNoneAvailable
    }

    // è·å–èŠ‚ç‚¹æ€§èƒ½æŒ‡æ ‡
    nodeScores := make([]*NodeScore, 0, len(nodes))
    for _, node := range nodes {
        score := alb.calculateNodeScore(service, node)
        nodeScores = append(nodeScores, score)
    }

    // æŒ‰ç»¼åˆè¯„åˆ†æ’åº
    sort.Slice(nodeScores, func(i, j int) bool {
        return nodeScores[i].TotalScore > nodeScores[j].TotalScore
    })

    // åº”ç”¨æ‹¥å¡æ§åˆ¶
    selected := alb.applyCongestionControl(service, nodeScores)
    if selected == nil {
        return nil, selector.ErrNoneAvailable
    }

    log.Printf("é€‰æ‹©æœ€ä¼˜èŠ‚ç‚¹: %s (è¯„åˆ†: %.2f, å»¶è¿Ÿ: %v, æ‹¥å¡åº¦: %.2f)",
        selected.Node.Id, selected.TotalScore, selected.Latency, selected.CongestionScore)

    return selected.Node, nil
}

func (alb *AdaptiveLatencyBalancer) calculateNodeScore(service string, node *registry.Node) *NodeScore {
    score := &NodeScore{
        Node:     node,
        Latency:  alb.latencyTracker.GetAverageLatency(service, node.Id),
    }

    // å»¶è¿Ÿè¯„åˆ† (æƒé‡ 40%)
    latencyScore := alb.calculateLatencyScore(service, node)

    // æ‹¥å¡æ§åˆ¶è¯„åˆ† (æƒé‡ 30%)
    congestionScore := alb.calculateCongestionScore(node)

    // åŒºåŸŸæ„ŸçŸ¥è¯„åˆ† (æƒé‡ 20%)
    regionScore := alb.regionAwareness.CalculateRegionScore(node)

    // è¶‹åŠ¿è¯„åˆ† (æƒé‡ 10%)
    trendScore := alb.trendAnalyzer.CalculateTrendScore(service, node.Id)

    // ç»¼åˆè¯„åˆ†è®¡ç®—
    score.TotalScore = latencyScore*0.4 + congestionScore*0.3 + regionScore*0.2 + trendScore*0.1
    score.LatencyScore = latencyScore
    score.CongestionScore = congestionScore
    score.RegionScore = regionScore
    score.TrendScore = trendScore

    return score
}

func (alb *AdaptiveLatencyBalancer) calculateLatencyScore(service string, node *registry.Node) float64 {
    latency := alb.latencyTracker.GetAverageLatency(service, node.Id)
    if latency == 0 {
        return 1.0
    }

    // ä½¿ç”¨å¯¹æ•°å‡½æ•°å°†å»¶è¿Ÿæ˜ å°„åˆ°0-1åˆ†ï¼Œå»¶è¿Ÿè¶Šä½åˆ†æ•°è¶Šé«˜
    maxLatency := 5 * time.Second
    if latency >= maxLatency {
        return 0.1
    }

    return math.Log(float64(maxLatency/latency)) / math.Log(float64(maxLatency/time.Millisecond))
}

func (alb *AdaptiveLatencyBalancer) calculateCongestionScore(node *registry.Node) float64 {
    congestionLevel := alb.congestionControl.GetCongestionLevel(node.Id)

    // æ‹¥å¡ç¨‹åº¦è¶Šé«˜ï¼Œåˆ†æ•°è¶Šä½
    switch congestionLevel {
    case "low":
        return 1.0
    case "medium":
        return 0.6
    case "high":
        return 0.3
    case "critical":
        return 0.1
    default:
        return 0.8
    }
}

func (alb *AdaptiveLatencyBalancer) applyCongestionControl(service string, nodes []*NodeScore) *NodeScore {
    alb.congestionControl.UpdateThresholds(nodes)

    // è¿‡æ»¤æ‰å¤„äºä¸¥é‡æ‹¥å¡çŠ¶æ€çš„èŠ‚ç‚¹
    var availableNodes []*NodeScore
    for _, node := range nodes {
        if !alb.congestionControl.IsUnderBackpressure(node.Node.Id) {
            availableNodes = append(availableNodes, node)
        }
    }

    if len(availableNodes) == 0 {
        // å¦‚æœæ‰€æœ‰èŠ‚ç‚¹éƒ½æ‹¥å¡ï¼Œé€‰æ‹©æ‹¥å¡ç¨‹åº¦æœ€è½»çš„
        return nodes[0]
    }

    return availableNodes[0]
}

func NewAdaptiveLatencyTracker(windowSize int, sampleInterval time.Duration) *AdaptiveLatencyTracker {
    return &AdaptiveLatencyTracker{
        latencies:       make(map[string]map[string]*LatencyWindow),
        weights:         make(map[string]map[string]float64),
        regionLatencies: make(map[string]map[string]time.Duration),
        windowSize:      windowSize,
        sampleInterval:  sampleInterval,
    }
}

func (alt *AdaptiveLatencyTracker) Record(service, nodeID string, latency time.Duration) {
    alt.mu.Lock()
    defer alt.mu.Unlock()

    key := service + ":" + nodeID
    if _, exists := alt.latencies[service]; !exists {
        alt.latencies[service] = make(map[string]*LatencyWindow)
    }

    window, exists := alt.latencies[service][nodeID]
    if !exists {
        window = &LatencyWindow{
            samples: make([]time.Duration, 0, alt.windowSize),
            updated: time.Now(),
        }
        alt.latencies[service][nodeID] = window
    }

    // æ·»åŠ æ–°æ ·æœ¬
    window.samples = append(window.samples, latency)

    // ä¿æŒçª—å£å¤§å°
    if len(window.samples) > alt.windowSize {
        window.samples = window.samples[1:]
    }

    // è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
    alt.updateWindowStatistics(window)

    // æ›´æ–°åŒºåŸŸå»¶è¿Ÿ
    if region := alt.getNodeRegion(nodeID); region != "" {
        alt.updateRegionLatency(region, service, latency)
    }
}

func (alt *AdaptiveLatencyTracker) updateWindowStatistics(window *LatencyWindow) {
    if len(window.samples) == 0 {
        return
    }

    // è®¡ç®—å¹³å‡å€¼
    var total time.Duration
    for _, sample := range window.samples {
        total += sample
    }
    window.mean = total / time.Duration(len(window.samples))

    // è®¡ç®—æ ‡å‡†å·®
    if len(window.samples) > 1 {
        var variance float64
        for _, sample := range window.samples {
            diff := float64(sample - window.mean)
            variance += diff * diff
        }
        variance /= float64(len(window.samples))
        window.stdDev = time.Duration(math.Sqrt(variance))
    }

    // åˆ†æè¶‹åŠ¿
    window.trend = alt.analyzeTrend(window.samples)
    window.updated = time.Now()
}

func (alt *AdaptiveLatencyTracker) analyzeTrend(samples []time.Duration) string {
    if len(samples) < 3 {
        return "stable"
    }

    // ç®€å•çš„çº¿æ€§å›å½’åˆ†æè¶‹åŠ¿
    n := len(samples)
    sumX := float64(n * (n - 1) / 2)
    sumY := 0.0
    sumXY := 0.0
    sumXX := 0.0

    for i, sample := range samples {
        x := float64(i)
        y := float64(sample)
        sumY += y
        sumXY += x * y
        sumXX += x * x
    }

    slope := (float64(n)*sumXY - sumX*sumY) / (float64(n)*sumXX - sumX*sumX)

    // æ ¹æ®æ–œç‡åˆ¤æ–­è¶‹åŠ¿
    if slope > -1000000 { // ä¸‹é™è¶‹åŠ¿
        return "improving"
    } else if slope < 1000000 { // ä¸Šå‡è¶‹åŠ¿
        return "degrading"
    }
    return "stable"
}

type NodeScore struct {
    Node            *registry.Node
    TotalScore      float64
    LatencyScore    float64
    CongestionScore float64
    RegionScore     float64
    TrendScore      float64
    Latency         time.Duration
}

// åŠ¨æ€æƒé‡è°ƒæ•´ç®—æ³•
type DynamicWeightAdjuster struct {
    balancer        *AdaptiveLatencyBalancer
    adjustmentRules []WeightAdjustmentRule
    metrics        *WeightMetrics
    adjustmentLock sync.RWMutex
}

type WeightAdjustmentRule struct {
    Condition     func(*NodeScore) bool
    Adjustment    func(*NodeScore) float64
    Priority      int
    Description   string
}

func (dwa *DynamicWeightAdjuster) AdjustWeights(service string, nodes []*registry.Node) {
    dwa.adjustmentLock.Lock()
    defer dwa.adjustmentLock.Unlock()

    // è®¡ç®—å½“å‰èŠ‚ç‚¹è¯„åˆ†
    nodeScores := make([]*NodeScore, len(nodes))
    for i, node := range nodes {
        nodeScores[i] = dwa.balancer.calculateNodeScore(service, node)
    }

    // åº”ç”¨æƒé‡è°ƒæ•´è§„åˆ™
    for _, score := range nodeScores {
        for _, rule := range dwa.adjustmentRules {
            if rule.Condition(score) {
                newWeight := rule.Adjustment(score)
                dwa.balancer.latencyTracker.UpdateWeight(service, score.Node.Id, newWeight)
                log.Printf("æƒé‡è°ƒæ•´: %s -> %.2f (è§„åˆ™: %s)", score.Node.Id, newWeight, rule.Description)
                break
            }
        }
    }
}

func (dwa *DynamicWeightAdjuster) AddRule(rule WeightAdjustmentRule) {
    dwa.adjustmentRules = append(dwa.adjustmentRules, rule)
    // æŒ‰ä¼˜å…ˆçº§æ’åº
    sort.Slice(dwa.adjustmentRules, func(i, j int) bool {
        return dwa.adjustmentRules[i].Priority > dwa.adjustmentRules[j].Priority
    })
}
```

#### **æ™ºèƒ½ç†”æ–­å™¨é›†æˆ**
```go
type SmartCircuitBreakerBalancer struct {
    breaker      *AdaptiveCircuitBreaker
    childBalancer selector.Balancer
    metrics      *CircuitBreakerMetrics
    policy       *CircuitBreakerPolicy
}

type AdaptiveCircuitBreaker struct {
    states           map[string]*BreakerState      // service -> state
    healthMetrics    map[string]*HealthMetrics    // service -> metrics
    recoveryStrategies map[string]RecoveryStrategy // service -> recovery strategy
    mu               sync.RWMutex
    config           *CircuitBreakerConfig
}

type BreakerState struct {
    State           string    // "open", "closed", "half-open"
    Failures        int
    LastFailure     time.Time
    RecoveryCount   int
    SuccessRate     float64
    LatencyPercentile time.Duration
}

type CircuitBreakerConfig struct {
    MaxFailures          int           `json:"max_failures"`
    Timeout              time.Duration `json:"timeout"`
    HalfOpenRequests    int           `json:"half_open_requests"`
    SuccessThreshold    float64       `json:"success_threshold"`
    RecoveryDelay       time.Duration `json:"recovery_delay"`
    LatencyThreshold    time.Duration `json:"latency_threshold"`
}

type HealthMetrics struct {
    TotalRequests     int64
    SuccessRequests   int64
    FailedRequests    int64
    LatencySamples    []time.Duration
    ErrorRate        float64
    LastUpdated      time.Time
}

func NewSmartCircuitBreakerBalancer(balancer selector.Balancer) *SmartCircuitBreakerBalancer {
    return &SmartCircuitBreakerBalancer{
        childBalancer: balancer,
        breaker:      NewAdaptiveCircuitBreaker(&CircuitBreakerConfig{
            MaxFailures:       5,
            Timeout:           time.Minute,
            HalfOpenRequests: 3,
            SuccessThreshold: 0.6,
            RecoveryDelay:    time.Second * 30,
            LatencyThreshold: time.Second * 2,
        }),
        metrics: NewCircuitBreakerMetrics(),
        policy:  NewCircuitBreakerPolicy(),
    }
}

func (scb *SmartCircuitBreakerBalancer) Select(service string, nodes []*registry.Node) (*registry.Node, error) {
    // æ£€æŸ¥ç†”æ–­å™¨çŠ¶æ€
    state := scb.breaker.GetState(service)
    switch state.State {
    case "open":
        return nil, fmt.Errorf("circuit breaker open for service %s", service)
    case "half-open":
        // åŠå¼€çŠ¶æ€ä¸‹åªå…è®¸å°‘é‡è¯·æ±‚
        if !scb.shouldAllowHalfOpenRequest(service) {
            return nil, fmt.Errorf("circuit breaker half-open, rejecting request for service %s", service)
        }
    }

    // ä½¿ç”¨å­å‡è¡¡å™¨é€‰æ‹©èŠ‚ç‚¹
    node, err := scb.childBalancer.Select(service, nodes)
    if err != nil {
        scb.breaker.RecordFailure(service, err)
        return nil, err
    }

    return node, nil
}

func (scb *SmartCircuitBreakerBalancer) RecordSuccess(service string, latency time.Duration) {
    scb.breaker.RecordSuccess(service, latency)
}

func (scb *SmartCircuitBreakerBalancer) RecordFailure(service string, err error) {
    scb.breaker.RecordFailure(service, err)
}

func (scb *SmartCircuitBreakerBalancer) shouldAllowHalfOpenRequest(service string) bool {
    scb.breaker.mu.RLock()
    defer scb.breaker.mu.RUnlock()

    state := scb.breaker.states[service]
    if state == nil || state.State != "half-open" {
        return false
    }

    // æ£€æŸ¥æ˜¯å¦è¶…è¿‡åŠå¼€çŠ¶æ€çš„æœ€å¤§è¯·æ±‚æ•°
    if state.RecoveryCount >= scb.breaker.config.HalfOpenRequests {
        return false
    }

    return true
}

func NewAdaptiveCircuitBreaker(config *CircuitBreakerConfig) *AdaptiveCircuitBreaker {
    return &AdaptiveCircuitBreaker{
        states:           make(map[string]*BreakerState),
        healthMetrics:    make(map[string]*HealthMetrics),
        recoveryStrategies: make(map[string]RecoveryStrategy),
        config:           config,
    }
}

func (acb *AdaptiveCircuitBreaker) RecordSuccess(service string, latency time.Duration) {
    acb.mu.Lock()
    defer acb.mu.Unlock()

    state := acb.getOrCreateState(service)
    metrics := acb.getOrCreateMetrics(service)

    // æ›´æ–°æŒ‡æ ‡
    metrics.TotalRequests++
    metrics.SuccessRequests++
    metrics.LatencySamples = append(metrics.LatencySamples, latency)
    metrics.LastUpdated = time.Now()

    // æ›´æ–°çŠ¶æ€
    if state.State == "half-open" {
        state.RecoveryCount++
        // è®¡ç®—æˆåŠŸç‡
        successRate := float64(state.RecoveryCount) / float64(acb.config.HalfOpenRequests)
        state.SuccessRate = successRate

        if successRate >= acb.config.SuccessThreshold {
            // æ¢å¤åˆ°å…³é—­çŠ¶æ€
            state.State = "closed"
            state.RecoveryCount = 0
            log.Printf("ç†”æ–­å™¨æ¢å¤åˆ°å…³é—­çŠ¶æ€ for service %s", service)
        }
    } else {
        state.Failures = 0
        state.State = "closed"
    }

    // æ›´æ–°å»¶è¿Ÿç™¾åˆ†ä½
    acb.updateLatencyPercentile(service)
}

func (acb *AdaptiveCircuitBreaker) RecordFailure(service string, err error) {
    acb.mu.Lock()
    defer acb.mu.Unlock()

    state := acb.getOrCreateState(service)
    metrics := acb.getOrCreateMetrics(service)

    // æ›´æ–°æŒ‡æ ‡
    metrics.TotalRequests++
    metrics.FailedRequests++
    metrics.LastUpdated = time.Now()
    metrics.ErrorRate = float64(metrics.FailedRequests) / float64(metrics.TotalRequests)

    // æ›´æ–°çŠ¶æ€
    state.Failures++
    state.LastFailure = time.Now()

    if state.Failures >= acb.config.MaxFailures {
        // æ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªé€‚åº”è°ƒæ•´é˜ˆå€¼
        if acb.shouldAdaptThreshold(service, metrics) {
            acb.adaptThreshold(service, metrics)
        }

        state.State = "open"
        state.RecoveryCount = 0
        log.Printf("ç†”æ–­å™¨å¼€å¯ for service %s (å¤±è´¥æ¬¡æ•°: %d)", service, state.Failures)
    }
}

func (acb *AdaptiveCircuitBreaker) shouldAdaptThreshold(service string, metrics *HealthMetrics) bool {
    // åŸºäºé”™è¯¯ç‡å’Œå»¶è¿Ÿè¶‹åŠ¿åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒæ•´é˜ˆå€¼
    if metrics.TotalRequests < 100 {
        return false // æ ·æœ¬ä¸è¶³ï¼Œä¸è°ƒæ•´
    }

    errorRate := metrics.ErrorRate
    if errorRate > 0.8 {
        return true // é”™è¯¯ç‡è¿‡é«˜ï¼Œéœ€è¦è°ƒæ•´
    }

    avgLatency := acb.calculateAverageLatency(metrics.LatencySamples)
    if avgLatency > acb.config.LatencyThreshold*2 {
        return true // å»¶è¿Ÿè¿‡é«˜ï¼Œéœ€è¦è°ƒæ•´
    }

    return false
}

func (acb *AdaptiveCircuitBreaker) adaptThreshold(service string, metrics *HealthMetrics) {
    state := acb.states[service]
    if state == nil {
        return
    }

    // é™ä½æœ€å¤§å¤±è´¥æ¬¡æ•°é˜ˆå€¼ï¼Œé¿å…é¢‘ç¹ç†”æ–­
    newMaxFailures := max(acb.config.MaxFailures/2, 2)
    log.Printf("è‡ªé€‚åº”è°ƒæ•´ç†”æ–­å™¨é˜ˆå€¼: %s -> %d", service, newMaxFailures)

    // æ›´æ–°é…ç½®
    acb.config.MaxFailures = newMaxFailures
    state.Failures = 0 // é‡ç½®å¤±è´¥æ¬¡æ•°
}

func (acb *AdaptiveCircuitBreaker) GetState(service string) *BreakerState {
    acb.mu.RLock()
    defer acb.mu.RUnlock()

    if state, exists := acb.states[service]; exists {
        // æ£€æŸ¥æ˜¯å¦éœ€è¦ä»å¼€å¯çŠ¶æ€è½¬ä¸ºåŠå¼€
        if state.State == "open" {
            recoveryStrategy := acb.recoveryStrategies[service]
            if recoveryStrategy == nil {
                recoveryStrategy = ExponentialBackoffRecovery{}
            }

            if recoveryStrategy.ShouldRecover(state, acb.config.Timeout) {
                acb.mu.RUnlock()
                acb.mu.Lock()
                state.State = "half-open"
                state.RecoveryCount = 0
                log.Printf("ç†”æ–­å™¨è¿›å…¥åŠå¼€çŠ¶æ€ for service %s", service)
                acb.mu.Unlock()
                acb.mu.RLock()
            }
        }
        return state
    }

    return acb.getOrCreateState(service)
}

func (acb *AdaptiveCircuitBreaker) updateLatencyPercentile(service string) {
    metrics := acb.healthMetrics[service]
    if metrics == nil || len(metrics.LatencySamples) == 0 {
        return
    }

    state := acb.states[service]
    if state == nil {
        return
    }

    // è®¡ç®—P95å»¶è¿Ÿ
    sortedLatencies := make([]time.Duration, len(metrics.LatencySamples))
    copy(sortedLatencies, metrics.LatencySamples)
    sort.Slice(sortedLatencies, func(i, j int) bool {
        return sortedLatencies[i] < sortedLatencies[j]
    })

    index := int(float64(len(sortedLatencies)) * 0.95)
    if index >= len(sortedLatencies) {
        index = len(sortedLatencies) - 1
    }

    state.LatencyPercentile = sortedLatencies[index]
}

func (acb *AdaptiveCircuitBreaker) calculateAverageLatency(samples []time.Duration) time.Duration {
    if len(samples) == 0 {
        return 0
    }

    var total time.Duration
    for _, sample := range samples {
        total += sample
    }

    return total / time.Duration(len(samples))
}

func (acb *AdaptiveCircuitBreaker) getOrCreateState(service string) *BreakerState {
    if state, exists := acb.states[service]; exists {
        return state
    }

    state := &BreakerState{
        State:    "closed",
        Failures: 0,
    }
    acb.states[service] = state
    return state
}

func (acb *AdaptiveCircuitBreaker) getOrCreateMetrics(service string) *HealthMetrics {
    if metrics, exists := acb.healthMetrics[service]; exists {
        return metrics
    }

    metrics := &HealthMetrics{
        LastUpdated: time.Now(),
    }
    acb.healthMetrics[service] = metrics
    return metrics
}

// æ¢å¤ç­–ç•¥æ¥å£
type RecoveryStrategy interface {
    ShouldRecover(state *BreakerState, timeout time.Duration) bool
    GetDelay() time.Duration
}

// æŒ‡æ•°é€€é¿æ¢å¤ç­–ç•¥
type ExponentialBackoffRecovery struct{}

func (ebr ExponentialBackoffRecovery) ShouldRecover(state *BreakerState, timeout time.Duration) bool {
    elapsed := time.Since(state.LastFailure)
    delay := ebr.GetDelay(state)

    return elapsed >= delay
}

func (ebr ExponentialBackoffRecovery) GetDelay() time.Duration {
    return time.Minute * 2 // å›ºå®šå»¶è¿Ÿ
}

func (ebr ExponentialBackoffRecovery) GetDelay(state *BreakerState) time.Duration {
    baseDelay := time.Second * 30
    multiplier := math.Pow(2, float64(state.Failures))
    return baseDelay * time.Duration(multiplier)
}

// çº¿æ€§é€€é¿æ¢å¤ç­–ç•¥
type LinearBackoffRecovery struct{}

func (lbr LinearBackoffRecovery) ShouldRecover(state *BreakerState, timeout time.Duration) bool {
    elapsed := time.Since(state.LastFailure)
    delay := lbr.GetDelay(state)

    return elapsed >= delay
}

func (lbr LinearBackoffRecovery) GetDelay(state *BreakerState) time.Duration {
    baseDelay := time.Second * 30
    increment := time.Second * 10
    return baseDelay + time.Duration(state.Failures)*increment
}
```

### å®¢æˆ·ç«¯é›†æˆç¤ºä¾‹

#### **æ™ºèƒ½å®¢æˆ·ç«¯å®ç°**
```go
type SmartClient struct {
    service   micro.Service
    selector  selector.Selector
    latencyTracker *LatencyTracker
    circuitBreaker *CircuitBreaker
    connectionTracker *ConnectionTracker
}

func NewSmartClient(service micro.Service) *SmartClient {
    // åˆ›å»ºå¤åˆè´Ÿè½½å‡è¡¡å™¨
    primaryBalancer := NewLatencyBasedBalancer()
    secondaryBalancer := NewRoundRobinBalancer()

    // åˆ›å»ºé€‰æ‹©å™¨
    selector := selector.NewSelector(
        selector.SetBalancer(primaryBalancer),
        selector.SetFallback(secondaryBalancer),
    )

    return &SmartClient{
        service:          service,
        selector:         selector,
        latencyTracker:    NewLatencyTracker(10),
        circuitBreaker:   NewCircuitBreaker(5, time.Minute),
        connectionTracker: NewConnectionTracker(),
    }
}

func (sc *SmartClient) Call(ctx context.Context, service, method string, req, rsp interface{}) error {
    startTime := time.Now()

    // è·å–æœåŠ¡èŠ‚ç‚¹
    next, err := sc.selector.Select(service)
    if err != nil {
        return fmt.Errorf("failed to select service node: %w", err)
    }

    node, err := next()
    if err != nil {
        return fmt.Errorf("failed to get service node: %w", err)
    }

    // è®°å½•è¿æ¥
    sc.connectionTracker.Increment(service, node.Id)
    defer sc.connectionTracker.Decrement(service, node.Id)

    // æ£€æŸ¥ç†”æ–­å™¨çŠ¶æ€
    state := sc.circuitBreaker.GetState(service)
    if state.State == "open" {
        return fmt.Errorf("service %s circuit breaker is open", service)
    }

    // æ‰§è¡Œè°ƒç”¨
    client := sc.service.Client()
    err = client.Call(ctx, service, method, req, rsp)

    // è®°å½•å»¶è¿Ÿå’ŒæˆåŠŸç‡
    latency := time.Since(startTime)
    sc.latencyTracker.Record(service, node.Id, latency)

    if err != nil {
        sc.circuitBreaker.RecordFailure(service)
    } else {
        sc.circuitBreaker.RecordSuccess(service)
    }

    return err
}
```

è¿™äº›è´Ÿè½½å‡è¡¡ç­–ç•¥æä¾›äº†çµæ´»çš„æœåŠ¡è°ƒç”¨åˆ†å‘æœºåˆ¶ï¼Œå¯ä»¥æ ¹æ®ä¸åŒçš„ä¸šåŠ¡åœºæ™¯å’Œæ€§èƒ½éœ€æ±‚é€‰æ‹©åˆé€‚çš„ç­–ç•¥ï¼Œç¡®ä¿ç³»ç»Ÿçš„é«˜å¯ç”¨æ€§å’Œæ€§èƒ½ä¼˜åŒ–ã€‚

## ğŸ¯ ç›´æ¥è¿æ¥æ¨¡å¼ï¼šç»•è¿‡æœåŠ¡å‘ç°çš„IP+Portç›´è¿

### åœºæ™¯è¯´æ˜

åœ¨æŸäº›ç‰¹æ®Šåœºæ™¯ä¸‹ï¼Œæˆ‘ä»¬å¯èƒ½å¸Œæœ›ç»•è¿‡æœåŠ¡å‘ç°æœºåˆ¶ï¼Œç›´æ¥é€šè¿‡ IP:Port æ–¹å¼è¿æ¥åˆ°æœåŠ¡å®ä¾‹ã€‚è¿™ç§æ¨¡å¼é€‚ç”¨äºï¼š

- **å¼€å‘è°ƒè¯•**ï¼šå¿«é€Ÿè¿æ¥åˆ°ç‰¹å®šæœåŠ¡å®ä¾‹è¿›è¡Œè°ƒè¯•
- **æµ‹è¯•ç¯å¢ƒ**ï¼šåœ¨æµ‹è¯•ç¯å¢ƒä¸­éœ€è¦ç²¾ç¡®æ§åˆ¶æœåŠ¡è¿æ¥
- **å°å‹åº”ç”¨**ï¼šä¸éœ€è¦å¤æ‚çš„æœåŠ¡å‘ç°æœºåˆ¶
- **æ··åˆéƒ¨ç½²**ï¼šéƒ¨åˆ†æœåŠ¡ä½¿ç”¨æœåŠ¡å‘ç°ï¼Œéƒ¨åˆ†æœåŠ¡ç›´æ¥è¿æ¥

### å®ç°æ–¹æ¡ˆ

#### **1. ç›´æ¥ä½¿ç”¨ RPC å®¢æˆ·ç«¯**
```go
package main

import (
    "context"
    "log"

    "google.golang.org/grpc"
    "google.golang.org/grpc/credentials/insecure"

    pb "github.com/yourproject/user/proto"
)

func main() {
    // ç›´æ¥åˆ›å»º gRPC è¿æ¥
    conn, err := grpc.Dial("192.168.1.100:8080", grpc.WithInsecure())
    if err != nil {
        log.Fatalf("æ— æ³•è¿æ¥åˆ°æœåŠ¡: %v", err)
    }
    defer conn.Close()

    // åˆ›å»ºå®¢æˆ·ç«¯
    client := pb.NewUserServiceClient(conn)

    // ç›´æ¥è°ƒç”¨æœåŠ¡
    ctx := context.Background()
    response, err := client.GetUser(ctx, &pb.GetUserRequest{
        UserId: "12345",
    })

    if err != nil {
        log.Printf("è°ƒç”¨æœåŠ¡å¤±è´¥: %v", err)
        return
    }

    log.Printf("ç”¨æˆ·ä¿¡æ¯: %+v", response.User)
}
```

#### **2. è‡ªå®šä¹‰æœåŠ¡æ³¨å†Œå™¨**
```go
package main

import (
    "context"
    "log"
    "sync"

    "github.com/go-micro/go-micro/v4"
    "github.com/go-micro/go-micro/v4/client"
    "github.com/go-micro/go-micro/v4/registry"
    "github.com/go-micro/go-micro/v4/selector"
)

type DirectRegistry struct {
    services map[string][]*registry.Service
    mu       sync.RWMutex
}

func NewDirectRegistry() *DirectRegistry {
    return &DirectRegistry{
        services: make(map[string][]*registry.Service),
    }
}

// æ·»åŠ é™æ€æœåŠ¡
func (dr *DirectRegistry) AddService(name, address string, port int) {
    dr.mu.Lock()
    defer dr.mu.Unlock()

    node := &registry.Node{
        Id:      name + "-static",
        Address: address,
        Port:    port,
    }

    service := &registry.Service{
        Name:  name,
        Nodes: []*registry.Node{node},
    }

    dr.services[name] = append(dr.services[name], service)
    log.Printf("æ·»åŠ é™æ€æœåŠ¡: %s -> %s:%d", name, address, port)
}

// å®ç°æ³¨å†Œä¸­å¿ƒæ¥å£
func (dr *DirectRegistry) GetService(name string) ([]*registry.Service, error) {
    dr.mu.RLock()
    defer dr.mu.RUnlock()

    services, exists := dr.services[name]
    if !exists {
        return nil, registry.ErrNotFound
    }

    return services, nil
}

func (dr *DirectRegistry) Register(service *registry.Service, opts ...registry.RegisterOption) error {
    dr.mu.Lock()
    defer dr.mu.Unlock()

    name := service.Name
    dr.services[name] = append(dr.services[name], service)
    log.Printf("æ³¨å†ŒæœåŠ¡: %s", name)
    return nil
}

func (dr *DirectRegistry) Deregister(service *registry.Service, opts ...registry.DeregisterOption) error {
    dr.mu.Lock()
    defer dr.mu.Unlock()

    name := service.Name
    if _, exists := dr.services[name]; exists {
        delete(dr.services, name)
        log.Printf("æ³¨é”€æœåŠ¡: %s", name)
    }
    return nil
}

func (dr *DirectRegistry) ListServices(opts ...registry.ListOption) ([]*registry.Service, error) {
    dr.mu.RLock()
    defer dr.mu.RUnlock()

    var allServices []*registry.Service
    for _, services := range dr.services {
        allServices = append(allServices, services...)
    }

    return allServices, nil
}

func (dr *DirectRegistry) Watch(opts ...registry.WatchOption) (registry.Watcher, error) {
    // è¿”å›ç©ºçš„ watcherï¼Œä¸æ”¯æŒç›‘å¬
    return &EmptyWatcher{}, nil
}

func (dr *DirectRegistry) String() string {
    return "direct-registry"
}

type EmptyWatcher struct{}

func (ew *EmptyWatcher) Next() (*registry.Result, error) {
    return nil, registry.ErrWatcherStopped
}

func (ew *EmptyWatcher) Stop() {
    // ç©ºå®ç°
}

// ä½¿ç”¨ç¤ºä¾‹
func main() {
    // åˆ›å»ºç›´æ¥è¿æ¥çš„æ³¨å†Œå™¨
    directReg := NewDirectRegistry()

    // æ·»åŠ é™æ€æœåŠ¡é…ç½®
    services := map[string]string{
        "user-service":     "192.168.1.100:8080",
        "order-service":    "192.168.1.101:8081",
        "payment-service": "192.168.1.102:8082",
    }

    for name, addr := range services {
        address, port := parseAddress(addr)
        directReg.AddService(name, address, port)
    }

    // åˆ›å»ºæœåŠ¡ï¼Œä½¿ç”¨ç›´æ¥æ³¨å†Œå™¨
    service := micro.NewService(
        micro.Name("client-service"),
        micro.Registry(directReg),
        micro.Selector(selector.NewSelector()),
    )

    service.Init()

    // è¿›è¡ŒæœåŠ¡è°ƒç”¨
    client := service.Client()

    // è°ƒç”¨ç”¨æˆ·æœåŠ¡
    userResponse := struct {
        Name  string `json:"name"`
        Email string `json:"email"`
    }{}

    err := client.Call(context.Background(),
        "user-service",
        "GetUser",
        map[string]interface{}{"user_id": "123"},
        &userResponse,
    )

    if err != nil {
        log.Printf("è°ƒç”¨ç”¨æˆ·æœåŠ¡å¤±è´¥: %v", err)
        return
    }

    log.Printf("ç”¨æˆ·ä¿¡æ¯: %+v", userResponse)
}

func parseAddress(addr string) (string, int) {
    // ç®€å•çš„åœ°å€è§£æ
    var host string
    var port int

    n, err := fmt.Sscanf(addr, "%s:%d", &host, &port)
    if err != nil || n != 2 {
        return "localhost", 8080
    }

    return host, port
}
```

#### **3. è‡ªå®šä¹‰å®¢æˆ·ç«¯åŒ…è£…å™¨**
```go
package main

import (
    "context"
    "log"
    "strings"

    "github.com/go-micro/go-micro/v4"
    "github.com/go-micro/go-micro/v4/client"
    "github.com/go-micro/go-micro/v4/selector"
)

type DirectClientWrapper struct {
    client.Client
    endpoints map[string]string // service name -> address
}

func NewDirectClientWrapper(endpoints map[string]string) *DirectClientWrapper {
    return &DirectClientWrapper{
        endpoints: endpoints,
    }
}

func (dcw *DirectClientWrapper) Call(ctx context.Context, req client.Request, opts ...client.CallOption) error {
    // æ£€æŸ¥æ˜¯å¦æœ‰ç›´æ¥é…ç½®çš„ç«¯ç‚¹
    if address, exists := dcw.endpoints[req.Service()]; exists {
        log.Printf("ä½¿ç”¨ç›´æ¥è¿æ¥è°ƒç”¨æœåŠ¡ %s -> %s", req.Service(), address)

        // æ›¿æ¢æœåŠ¡åç§°ä¸ºå…·ä½“åœ°å€
        originalService := req.Service()
        modifiedReq := &DirectRequest{
            Request: req,
            service: address,
        }

        return dcw.Client.Call(ctx, modifiedReq, opts...)
    }

    // å¦åˆ™ä½¿ç”¨åŸæœ‰çš„å®¢æˆ·ç«¯é€»è¾‘
    return dcw.Client.Call(ctx, req, opts...)
}

type DirectRequest struct {
    client.Request
    service string
}

func (dr *DirectRequest) Service() string {
    return dr.service
}

// ä½¿ç”¨ç¤ºä¾‹
func main() {
    // é…ç½®ç›´æ¥è¿æ¥çš„ç«¯ç‚¹
    endpoints := map[string]string{
        "user-service":     "192.168.1.100:8080",
        "order-service":    "192.168.1.101:8081",
        "payment-service": "192.168.1.102:8082",
    }

    // åˆ›å»ºæœåŠ¡
    service := micro.NewService(
        micro.Name("client-service"),
    )

    // åŒ…è£…å®¢æˆ·ç«¯
    wrappedClient := NewDirectClientWrapper(endpoints)
    service.Client().Init(client.WithWrapper(wrappedClient))

    service.Init()

    // æµ‹è¯•è°ƒç”¨
    client := service.Client()

    // è°ƒç”¨ç”¨æˆ·æœåŠ¡ï¼ˆå°†ä½¿ç”¨ç›´æ¥è¿æ¥ï¼‰
    userResponse := struct {
        Name  string `json:"name"`
        Email string `json:"email"`
    }{}

    err := client.Call(context.Background(),
        "user-service",
        "GetUser",
        map[string]interface{}{"user_id": "123"},
        &userResponse,
    )

    if err != nil {
        log.Printf("è°ƒç”¨ç”¨æˆ·æœåŠ¡å¤±è´¥: %v", err)
        return
    }

    log.Printf("ç”¨æˆ·ä¿¡æ¯: %+v", userResponse)

    // è°ƒç”¨å…¶ä»–æœåŠ¡ï¼ˆå°†ä½¿ç”¨æœåŠ¡å‘ç°ï¼‰
    orderResponse := struct {
        OrderId string `json:"order_id"`
        Amount  int64  `json:"amount"`
    }{}

    err = client.Call(context.Background(),
        "inventory-service", // æ²¡æœ‰åœ¨endpointsä¸­é…ç½®
        "GetInventory",
        map[string]interface{}{"product_id": "456"},
        &orderResponse,
    )

    if err != nil {
        log.Printf("è°ƒç”¨åº“å­˜æœåŠ¡å¤±è´¥: %v", err)
        return
    }

    log.Printf("åº“å­˜ä¿¡æ¯: %+v", orderResponse)
}
```

#### **4. é…ç½®é©±åŠ¨çš„è¿æ¥æ–¹å¼**
```go
package main

import (
    "context"
    "encoding/json"
    "log"
    "os"

    "github.com/go-micro/go-micro/v4"
)

type ServiceConfig struct {
    DirectMode  bool              `json:"direct_mode"`
    Services   map[string]string `json:"services"`
    Registry   struct {
        Type    string   `json:"type"`
        Address string   `json:"address"`
    } `json:"registry"`
}

func loadConfig(configPath string) (*ServiceConfig, error) {
    data, err := os.ReadFile(configPath)
    if err != nil {
        return nil, err
    }

    var config ServiceConfig
    if err := json.Unmarshal(data, &config); err != nil {
        return nil, err
    }

    return &config, nil
}

func createService(config *ServiceConfig) micro.Service {
    if config.DirectMode {
        return createDirectService(config)
    }
    return createRegistryService(config)
}

func createDirectService(config *ServiceConfig) micro.Service {
    log.Println("ä½¿ç”¨ç›´æ¥è¿æ¥æ¨¡å¼")

    // åˆ›å»ºç›´æ¥æ³¨å†Œå™¨
    directReg := NewDirectRegistry()

    for name, address := range config.Services {
        host, port := parseAddress(address)
        directReg.AddService(name, host, port)
    }

    return micro.NewService(
        micro.Name("client-service"),
        micro.Registry(directReg),
    )
}

func createRegistryService(config *ServiceConfig) micro.Service {
    log.Println("ä½¿ç”¨æœåŠ¡å‘ç°æ¨¡å¼")

    var opts []micro.Option
    switch config.Registry.Type {
    case "consul":
        opts = append(opts, micro.Registry(consul.NewRegistry(
            registry.Addrs(config.Registry.Address),
        )))
    case "etcd":
        opts = append(opts, micro.Registry(etcd.NewRegistry(
            registry.Addrs(config.Registry.Address),
        )))
    default:
        log.Printf("æœªçŸ¥çš„æ³¨å†Œä¸­å¿ƒç±»å‹: %s, ä½¿ç”¨é»˜è®¤", config.Registry.Type)
    }

    return micro.NewService(
        micro.Name("client-service"),
        opts...,
    )
}

func main() {
    // åŠ è½½é…ç½®
    config, err := loadConfig("service-config.json")
    if err != nil {
        log.Fatalf("åŠ è½½é…ç½®å¤±è´¥: %v", err)
    }

    // æ ¹æ®é…ç½®åˆ›å»ºæœåŠ¡
    service := createService(config)
    service.Init()

    // æœåŠ¡è°ƒç”¨é€»è¾‘
    client := service.Client()

    // è°ƒç”¨ç”¨æˆ·æœåŠ¡
    userResponse := struct {
        Name  string `json:"name"`
        Email string `json:"email"`
    }{}

    err = client.Call(context.Background(),
        "user-service",
        "GetUser",
        map[string]interface{}{"user_id": "123"},
        &userResponse,
    )

    if err != nil {
        log.Printf("è°ƒç”¨æœåŠ¡å¤±è´¥: %v", err)
        return
    }

    log.Printf("ç”¨æˆ·ä¿¡æ¯: %+v", userResponse)
}

// é…ç½®æ–‡ä»¶ç¤ºä¾‹ (service-config.json)
/*
{
    "direct_mode": true,
    "services": {
        "user-service": "192.168.1.100:8080",
        "order-service": "192.168.1.101:8081",
        "payment-service": "192.168.1.102:8082"
    },
    "registry": {
        "type": "consul",
        "address": "127.0.0.1:8500"
    }
}
*/
```

### é«˜çº§åº”ç”¨åœºæ™¯

#### **ç”Ÿäº§çº§æ··åˆè¿æ¥ç®¡ç†å™¨**
```go
type ProductionHybridConnectionManager struct {
    directEndpoints      map[string]*DirectEndpoint
    registryClient     client.Client
    selector          selector.Selector
    healthMonitor      *EndpointHealthMonitor
    failoverManager   *FailoverManager
    metrics           *ConnectionMetrics
    config            *HybridConnectionConfig
    mu                sync.RWMutex
}

type DirectEndpoint struct {
    Address           string            `json:"address"`
    Client            client.Client     `json:"-"`
    Health            *EndpointHealth  `json:"health"`
    ActiveConnections  int              `json:"active_connections"`
    TotalConnections   int64            `json:"total_connections"`
    Latency           time.Duration    `json:"latency"`
    ErrorRate         float64          `json:"error_rate"`
    Metadata          map[string]string `json:"metadata"`
}

type EndpointHealth struct {
    Status           string    `json:"status"` // "healthy", "degraded", "unhealthy"
    LastCheck        time.Time `json:"last_check"`
    ConsecutiveFail   int       `json:"consecutive_fail"`
    RecoveryCount     int       `json:"recovery_count"`
    Uptime           time.Duration `json:"uptime"`
}

type HybridConnectionConfig struct {
    DirectMode           bool              `json:"direct_mode"`
    RegistryFallback    bool              `json:"registry_fallback"`
    HealthCheckInterval time.Duration     `json:"health_check_interval"`
    FailoverTimeout    time.Duration     `json:"failover_timeout"`
    MaxRetries          int               `json:"max_retries"`
    ConnectionPoolSize  int               `json:"connection_pool_size"`
    CircuitBreaker      bool              `json:"circuit_breaker"`
}

type FailoverManager struct {
    strategies        map[string]FailoverStrategy
    currentStrategy   string
    failoverHistory   []FailoverEvent
    mu                sync.RWMutex
}

type FailoverStrategy struct {
    Name              string                 `json:"name"`
    Priority          int                    `json:"priority"`
    Condition         func(*EndpointHealth) bool `json:"-"`
    Action           func(string) error     `json:"-"`
    Rollback         func(string) error     `json:"-"`
}

type FailoverEvent struct {
    Timestamp       time.Time `json:"timestamp"`
    ServiceName    string    `json:"service_name"`
    FromMode       string    `json:"from_mode"`  // "direct", "registry"
    ToMode         string    `json:"to_mode"`
    Reason         string    `json:"reason"`
    Success        bool      `json:"success"`
}

func NewProductionHybridConnectionManager(service micro.Service, config *HybridConnectionConfig) *ProductionHybridConnectionManager {
    return &ProductionHybridConnectionManager{
        directEndpoints:     make(map[string]*DirectEndpoint),
        registryClient:    service.Client(),
        selector:          service.Options().Selector,
        healthMonitor:      NewEndpointHealthMonitor(config.HealthCheckInterval),
        failoverManager:   NewFailoverManager(),
        metrics:           NewConnectionMetrics(),
        config:            config,
    }
}

func (phcm *ProductionHybridConnectionManager) AddDirectEndpoint(serviceName, address string, metadata map[string]string) error {
    phcm.mu.Lock()
    defer phcm.mu.Unlock()

    // åˆ›å»ºè¿æ¥æ± 
    connectionPool := NewConnectionPool(phcm.config.ConnectionPoolSize)

    // åˆ›å»ºä¸“ç”¨å®¢æˆ·ç«¯
    directClient := client.NewClient(
        client.Selector(selector.NewSelector(
            selector.SetBalancer(&SmartDirectBalancer{
                Address:       address,
                ConnectionPool: connectionPool,
                HealthMonitor:  phcm.healthMonitor,
            }),
        )),
    )

    endpoint := &DirectEndpoint{
        Address:    address,
        Client:     directClient,
        Metadata:   metadata,
        Health: &EndpointHealth{
            Status:     "healthy",
            LastCheck:  time.Now(),
        },
    }

    phcm.directEndpoints[serviceName] = endpoint
    phcm.metrics.RegisterEndpoint(serviceName, "direct")

    // å¯åŠ¨å¥åº·ç›‘æ§
    phcm.healthMonitor.RegisterEndpoint(serviceName, address)

    log.Printf("æ·»åŠ ç›´æ¥ç«¯ç‚¹: %s -> %s (å…ƒæ•°æ®: %+v)", serviceName, address, metadata)
    return nil
}

func (phcm *ProductionHybridConnectionManager) Call(ctx context.Context, req client.Request, opts ...client.CallOption) error {
    serviceName := req.Service()
    startTime := time.Now()

    // é€‰æ‹©è¿æ¥ç­–ç•¥
    strategy := phcm.selectConnectionStrategy(serviceName)

    var err error
    var mode string

    switch strategy {
    case "direct":
        mode = "direct"
        err = phcm.callDirectEndpoint(ctx, serviceName, req, opts...)
    case "registry":
        mode = "registry"
        err = phcm.callRegistryEndpoint(ctx, serviceName, req, opts...)
    case "failover":
        mode = "failover"
        err = phcm.callWithFailover(ctx, serviceName, req, opts...)
    default:
        err = fmt.Errorf("æœªçŸ¥çš„è¿æ¥ç­–ç•¥: %s", strategy)
    }

    // è®°å½•è°ƒç”¨æŒ‡æ ‡
    latency := time.Since(startTime)
    phcm.metrics.RecordCall(serviceName, mode, err == nil, latency)

    return err
}

func (phcm *ProductionHybridConnectionManager) selectConnectionStrategy(serviceName string) string {
    phcm.mu.RLock()
    defer phcm.mu.RUnlock()

    // æ£€æŸ¥ç›´æ¥ç«¯ç‚¹æ˜¯å¦å¯ç”¨
    if endpoint, exists := phcm.directEndpoints[serviceName]; exists {
        health := phcm.healthMonitor.GetEndpointHealth(serviceName, endpoint.Address)

        if health.Status == "healthy" {
            if phcm.config.DirectMode {
                return "direct"
            }
        } else if health.Status == "degraded" && phcm.config.RegistryFallback {
            return "registry" // é™çº§åˆ°æ³¨å†Œä¸­å¿ƒ
        }
    }

    // æ£€æŸ¥æ˜¯å¦éœ€è¦æ•…éšœè½¬ç§»
    if phcm.failoverManager.ShouldFailover(serviceName) {
        return "failover"
    }

    // é»˜è®¤ä½¿ç”¨æ³¨å†Œä¸­å¿ƒ
    return "registry"
}

func (phcm *ProductionHybridConnectionManager) callDirectEndpoint(ctx context.Context, serviceName string, req client.Request, opts ...client.CallOption) error {
    phcm.mu.RLock()
    endpoint, exists := phcm.directEndpoints[serviceName]
    phcm.mu.RUnlock()

    if !exists {
        return fmt.Errorf("ç›´æ¥ç«¯ç‚¹ä¸å­˜åœ¨: %s", serviceName)
    }

    // æ£€æŸ¥ç«¯ç‚¹å¥åº·çŠ¶æ€
    health := phcm.healthMonitor.GetEndpointHealth(serviceName, endpoint.Address)
    if health.Status != "healthy" {
        return fmt.Errorf("ç›´æ¥ç«¯ç‚¹ä¸å¥åº·: %s (çŠ¶æ€: %s)", serviceName, health.Status)
    }

    // æ‰§è¡Œè°ƒç”¨
    endpoint.ActiveConnections++
    endpoint.TotalConnections++

    err := endpoint.Client.Call(ctx, req, opts...)

    endpoint.ActiveConnections--

    // æ›´æ–°å¥åº·çŠ¶æ€
    if err != nil {
        phcm.healthMonitor.RecordFailure(serviceName, endpoint.Address, err)
        endpoint.ErrorRate = (endpoint.ErrorRate*float64(endpoint.TotalConnections-1) + 1.0) / float64(endpoint.TotalConnections)
    } else {
        phcm.healthMonitor.RecordSuccess(serviceName, endpoint.Address)
        endpoint.ErrorRate = endpoint.ErrorRate * float64(endpoint.TotalConnections-1) / float64(endpoint.TotalConnections)
    }

    return err
}

func (phcm *ProductionHybridConnectionManager) callRegistryEndpoint(ctx context.Context, serviceName string, req client.Request, opts ...client.CallOption) error {
    log.Printf("é€šè¿‡æ³¨å†Œä¸­å¿ƒè°ƒç”¨æœåŠ¡: %s", serviceName)
    err := phcm.registryClient.Call(ctx, req, opts...)

    if err != nil {
        // è®°å½•æ³¨å†Œä¸­å¿ƒè°ƒç”¨å¤±è´¥
        phcm.metrics.RecordRegistryFailure(serviceName, err)

        // å¦‚æœé…ç½®äº†æ•…éšœè½¬ç§»ï¼Œå°è¯•ç›´æ¥ç«¯ç‚¹
        if phcm.config.RegistryFallback {
            if endpoint, exists := phcm.directEndpoints[serviceName]; exists {
                log.Printf("æ³¨å†Œä¸­å¿ƒè°ƒç”¨å¤±è´¥ï¼Œå°è¯•ç›´æ¥ç«¯ç‚¹: %s", serviceName)
                return phcm.callDirectEndpoint(ctx, serviceName, req, opts...)
            }
        }
    }

    return err
}

func (phcm *ProductionHybridConnectionManager) callWithFailover(ctx context.Context, serviceName string, req client.Request, opts ...client.CallOption) error {
    // è·å–æ•…éšœè½¬ç§»ç­–ç•¥
    strategy := phcm.failoverManager.GetCurrentStrategy(serviceName)
    if strategy == nil {
        return fmt.Errorf("æ— å¯ç”¨çš„æ•…éšœè½¬ç§»ç­–ç•¥: %s", serviceName)
    }

    log.Printf("æ‰§è¡Œæ•…éšœè½¬ç§»ç­–ç•¥: %s for service %s", strategy.Name, serviceName)

    // æ‰§è¡Œæ•…éšœè½¬ç§»æ“ä½œ
    err := strategy.Action(serviceName)
    event := FailoverEvent{
        Timestamp:    time.Now(),
        ServiceName: serviceName,
        FromMode:     "unknown",
        ToMode:       "failover",
        Reason:       "æ•…éšœè½¬ç§»æ¿€æ´»",
        Success:      err == nil,
    }

    phcm.failoverManager.RecordEvent(event)

    if err != nil {
        return fmt.Errorf("æ•…éšœè½¬ç§»å¤±è´¥: %w", err)
    }

    // é‡è¯•è°ƒç”¨
    return phcm.Call(ctx, req, opts...)
}

type SmartDirectBalancer struct {
    Address         string
    ConnectionPool *ConnectionPool
    HealthMonitor  *EndpointHealthMonitor
}

func (sdb *SmartDirectBalancer) Select(service string, nodes []*registry.Node) (selector.Next, error) {
    // ä»è¿æ¥æ± è·å–è¿æ¥
    conn, err := sdb.ConnectionPool.GetConnection(sdb.Address)
    if err != nil {
        return nil, fmt.Errorf("è·å–è¿æ¥å¤±è´¥: %w", err)
    }

    host, port := parseAddress(sdb.Address)
    return func() (*registry.Node, error) {
        return &registry.Node{
            Id:      fmt.Sprintf("%s-%d", service, rand.Intn(10000)),
            Address: host,
            Port:    port,
            Metadata: map[string]string{
                "connection_id": conn.ID(),
                "created_at":    time.Now().Format(time.RFC3339),
            },
        }, nil
    }, nil
}

func (sdb *SmartDirectBalancer) String() string {
    return "smart-direct-balancer"
}

type ConnectionPool struct {
    connections chan *PooledConnection
    maxSize     int
    currentSize  int
    mu          sync.Mutex
}

type PooledConnection struct {
    ID         string
    Connection interface{}
    Created    time.Time
    LastUsed   time.Time
    Healthy    bool
}

func NewConnectionPool(maxSize int) *ConnectionPool {
    return &ConnectionPool{
        connections: make(chan *PooledConnection, maxSize),
        maxSize:     maxSize,
    }
}

func (cp *ConnectionPool) GetConnection(address string) (*PooledConnection, error) {
    select {
    case conn := <-cp.connections:
        cp.mu.Lock()
        conn.LastUsed = time.Now()
        cp.currentSize--
        cp.mu.Unlock()
        return conn, nil
    default:
        // è¿æ¥æ± ä¸ºç©ºï¼Œåˆ›å»ºæ–°è¿æ¥
        return cp.createNewConnection(address)
    }
}

func (cp *ConnectionPool) ReturnConnection(conn *PooledConnection) {
    if !conn.Healthy {
        return // ä¸å¥åº·çš„è¿æ¥ä¸è¿”å›åˆ°æ± ä¸­
    }

    cp.mu.Lock()
    defer cp.mu.Unlock()

    if cp.currentSize < cp.maxSize {
        conn.LastUsed = time.Now()
        cp.connections <- conn
        cp.currentSize++
    }
}

func (cp *ConnectionPool) createNewConnection(address string) (*PooledConnection, error) {
    connID := fmt.Sprintf("conn-%d-%d", time.Now().UnixNano(), rand.Intn(10000))

    return &PooledConnection{
        ID:        connID,
        Connection: nil, // å®é™…è¿æ¥æ ¹æ®åè®®ç±»å‹åˆ›å»º
        Created:   time.Now(),
        LastUsed:  time.Now(),
        Healthy:   true,
    }, nil
}

func NewFailoverManager() *FailoverManager {
    strategies := map[string]FailoverStrategy{
        "retry": {
            Name:     "é‡è¯•ç­–ç•¥",
            Priority: 1,
            Condition: func(health *EndpointHealth) bool {
                return health.ConsecutiveFail < 3
            },
            Action: func(serviceName string) error {
                log.Printf("æ‰§è¡Œé‡è¯•ç­–ç•¥ for service %s", serviceName)
                return nil // é‡è¯•é€»è¾‘ç”±è°ƒç”¨è€…å¤„ç†
            },
            Rollback: func(serviceName string) error {
                return nil
            },
        },
        "direct_only": {
            Name:     "ä»…ç›´æ¥æ¨¡å¼",
            Priority: 2,
            Condition: func(health *EndpointHealth) bool {
                return health.Status == "healthy"
            },
            Action: func(serviceName string) error {
                log.Printf("åˆ‡æ¢åˆ°ä»…ç›´æ¥æ¨¡å¼ for service %s", serviceName)
                return nil
            },
            Rollback: func(serviceName string) error {
                return nil
            },
        },
        "cache_fallback": {
            Name:     "ç¼“å­˜å›é€€",
            Priority: 3,
            Condition: func(health *EndpointHealth) bool {
                return health.ConsecutiveFail >= 3
            },
            Action: func(serviceName string) error {
                log.Printf("åˆ‡æ¢åˆ°ç¼“å­˜å›é€€æ¨¡å¼ for service %s", serviceName)
                return nil
            },
            Rollback: func(serviceName string) error {
                return nil
            },
        },
    }

    return &FailoverManager{
        strategies:      strategies,
        currentStrategy: "retry",
        failoverHistory: make([]FailoverEvent, 0),
    }
}
```

è¿™ç§ç›´æ¥è¿æ¥æ¨¡å¼æä¾›äº†çµæ´»çš„éƒ¨ç½²é€‰é¡¹ï¼Œè®©å¼€å‘è€…å¯ä»¥æ ¹æ®å®é™…éœ€æ±‚é€‰æ‹©æœ€é€‚åˆçš„æœåŠ¡è¿æ¥æ–¹å¼ã€‚ the command line interface for developing Go Micro projects.

## âš ï¸ è‡ªå®šä¹‰é”™è¯¯è¿”å›æœºåˆ¶

### é”™è¯¯å¤„ç†çš„é‡è¦æ€§

åœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­ï¼Œé”™è¯¯å¤„ç†ä¸ä»…å…³ç³»åˆ°ç³»ç»Ÿçš„ç¨³å®šæ€§ï¼Œè¿˜ç›´æ¥å½±å“ç”¨æˆ·ä½“éªŒå’Œé—®é¢˜æ’æŸ¥æ•ˆç‡ã€‚Go Micro æä¾›äº†å¼ºå¤§çš„è‡ªå®šä¹‰é”™è¯¯è¿”å›æœºåˆ¶ï¼Œè®©å¼€å‘è€…èƒ½å¤Ÿæ ¹æ®ä¸šåŠ¡éœ€æ±‚è®¾è®¡å’Œå®ç°ç»Ÿä¸€çš„é”™è¯¯å¤„ç†è§„èŒƒã€‚

### è‡ªå®šä¹‰é”™è¯¯ç±»å‹

#### **1. å®šä¹‰ä¸šåŠ¡é”™è¯¯ç **
```go
package errors

import (
    "fmt"
    "google.golang.org/grpc/codes"
    "google.golang.org/grpc/status"
)

// å®šä¹‰é”™è¯¯ç å¸¸é‡
const (
    ErrorCodeUserNotFound     = 10001
    ErrorCodeInvalidPassword   = 10002
    ErrorCodeUserAlreadyExists = 10003
    ErrorCodeInsufficientBalance = 10004
    ErrorCodeOrderNotFound     = 20001
    ErrorCodePaymentFailed     = 20002
    ErrorCodeInvalidOrderStatus = 20003
)

// é”™è¯¯ç æ˜ å°„
var errorCodeToGRPC = map[int32]codes.Code{
    ErrorCodeUserNotFound:      codes.NotFound,
    ErrorCodeInvalidPassword:   codes.InvalidArgument,
    ErrorCodeUserAlreadyExists: codes.AlreadyExists,
    ErrorCodeInsufficientBalance: codes.ResourceExhausted,
    ErrorCodeOrderNotFound:      codes.NotFound,
    ErrorCodePaymentFailed:      codes.Internal,
    ErrorCodeInvalidOrderStatus: codes.FailedPrecondition,
}

var errorCodeToMessage = map[int32]string{
    ErrorCodeUserNotFound:      "ç”¨æˆ·ä¸å­˜åœ¨",
    ErrorCodeInvalidPassword:   "å¯†ç æ— æ•ˆ",
    ErrorCodeUserAlreadyExists: "ç”¨æˆ·å·²å­˜åœ¨",
    ErrorCodeInsufficientBalance: "ä½™é¢ä¸è¶³",
    ErrorCodeOrderNotFound:      "è®¢å•ä¸å­˜åœ¨",
    ErrorCodePaymentFailed:      "æ”¯ä»˜å¤±è´¥",
    ErrorCodeInvalidOrderStatus: "è®¢å•çŠ¶æ€æ— æ•ˆ",
}

// ä¸šåŠ¡é”™è¯¯ç±»å‹
type BusinessError struct {
    Code        int32                  `json:"code"`
    Message     string                 `json:"message"`
    Details     string                 `json:"details,omitempty"`
    StackTrace  string                 `json:"stack_trace,omitempty"`
    Context     map[string]interface{} `json:"context,omitempty"`
    Timestamp   time.Time              `json:"timestamp"`
    RequestID   string                 `json:"request_id,omitempty"`
}

func (be *BusinessError) Error() string {
    return fmt.Sprintf("ä¸šåŠ¡é”™è¯¯ [%d]: %s", be.Code, be.Message)
}

func (be *BusinessError) GRPCStatus() *status.Status {
    grpcCode, exists := errorCodeToGRPC[be.Code]
    if !exists {
        grpcCode = codes.Unknown
    }

    return status.New(grpcCode, be.Message)
}

// é”™è¯¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨
type ErrorContext struct {
    RequestID   string
    UserID      string
    ServiceName string
    Method      string
    TraceID     string
    SpanID      string
    Metadata     map[string]interface{}
    Timestamp   time.Time
}

type ErrorContextManager struct {
    contextMap map[string]*ErrorContext
    mu         sync.RWMutex
}

func NewErrorContextManager() *ErrorContextManager {
    return &ErrorContextManager{
        contextMap: make(map[string]*ErrorContext),
    }
}

func (ecm *ErrorContextManager) SetContext(key string, ctx *ErrorContext) {
    ecm.mu.Lock()
    defer ecm.mu.Unlock()
    ecm.contextMap[key] = ctx
}

func (ecm *ErrorContextManager) GetContext(key string) *ErrorContext {
    ecm.mu.RLock()
    defer ecm.mu.RUnlock()
    return ecm.contextMap[key]
}

// åˆ›å»ºå¢å¼ºçš„ä¸šåŠ¡é”™è¯¯
func NewBusinessErrorWithContext(code int32, message string, ctx *ErrorContext, details ...string) *BusinessError {
    err := &BusinessError{
        Code:      code,
        Message:   message,
        Timestamp: time.Now(),
        Context:   make(map[string]interface{}),
    }

    if ctx != nil {
        err.RequestID = ctx.RequestID
        err.Context["user_id"] = ctx.UserID
        err.Context["service_name"] = ctx.ServiceName
        err.Context["method"] = ctx.Method
        err.Context["trace_id"] = ctx.TraceID
        err.Context["span_id"] = ctx.SpanID
        if ctx.Metadata != nil {
            for k, v := range ctx.Metadata {
                err.Context[k] = v
            }
        }
    }

    if len(details) > 0 {
        err.Details = details[0]
    }

    // æ·»åŠ å †æ ˆä¿¡æ¯
    err.StackTrace = captureStackTrace(3)

    return err
}

// åˆ›å»ºä¸šåŠ¡é”™è¯¯
func NewBusinessError(code int32, message string, details ...string) *BusinessError {
    return NewBusinessErrorWithContext(code, message, nil, details...)
}

// é¢„å®šä¹‰é”™è¯¯åˆ›å»ºå‡½æ•°
var (
    ErrUserNotFound = func(details ...string) error {
        ctx := getCurrentErrorContext()
        return NewBusinessErrorWithContext(ErrorCodeUserNotFound, errorCodeToMessage[ErrorCodeUserNotFound], ctx, details...)
    }

    ErrInvalidPassword = func(details ...string) error {
        ctx := getCurrentErrorContext()
        return NewBusinessErrorWithContext(ErrorCodeInvalidPassword, errorCodeToMessage[ErrorCodeInvalidPassword], ctx, details...)
    }

    ErrUserAlreadyExists = func(details ...string) error {
        ctx := getCurrentErrorContext()
        return NewBusinessErrorWithContext(ErrorCodeUserAlreadyExists, errorCodeToMessage[ErrorCodeUserAlreadyExists], ctx, details...)
    }

    ErrInsufficientBalance = func(details ...string) error {
        ctx := getCurrentErrorContext()
        return NewBusinessErrorWithContext(ErrorCodeInsufficientBalance, errorCodeToMessage[ErrorCodeInsufficientBalance], ctx, details...)
    }

    ErrOrderNotFound = func(details ...string) error {
        ctx := getCurrentErrorContext()
        return NewBusinessErrorWithContext(ErrorCodeOrderNotFound, errorCodeToMessage[ErrorCodeOrderNotFound], ctx, details...)
    }

    ErrPaymentFailed = func(details ...string) error {
        ctx := getCurrentErrorContext()
        return NewBusinessErrorWithContext(ErrorCodePaymentFailed, errorCodeToMessage[ErrorCodePaymentFailed], ctx, details...)
    }
)

// å…¨å±€é”™è¯¯ä¸Šä¸‹æ–‡ç®¡ç†
var globalErrorContextManager = NewErrorContextManager()
var currentErrorContext atomic.Value // stores *ErrorContext

func WithErrorContext(ctx context.Context) context.Context {
    if requestID := ctx.Value("request_id"); requestID != nil {
        errorCtx := &ErrorContext{
            RequestID:   requestID.(string),
            ServiceName: ctx.Value("service_name").(string),
            Method:      ctx.Value("method").(string),
            TraceID:     ctx.Value("trace_id").(string),
            SpanID:      ctx.Value("span_id").(string),
            Timestamp:   time.Now(),
        }

        if userID := ctx.Value("user_id"); userID != nil {
            errorCtx.UserID = userID.(string)
        }

        currentErrorContext.Store(errorCtx)
    }
    return ctx
}

func getCurrentErrorContext() *ErrorContext {
    if ctx := currentErrorContext.Load(); ctx != nil {
        return ctx.(*ErrorContext)
    }
    return nil
}

func captureStackTrace(skip int) string {
    pc := make([]uintptr, 32)
    n := runtime.Callers(skip+2, pc)
    if n == 0 {
        return ""
    }

    pc = pc[:n]
    frames := runtime.CallersFrames(pc)
    var builder strings.Builder

    for {
        frame, more := frames.Next()
        if !more {
            break
        }

        funcInfo := runtime.FuncForPC(frame.PC)
        if funcInfo != nil {
            file, line := funcInfo.FileLine(frame.PC)
            builder.WriteString(fmt.Sprintf("%s:%d - %s\n", file, line, funcInfo.Name()))
        }
    }

    return builder.String()
}
```

#### **2. é”™è¯¯åŒ…è£…å™¨**
```go
package errors

import (
    "context"
    "errors"
    "log"
    "runtime/debug"
    "time"

    "github.com/go-micro/go-micro/v4/errors"
)

// é”™è¯¯åŒ…è£…å™¨
type ErrorWrapper struct {
    service string
    method  string
}

func NewErrorWrapper(service, method string) *ErrorWrapper {
    return &ErrorWrapper{
        service: service,
        method:  method,
    }
}

// åŒ…è£…ä¸šåŠ¡é”™è¯¯
func (ew *ErrorWrapper) WrapBusinessError(ctx context.Context, err *BusinessError) error {
    // è®°å½•é”™è¯¯æ—¥å¿—
    ew.logError(ctx, err, "business")

    // è½¬æ¢ä¸º gRPC é”™è¯¯
    return err.GRPCStatus().Err()
}

// åŒ…è£…ç³»ç»Ÿé”™è¯¯
func (ew *ErrorWrapper) WrapSystemError(ctx context.Context, err error) error {
    // è®°å½•é”™è¯¯æ—¥å¿—
    ew.logError(ctx, err, "system")

    // è¿”å›åŸå§‹é”™è¯¯æˆ–åŒ…è£…ä¸ºå†…éƒ¨é”™è¯¯
    if errors.Is(err, context.Canceled) {
        return err
    }

    return errors.InternalServer("internal server error", err)
}

// åŒ…è£…æ•°æ®åº“é”™è¯¯
func (ew *ErrorWrapper) WrapDatabaseError(ctx context.Context, err error) error {
    ew.logError(ctx, err, "database")
    return errors.InternalServer("database operation failed", err)
}

// åŒ…è£…éªŒè¯é”™è¯¯
func (ew *ErrorWrapper) WrapValidationError(ctx context.Context, err error) error {
    ew.logError(ctx, err, "validation")
    return errors.InvalidArgument("validation failed", err)
}

// åŒ…è£…å¤–éƒ¨æœåŠ¡é”™è¯¯
func (ew *ErrorWrapper) WrapExternalServiceError(ctx context.Context, serviceName, method string, err error) error {
    ew.logError(ctx, err, "external_service")
    return errors.ServiceUnavailable(
        fmt.Sprintf("external service %s method %s failed", serviceName, method),
        err,
    )
}

// é”™è¯¯æ—¥å¿—è®°å½•
func (ew *ErrorWrapper) logError(ctx context.Context, err error, errorType string) {
    now := time.Now()

    // è·å–è°ƒç”¨æ ˆä¿¡æ¯
    stack := debug.Stack()

    log.Printf("[%s] [%s] %s - %s\n%s",
        now.Format("2006-01-02 15:04:05"),
        errorType,
        ew.service,
        ew.method,
        err.Error(),
        stack,
    )
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleUsage() {
    wrapper := NewErrorWrapper("user-service", "CreateUser")

    ctx := context.Background()

    // æ¨¡æ‹Ÿä¸šåŠ¡é”™è¯¯
    businessErr := ErrUserNotFound("user_id: 12345")
    grpcErr := wrapper.WrapBusinessError(ctx, businessErr)
    log.Printf("ä¸šåŠ¡é”™è¯¯: %v", grpcErr)

    // æ¨¡æ‹Ÿç³»ç»Ÿé”™è¯¯
    systemErr := errors.New("database connection timeout")
    grpcErr = wrapper.WrapSystemError(ctx, systemErr)
    log.Printf("ç³»ç»Ÿé”™è¯¯: %v", grpcErr)

    // æ¨¡æ‹ŸéªŒè¯é”™è¯¯
    validationErr := errors.New("email format invalid")
    grpcErr = wrapper.WrapValidationError(ctx, validationErr)
    log.Printf("éªŒè¯é”™è¯¯: %v", grpcErr)
}
```

#### **3. é”™è¯¯å¤„ç†å™¨ä¸­é—´ä»¶**
```go
package middleware

import (
    "context"
    "net/http"

    "github.com/go-micro/go-micro/v4/client"
    "github.com/go-micro/go-micro/v4/selector"
    "github.com/yourproject/errors"
)

// é”™è¯¯å¤„ç†å™¨
type ErrorHandler struct {
    errorWrapper *errors.ErrorWrapper
}

func NewErrorHandler(serviceName string) *ErrorHandler {
    return &ErrorHandler{
        errorWrapper: errors.NewErrorWrapper(serviceName, "*"),
    }
}

// gRPC è°ƒç”¨é”™è¯¯å¤„ç†åŒ…è£…å™¨
func (eh *ErrorHandler) WrapCall(fn func(ctx context.Context, req interface{}, rsp interface{}) error) func(ctx context.Context, req interface{}, rsp interface{}) error {
    return func(ctx context.Context, req interface{}, rsp interface{}) error {
        err := fn(ctx, req, rsp)
        if err != nil {
            return eh.errorWrapper.WrapSystemError(ctx, err)
        }
        return nil
    }
}

// HTTP é”™è¯¯å¤„ç†å™¨
func (eh *ErrorHandler) HandleHTTPError(w http.ResponseWriter, r *http.Request, err error) {
    // è®°å½•é”™è¯¯
    eh.errorWrapper.WrapSystemError(r.Context(), err)

    // æ ¹æ® error ç±»å‹è¿”å›ç›¸åº”çš„ HTTP çŠ¶æ€ç 
    var statusCode int
    var message string

    switch {
    case errors.Is(err, errors.NotFound):
        statusCode = http.StatusNotFound
        message = "Resource not found"
    case errors.Is(err, errors.InvalidArgument):
        statusCode = http.StatusBadRequest
        message = "Invalid request"
    case errors.Is(err, errors.AlreadyExists):
        statusCode = http.StatusConflict
        message = "Resource already exists"
    case errors.Is(err, errors.ResourceExhausted):
        statusCode = http.StatusTooManyRequests
        message = "Rate limit exceeded"
    case errors.Is(err, errors.InternalServer):
        statusCode = http.StatusInternalServerError
        message = "Internal server error"
    case errors.Is(err, errors.ServiceUnavailable):
        statusCode = http.StatusServiceUnavailable
        message = "Service unavailable"
    default:
        statusCode = http.StatusInternalServerError
        message = "Unknown error"
    }

    // è¿”å›é”™è¯¯å“åº”
    w.Header().Set("Content-Type", "application/json")
    w.WriteHeader(statusCode)

    json.NewEncoder(w).Encode(map[string]interface{}{
        "error": map[string]interface{}{
            "code":    statusCode,
            "message": message,
            "details":  err.Error(),
        },
        "timestamp": time.Now(),
    })
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleUsage() {
    errorHandler := NewErrorHandler("user-service")

    // gRPC æœåŠ¡ä¸­ä½¿ç”¨
    type UserService struct{}

    func (s *UserService) CreateUser(ctx context.Context, req *CreateUserRequest, rsp *CreateUserResponse) error {
        // ä¸šåŠ¡é€»è¾‘
        if req.Email == "" {
            return errors.InvalidArgument("email is required")
        }

        // è°ƒç”¨ä»“å‚¨å±‚ï¼Œå¹¶åŒ…è£…é”™è¯¯
        err := userRepository.Create(ctx, req)
        if err != nil {
            return errorHandler.WrapCall(func(ctx context.Context, req interface{}, rsp interface{}) error {
                return userRepository.Create(ctx, req)
            })(ctx, req, rsp)
        }

        return nil
    }

    // HTTP æœåŠ¡ä¸­ä½¿ç”¨
    http.HandleFunc("/users", func(w http.ResponseWriter, r *http.Request) {
        var req CreateUserRequest
        if err := json.NewDecoder(r.Body).Decode(&req); err != nil {
            errorHandler.HandleHTTPError(w, r, errors.InvalidArgument("invalid request body"))
            return
        }

        rsp := CreateUserResponse{}
        // æ¨¡æ‹Ÿä¸šåŠ¡é”™è¯¯
        if req.Email == "existing@example.com" {
            err := errors.ErrUserAlreadyExists("email already exists")
            errorHandler.HandleHTTPError(w, r, err)
            return
        }

        // æ­£å¸¸å¤„ç†
        json.NewEncoder(w).Encode(rsp)
    })
}
```

### é«˜çº§é”™è¯¯å¤„ç†ç‰¹æ€§

#### **é”™è¯¯æ¢å¤æœºåˆ¶**
```go
package errors

import (
    "context"
    "fmt"
    "time"

    "github.com/go-micro/go-micro/v4/errors"
)

// é”™è¯¯æ¢å¤å™¨
type ErrorRecoverer struct {
    retryCount    int
    maxRetries    int
    retryableErrors map[error]bool
}

func NewErrorRecoverer(maxRetries int) *ErrorRecoverer {
    return &ErrorRecoverer{
        maxRetries: maxRetries,
        retryableErrors: map[error]bool{
            errors.ServiceUnavailable: true,
            errors.ResourceExhausted: true,
            errors.InternalServer:     true,
        },
    }
}

// å¸¦é‡è¯•çš„è°ƒç”¨
func (er *ErrorRecoverer) CallWithRetry(
    ctx context.Context,
    fn func(context.Context) error,
    serviceName string,
    methodName string,
) error {
    var lastErr error
    var retryDelay time.Duration

    for er.retryCount = 0; er.retryCount < er.maxRetries; er.retryCount++ {
        lastErr = fn(ctx)

        if lastErr == nil {
            return nil
        }

        // æ£€æŸ¥æ˜¯å¦æ˜¯å¯é‡è¯•çš„é”™è¯¯
        if !er.isRetryableError(lastErr) {
            return lastErr
        }

        // å¦‚æœä¸æ˜¯æœ€åä¸€æ¬¡å°è¯•ï¼Œåˆ™ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
        if er.retryCount < er.maxRetries {
            // æŒ‡æ•°é€€é¿ç­–ç•¥è®¡ç®—å»¶è¿Ÿ
            retryDelay = er.calculateRetryDelay(er.retryCount)

            select {
            case <-time.After(retryDelay):
                log.Printf("é‡è¯•è°ƒç”¨ %s.%s (ç¬¬%dæ¬¡, ç­‰å¾… %v)", serviceName, methodName, er.retryCount+1, retryDelay)
            case <-ctx.Done():
                return ctx.Err()
            }
        }
    }

    return lastErr
}

// è®¡ç®—é‡è¯•å»¶è¿Ÿ
func (er *ErrorRecoverer) calculateRetryDelay(attempt int) time.Duration {
    baseDelay := time.Second
    maxDelay := time.Second * 30

    // æŒ‡æ•°é€€é¿ï¼šdelay = baseDelay * 2^(attempt-1)
    delay := baseDelay * time.Duration(math.Pow(2, float64(attempt-1)))

    if delay > maxDelay {
        return maxDelay
    }

    return delay
}

// å¸¦ç†”æ–­çš„è°ƒç”¨
func (er *ErrorRecoverer) CallWithCircuitBreaker(
    ctx context.Context,
    fn func(context.Context) error,
    serviceName string,
    methodName string,
    maxFailures int,
) error {
    lastErr := fn(ctx)

    if lastErr == nil {
        return nil
    }

    // æ£€æŸ¥æ˜¯å¦æ˜¯ç½‘ç»œé”™è¯¯æˆ–æœåŠ¡ä¸å¯ç”¨é”™è¯¯
    if er.isRetryableError(lastErr) {
        // ç†”æ–­å™¨é€»è¾‘ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
        return fmt.Errorf("service %s method %s failed after circuit breaker: %w", serviceName, methodName, lastErr)
    }

    return lastErr
}

// å¸¦æ–­è·¯å™¨çš„é«˜çº§è°ƒç”¨
func (er *ErrorRecoverer) CallWithAdvancedRetry(
    ctx context.Context,
    fn func(context.Context) error,
    config *RetryConfig,
) error {
    var lastErr error
    var consecutiveFailures int
    var backoffDelay time.Duration

    for er.retryCount = 0; er.retryCount < config.MaxRetries; er.retryCount++ {
        lastErr = fn(ctx)

        if lastErr == nil {
            return nil
        }

        // æ£€æŸ¥æ˜¯å¦æ˜¯å¯é‡è¯•çš„é”™è¯¯
        if !er.isRetryableError(lastErr) {
            return lastErr
        }

        consecutiveFailures++
        backoffDelay = config.Strategy.CalculateDelay(consecutiveFailures)

        // æ£€æŸ¥æ˜¯å¦è¶…è¿‡æœ€å¤§é‡è¯•æ—¶é—´
        if config.MaxRetryTime > 0 && time.Since(ctx.Value("retry_start_time").(time.Time)) > config.MaxRetryTime {
            return fmt.Errorf("è¶…è¿‡æœ€å¤§é‡è¯•æ—¶é—´é™åˆ¶: %v", config.MaxRetryTime)
        }

        if er.retryCount < config.MaxRetries-1 {
            select {
            case <-time.After(backoffDelay):
                log.Printf("é‡è¯•è°ƒç”¨ (ç¬¬%dæ¬¡, å»¶è¿Ÿ: %v, ç­–ç•¥: %s)",
                    er.retryCount+1, backoffDelay, config.Strategy.Name())
            case <-ctx.Done():
                return ctx.Err()
            }
        }
    }

    return lastErr
}

// é‡è¯•ç­–ç•¥æ¥å£
type RetryStrategy interface {
    Name() string
    CalculateDelay(attempt int) time.Duration
}

// æŒ‡æ•°é€€é¿ç­–ç•¥
type ExponentialBackoffStrategy struct {
    BaseDelay time.Duration
    MaxDelay  time.Duration
    Multiplier float64
}

func (e *ExponentialBackoffStrategy) Name() string {
    return "exponential_backoff"
}

func (e *ExponentialBackoffStrategy) CalculateDelay(attempt int) time.Duration {
    delay := e.BaseDelay * time.Duration(math.Pow(e.Multiplier, float64(attempt-1)))
    if delay > e.MaxDelay {
        return e.MaxDelay
    }
    return delay
}

// çº¿æ€§é€€é¿ç­–ç•¥
type LinearBackoffStrategy struct {
    BaseDelay time.Duration
    MaxDelay  time.Duration
    Increment time.Duration
}

func (l *LinearBackoffStrategy) Name() string {
    return "linear_backoff"
}

func (l *LinearBackoffStrategy) CalculateDelay(attempt int) time.Duration {
    delay := l.BaseDelay + time.Duration(attempt-1)*l.Increment
    if delay > l.MaxDelay {
        return l.MaxDelay
    }
    return delay
}

// å›ºå®šé—´éš”ç­–ç•¥
type FixedIntervalStrategy struct {
    Interval time.Duration
}

func (f *FixedIntervalStrategy) Name() string {
    return "fixed_interval"
}

func (f *FixedIntervalStrategy) CalculateDelay(attempt int) time.Duration {
    return f.Interval
}

// é‡è¯•é…ç½®
type RetryConfig struct {
    MaxRetries   int           `json:"max_retries"`
    MaxRetryTime time.Duration `json:"max_retry_time"`
    Strategy     RetryStrategy `json:"strategy"`
    Jitter       bool          `json:"jitter"`
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleUsage() {
    // é…ç½®ä¸åŒçš„é‡è¯•ç­–ç•¥
    exponentialStrategy := &ExponentialBackoffStrategy{
        BaseDelay: time.Second,
        MaxDelay:  time.Second * 30,
        Multiplier: 2.0,
    }

    linearStrategy := &LinearBackoffStrategy{
        BaseDelay: time.Second,
        MaxDelay:  time.Second * 20,
        Increment: time.Second * 2,
    }

    fixedStrategy := &FixedIntervalStrategy{
        Interval: time.Second * 5,
    }

    configs := map[string]*RetryConfig{
        "exponential": {
            MaxRetries:   5,
            MaxRetryTime: time.Minute * 10,
            Strategy:     exponentialStrategy,
            Jitter:       true,
        },
        "linear": {
            MaxRetries:   6,
            MaxRetryTime: time.Minute * 5,
            Strategy:     linearStrategy,
            Jitter:       false,
        },
        "fixed": {
            MaxRetries:   8,
            MaxRetryTime: 0,
            Strategy:     fixedStrategy,
            Jitter:       false,
        },
    }

    ctx, cancel := context.WithTimeout(context.Background(), time.Minute*2)
    defer cancel()

    // æ¨¡æ‹Ÿä¸€ä¸ªå¯èƒ½å¤±è´¥çš„æœåŠ¡è°ƒç”¨
    attemptCount := 0
    for strategyName, config := range configs {
        ctx = context.WithValue(ctx, "retry_start_time", time.Now())

        err := NewErrorRecoverer(config.MaxRetries).CallWithAdvancedRetry(
            ctx,
            func(ctx context.Context) error {
                attemptCount++
                log.Printf("æ‰§è¡ŒæœåŠ¡è°ƒç”¨ (ç­–ç•¥: %s, å°è¯•: %d)", strategyName, attemptCount)

                // æ¨¡æ‹Ÿå‰å‡ æ¬¡å¤±è´¥ï¼Œæœ€åä¸€æ¬¡æˆåŠŸ
                if attemptCount < 4 {
                    return errors.ServiceUnavailable(fmt.Sprintf("service temporarily unavailable (attempt %d)", attemptCount))
                }
                return nil
            },
            config,
        )

        if err != nil {
            log.Printf("ç­–ç•¥ %s æœ€ç»ˆè°ƒç”¨å¤±è´¥: %v", strategyName, err)
        } else {
            log.Printf("ç­–ç•¥ %s è°ƒç”¨æˆåŠŸ", strategyName)
        }

        // é‡ç½®è®¡æ•°å™¨
        attemptCount = 0
    }
}
```
```

#### **é”™è¯¯ç›‘æ§å’Œå‘Šè­¦**
```go
package monitoring

import (
    "context"
    "log"
    "sync"
    "time"

    "github.com/go-micro/go-micro/v4/errors"
)

// é”™è¯¯ç›‘æ§å™¨
type ErrorMonitor struct {
    errorCounts map[string]int64 // error type -> count
    alerts      map[string]*AlertConfig
    mu           sync.RWMutex
}

type AlertConfig struct {
    Threshold   int           `json:"threshold"`
    Interval    time.Duration `json:"interval"`
    WebhookURL string         `json:"webhook_url"`
}

func NewErrorMonitor() *ErrorMonitor {
    return &ErrorMonitor{
        errorCounts: make(map[string]int64),
        alerts:      make(map[string]*AlertConfig),
    }
}

// è®°å½•é”™è¯¯
func (em *ErrorMonitor) RecordError(err error, service, method string) {
    em.mu.Lock()
    defer em.mu.Unlock()

    errorType := em.classifyError(err)
    em.errorCounts[errorType]++

    log.Printf("é”™è¯¯ç›‘æ§: %s.%s - %s (%s)", service, method, errorType, err.Error())

    // æ£€æŸ¥æ˜¯å¦éœ€è¦è§¦å‘å‘Šè­¦
    if alert, exists := em.alerts[errorType]; exists {
        if em.errorCounts[errorType] >= int64(alert.Threshold) {
            em.triggerAlert(errorType, alert, service, method)
        }
    }
}

// åˆ†ç±»é”™è¯¯ç±»å‹
func (em *ErrorMonitor) classifyError(err error) string {
    switch {
    case errors.Is(err, errors.NotFound):
        return "not_found"
    case errors.Is(err, errors.InvalidArgument):
        return "invalid_argument"
    case errors.Is(err, errors.AlreadyExists):
        return "already_exists"
    case errors.Is(err, errors.ResourceExhausted):
        return "resource_exhausted"
    case errors.Is(err, errors.ServiceUnavailable):
        return "service_unavailable"
    case errors.Is(err, errors.InternalServer):
        return "internal_server"
    default:
        return "unknown"
    }
}

// è§¦å‘å‘Šè­¦
func (em *ErrorMonitor) triggerAlert(errorType string, alert *AlertConfig, service, method string) {
    alertData := map[string]interface{}{
        "timestamp":    time.Now(),
        "error_type":   errorType,
        "service":      service,
        "method":       method,
        "count":        em.errorCounts[errorType],
        "threshold":    alert.Threshold,
        "message":      fmt.Sprintf("%s errors exceeded threshold", errorType),
    }

    log.Printf("è§¦å‘å‘Šè­¦: %+v", alertData)

    // è¿™é‡Œå¯ä»¥å‘é€åˆ°å¤–éƒ¨ç›‘æ§ç³»ç»Ÿ
    // em.sendToWebhook(alert.WebhookURL, alertData)
    // em.sendToSlack(alertData)
    // em.sendToEmail(alertData)
}

// æ·»åŠ å‘Šè­¦é…ç½®
func (em *ErrorMonitor) AddAlert(errorType string, threshold int, interval time.Duration, webhookURL string) {
    em.mu.Lock()
    defer em.mu.Unlock()

    em.alerts[errorType] = &AlertConfig{
        Threshold:   threshold,
        Interval:    interval,
        WebhookURL: webhookURL,
    }

    log.Printf("æ·»åŠ å‘Šè­¦é…ç½®: %s -> threshold: %d", errorType, threshold)
}

// å®šæœŸé‡ç½®è®¡æ•°å™¨
func (em *ErrorMonitor) StartPeriodicReset(interval time.Duration) {
    go func() {
        ticker := time.NewTicker(interval)
        defer ticker.Stop()

        for range ticker.C {
            em.resetCounts()
            log.Println("é”™è¯¯è®¡æ•°å™¨å·²é‡ç½®")
        }
    }()
}

func (em *ErrorMonitor) resetCounts() {
    em.mu.Lock()
    defer em.mu.Unlock()

    for key := range em.errorCounts {
        em.errorCounts[key] = 0
    }
}

// é«˜çº§é”™è¯¯èšåˆå™¨
type ErrorAggregator struct {
    windowSize     time.Duration
    errorBuffer    []ErrorEvent
    patternMatcher *ErrorPatternMatcher
    mu             sync.RWMutex
}

type ErrorEvent struct {
    Timestamp   time.Time              `json:"timestamp"`
    ServiceName string                 `json:"service_name"`
    Method      string                 `json:"method"`
    ErrorType   string                 `json:"error_type"`
    Message     string                 `json:"message"`
    TraceID     string                 `json:"trace_id"`
    UserID      string                 `json:"user_id,omitempty"`
    Metadata    map[string]interface{} `json:"metadata"`
}

type ErrorPattern struct {
    Pattern    string   `json:"pattern"`
    Type       string   `json:"type"`
    Priority   int      `json:"priority"`
    Action      string   `json:"action"` // "alert", "log", "ignore"
}

func NewErrorAggregator(windowSize time.Duration) *ErrorAggregator {
    return &ErrorAggregator{
        windowSize:     windowSize,
        errorBuffer:    make([]ErrorEvent, 0),
        patternMatcher: NewErrorPatternMatcher(),
    }
}

func (ea *ErrorAggregator) RecordError(event ErrorEvent) {
    ea.mu.Lock()
    defer ea.mu.Unlock()

    // æ·»åŠ åˆ°ç¼“å†²åŒº
    ea.errorBuffer = append(ea.errorBuffer, event)

    // ä¿æŒçª—å£å¤§å°
    cutoff := time.Now().Add(-ea.windowSize)
    for i := 0; i < len(ea.errorBuffer); i++ {
        if ea.errorBuffer[i].Timestamp.Before(cutoff) {
            ea.errorBuffer = ea.errorBuffer[i:]
            break
        }
    }

    // æ£€æŸ¥é”™è¯¯æ¨¡å¼
    patterns := ea.patternMatcher.MatchPatterns(event)
    for _, pattern := range patterns {
        ea.handlePatternMatch(event, pattern)
    }
}

func (ea *ErrorAggregator) handlePatternMatch(event ErrorEvent, pattern ErrorPattern) {
    switch pattern.Action {
    case "alert":
        log.Printf("é”™è¯¯æ¨¡å¼åŒ¹é…å‘Šè­¦: %s - %s (æ¨¡å¼: %s)", event.ErrorType, event.Message, pattern.Pattern)
    case "log":
        log.Printf("é”™è¯¯æ¨¡å¼è®°å½•: %s - %s (æ¨¡å¼: %s)", event.ErrorType, event.Message, pattern.Pattern)
    case "ignore":
        // å¿½ç•¥æ­¤é”™è¯¯
    }
}

func (ea *ErrorAggregator) GetErrorReport(startTime, endTime time.Time) *ErrorReport {
    ea.mu.RLock()
    defer ea.mu.RUnlock()

    var events []ErrorEvent
    errorStats := make(map[string]int)
    serviceStats := make(map[string]int)

    for _, event := range ea.errorBuffer {
        if event.Timestamp.After(startTime) && event.Timestamp.Before(endTime) {
            events = append(events, event)
            errorStats[event.ErrorType]++
            serviceStats[event.ServiceName]++
        }
    }

    return &ErrorReport{
        StartTime:    startTime,
        EndTime:      endTime,
        TotalEvents:   len(events),
        Events:       events,
        ErrorStats:   errorStats,
        ServiceStats:  serviceStats,
    }
}

type ErrorReport struct {
    StartTime    time.Time              `json:"start_time"`
    EndTime      time.Time              `json:"end_time"`
    TotalEvents  int                   `json:"total_events"`
    Events       []ErrorEvent          `json:"events"`
    ErrorStats   map[string]int         `json:"error_stats"`
    ServiceStats  map[string]int         `json:"service_stats"`
}

type ErrorPatternMatcher struct {
    patterns []ErrorPattern
    mu       sync.RWMutex
}

func NewErrorPatternMatcher() *ErrorPatternMatcher {
    return &ErrorPatternMatcher{
        patterns: []ErrorPattern{
            {
                Pattern:  "timeout|deadline",
                Type:     "timeout_error",
                Priority: 1,
                Action:   "alert",
            },
            {
                Pattern:  "connection.*fail",
                Type:     "connection_error",
                Priority: 2,
                Action:   "alert",
            },
            {
                Pattern:  "permission.*denied",
                Type:     "authorization_error",
                Priority: 3,
                Action:   "log",
            },
        },
    }
}

func (epm *ErrorPatternMatcher) AddPattern(pattern ErrorPattern) {
    epm.mu.Lock()
    defer epm.mu.Unlock()

    epm.patterns = append(epm.patterns, pattern)
    // æŒ‰ä¼˜å…ˆçº§æ’åº
    sort.Slice(epm.patterns, func(i, j int) bool {
        return epm.patterns[i].Priority < epm.patterns[j].Priority
    })
}

func (epm *ErrorPatternMatcher) MatchPatterns(event ErrorEvent) []ErrorPattern {
    epm.mu.RLock()
    defer epm.mu.RUnlock()

    var matchedPatterns []ErrorPattern

    for _, pattern := range epm.patterns {
        matched, _ := regexp.MatchString(pattern.Pattern, event.Message)
        if matched {
            matchedPatterns = append(matchedPatterns, pattern)
        }
    }

    return matchedPatterns
}

// ä½¿ç”¨ç¤ºä¾‹
func ExampleUsage() {
    monitor := NewErrorMonitor()
    aggregator := NewErrorAggregator(time.Hour)

    // é…ç½®å‘Šè­¦è§„åˆ™
    monitor.AddAlert("service_unavailable", 10, time.Minute, "https://hooks.slack.com/services/xxx")
    monitor.AddAlert("internal_server", 5, time.Minute*5, "https://hooks.slack.com/services/xxx")

    // å¯åŠ¨å®šæœŸé‡ç½®
    monitor.StartPeriodicReset(time.Hour)

    // é…ç½®è‡ªå®šä¹‰é”™è¯¯æ¨¡å¼
    aggregator.patternMatcher.AddPattern(ErrorPattern{
        Pattern:  "payment.*failed",
        Type:     "payment_error",
        Priority: 1,
        Action:   "alert",
    })

    // æ¨¡æ‹Ÿé”™è¯¯è®°å½•
    err := errors.ServiceUnavailable("service down")
    monitor.RecordError(err, "user-service", "GetUser")
    aggregator.RecordError(ErrorEvent{
        Timestamp:   time.Now(),
        ServiceName: "user-service",
        Method:      "GetUser",
        ErrorType:   "service_unavailable",
        Message:     "service down",
        TraceID:     "trace-123",
    })

    err = errors.InternalServer("database connection failed")
    monitor.RecordError(err, "order-service", "CreateOrder")
    aggregator.RecordError(ErrorEvent{
        Timestamp:   time.Now(),
        ServiceName: "order-service",
        Method:      "CreateOrder",
        ErrorType:   "internal_server",
        Message:     "database connection failed",
        TraceID:     "trace-456",
    })

    // ç”Ÿæˆé”™è¯¯æŠ¥å‘Š
    report := aggregator.GetErrorReport(time.Now().Add(-time.Hour), time.Now())
    log.Printf("é”™è¯¯æŠ¥å‘Š: æ€»äº‹ä»¶=%d, é”™è¯¯ç»Ÿè®¡=%+v", report.TotalEvents, report.ErrorStats)
}
```

### æœ€ä½³å®è·µå»ºè®®

#### **é”™è¯¯å¤„ç†ç­–ç•¥**
1. **åˆ†å±‚é”™è¯¯å¤„ç†**
   - **æ•°æ®å±‚é”™è¯¯**ï¼šæ•°æ®åº“æ“ä½œé”™è¯¯
   - **ä¸šåŠ¡å±‚é”™è¯¯**ï¼šä¸šåŠ¡é€»è¾‘é”™è¯¯
   - **æ¥å£å±‚é”™è¯¯**ï¼šAPI è°ƒç”¨é”™è¯¯
   - **ç³»ç»Ÿå±‚é”™è¯¯**ï¼šåŸºç¡€è®¾æ–½é”™è¯¯

2. **é”™è¯¯ä¿¡æ¯è§„èŒƒåŒ–**
   - ä½¿ç”¨æ ‡å‡†çš„é”™è¯¯ç 
   - æä¾›æ¸…æ™°çš„é”™è¯¯æè¿°
   - åŒ…å«è¶³å¤Ÿçš„è°ƒè¯•ä¿¡æ¯
   - é¿å…æ•æ„Ÿä¿¡æ¯æ³„éœ²

3. **é”™è¯¯æ¢å¤æœºåˆ¶**
   - å®ç°è‡ªåŠ¨é‡è¯•ç­–ç•¥
   - ä½¿ç”¨ç†”æ–­å™¨ä¿æŠ¤
   - æä¾›é™çº§æ–¹æ¡ˆ
   - ç¡®ä¿æœ€ç»ˆä¸€è‡´æ€§

4. **é”™è¯¯ç›‘æ§å’Œåˆ†æ**
   - å®æ—¶é”™è¯¯æ”¶é›†
   - é”™è¯¯ç‡ç»Ÿè®¡
   - å‘Šè­¦æœºåˆ¶
   - é”™è¯¯è¶‹åŠ¿åˆ†æ

è¿™äº›è‡ªå®šä¹‰é”™è¯¯è¿”å›æœºåˆ¶æä¾›äº†å®Œæ•´çš„é”™è¯¯å¤„ç†è§£å†³æ–¹æ¡ˆï¼Œå¸®åŠ©å¼€å‘è€…æ„å»ºæ›´åŠ å¥å£®å’Œå¯é çš„åˆ†å¸ƒå¼ç³»ç»Ÿã€‚

## æ‰©å±•æ€§
åŸºäºWrapperï¼ˆä¸­é—´ä»¶ï¼‰
