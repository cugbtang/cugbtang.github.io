---
title: "llm why, how to play?"
date: 2023-11-30T16:01:23+08:00
lastmod: 2023-11-30T16:01:23+08:00
draft: true
tags: ["llm", "why"]
categories: ["llm"]
author: "cugbtang"
---

## transformer-architecture

- 为什么Transformer架构比RNN更适合长序列
- 为什么自注意力机制能捕获长距离依赖
- 为什么多头注意力机制需要多个头
- 为什么位置编码在Transformer中必不可少
- 为什么Transformer不需要递归结构
- 为什么Layer Normalization在Transformer中重要
- 为什么残差连接能解决梯度消失问题
- 为什么前馈网络需要两个线性层
- 为什么Encoder-Decoder架构适合seq2seq任务
- 为什么Transformer的并行化能力强

## attention-mechanism

- 为什么注意力机制能模拟人类认知
- 为什么Query-Key-Value模型有效
- 为什么缩放点积注意力需要缩放
- 为什么自注意力比传统注意力更强大
- 为什么交叉注意力在机器翻译中重要
- 为什么注意力权重和为1
- 为什么注意力机制能解决对齐问题
- 为什么注意力可视化有意义
- 为什么稀疏注意力能降低计算复杂度
- 为什么局部注意力适合长文本

## pretraining-finetuning

- 为什么预训练-微调范式成功
- 为什么自监督学习在NLP中有效
- 为什么MLM和NSL是有效的预训练任务
- 为什么预训练需要海量数据
- 为什么微调需要领域数据
- 为什么参数冻结和全微调有不同效果
- 为什么迁移学习在LLM中重要
- 为什么预训练模型能泛化到新任务
- 为什么少样本学习需要预训练
- 为什么预训练模型需要持续学习

## scaling-laws

- 为什么模型规模会带来性能提升
- 为什么参数量和训练数据要同时增长
- 为什么计算量比参数量更重要
- 为什么涌现能力在特定规模出现
- 为什么上下文学习需要大模型
- 为什么思维链推理需要大模型
- 为什么模型越大，泛化能力越强
- 为什么训练损失遵循幂律分布
- 为什么推理能力随规模增长
- 为什么模型规模不是唯一因素

## inference-optimization

- 为什么推理时的计算复杂度是O(n²)
- 为什么KV Cache能加速推理
- 为什么批处理能提高吞吐量
- 为什么量化能减少显存占用
- 为什么模型蒸馏能保持性能
- 为什么模型剪枝能减少参数量
- 为什么注意力计算是推理瓶颈
- 为什么生成需要逐步解码
- 为什么Beam Search比Greedy Search好
- 为什么温度参数影响生成质量

## tokenization

- 为什么分词是LLM的第一步
- 为什么Byte Pair Encoding有效
- 为什么WordPiece比BPE更好
- 为什么SentencePiece支持多语言
- 为什么子词分词能解决OOV问题
- 为什么词汇表大小影响模型大小
- 为什么分词一致性很重要
- 为什么特殊token（如[CLS], [SEP]）需要
- 为什么分词粒度影响性能
- 为什么后处理能改善输出质量

## training-strategies

- 为什么Adam优化器适合LLM训练
- 为什么学习率预热必要
- 为什么权重衰减能防止过拟合
- 为什么梯度裁剪能稳定训练
- 为什么混合精度训练能加速
- 为什么分布式训练需要同步
- 为什么数据并行比模型并行简单
- 为什么检查点很重要
- 为什么早停能防止过拟合
- 为什么训练需要监控指标

## hallucination-problem

- 为什么LLM会产生幻觉
- 为什么幻觉在事实性任务中更严重
- 为什么检索增强生成能减少幻觉
- 为什么自洽性测试能检测幻觉
- 为什么约束解码能控制输出
- 为什么提示工程能改善输出质量
- 为什么外部知识库能减少幻觉
- 为什么置信度估计很重要
- 为什么多轮对话会放大幻觉
- 为什么幻觉不能完全消除

## ethics-safety

- 为什么LLM需要伦理对齐
- 为什么RLHF能改善模型行为
- 为什么红队测试很重要
- 为什么偏见在LLM中会放大
- 为什么隐私保护在训练中重要
- 为什么内容过滤必要
- 为什么可解释性很重要
- 为什么公平性很难定义
- 为什么安全对齐需要权衡
-为什么透明度很重要

## future-directions

- 为什么多模态融合是趋势
- 为什么Agent架构有前景
- 为什么工具使用能力重要
- 为什么持续学习是挑战
- 为什么能效优化必要
- 为什么边缘部署有价值
- 为什么个性化服务有市场
- 为什么开放生态很重要
- 为什么监管框架需要制定
- 为什么技术普及有社会意义